{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testres/correlation/myexp\n"
     ]
    }
   ],
   "source": [
    "import helmo.util.path_help as path_help\n",
    "\n",
    "save_path = path_help.get_save_path_from_config_path(\n",
    "    '../tests/correlation/myexp.json',\n",
    "    'tests',\n",
    "    'testres',\n",
    ")\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from deeppavlov.core.commands.train import build_model_from_config\n",
    "from deeppavlov.core.data.dataset_reader import DatasetReader\n",
    "#from deeppavlov.core.data.utils import download_decompress\n",
    "from deeppavlov.core.common.registry import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__setitem__\n",
      "SortedDict([('I', 73)])\n",
      "sorted\n",
      "__setitem__\n",
      "SortedDict([('I', 73), ('Z', 90)])\n",
      "I\n",
      "sorted\n",
      "__setitem__\n",
      "SortedDict([('I', 73), ('Z', 90), ('L', 76)])\n",
      "I\n",
      "Z\n",
      "__setitem__\n",
      "SortedDict([('I', 73)])\n",
      "sorted\n",
      "__setitem__\n",
      "SortedDict([('I', 73), ('L', 76)])\n",
      "I\n",
      "sorted\n",
      "__setitem__\n",
      "SortedDict([('I', 73), ('L', 76), ('Z', 90)])\n",
      "I\n",
      "L\n",
      "sorted\n",
      "SortedDict([('I', 73), ('L', 76), ('Z', 90)])\n",
      "I\n",
      "L\n",
      "sorted\n",
      "(SortedDict.sort)self: SortedDict([('I', 73), ('L', 76), ('Z', 90)])\n",
      "SortedDict([('I', 73), ('Z', 90), ('L', 76)])\n",
      "I\n",
      "Z\n",
      "__setitem__\n",
      "SortedDict([('I', 73)])\n",
      "sorted\n",
      "__setitem__\n",
      "SortedDict([('I', 73), ('L', 76)])\n",
      "I\n",
      "sorted\n",
      "__setitem__\n",
      "SortedDict([('I', 73), ('L', 76), ('Z', 90)])\n",
      "I\n",
      "L\n",
      "sorted\n",
      "SortedDict([('I', 73), ('L', 76), ('Z', 90)])\n",
      "I\n",
      "L\n",
      "sorted\n",
      "(SortedDict.sort)self: SortedDict([('I', 73), ('L', 76), ('Z', 90)])\n",
      "I\n",
      "Z\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def decorate_with_post_sort(fn):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        fn(*args, **kwargs)\n",
    "        print(fn.__name__)\n",
    "        args[0].sort()\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class SortedDict(OrderedDict):\n",
    "    def issorted(self):\n",
    "        items = iter(self.items())\n",
    "        first = self._sorting_key(next(items))\n",
    "        print(self)\n",
    "        for item in items:\n",
    "            print(first)\n",
    "            second = self._sorting_key(item)\n",
    "            if second < first:\n",
    "                return False\n",
    "            first = second\n",
    "        print('sorted')\n",
    "        return True\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._sorting_key = lambda x: str(x[0])\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.sort()\n",
    "\n",
    "    @decorate_with_post_sort\n",
    "    def set_sorting_key(self, sorting_key):\n",
    "        self._sorting_key = sorting_key\n",
    "\n",
    "    def sort(self):\n",
    "        if not self.issorted():\n",
    "            self = SortedDict(sorted(self.items(), key=self._sorting_key))\n",
    "            print(\"(SortedDict.sort)self:\", self)\n",
    "\n",
    "    @decorate_with_post_sort\n",
    "    def __setitem__(self, k, v):\n",
    "        super().__setitem__(k, v)\n",
    "        \n",
    "        \n",
    "import string\n",
    "import random\n",
    "sd = SortedDict(random.sample([(c, ord(c)) for c in string.ascii_uppercase], 3))\n",
    "for k, v in sd.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "import string\n",
    "\n",
    "\n",
    "class NotFoundError(Exception):\n",
    "    def __init__(self, message, insert_position):\n",
    "        self.insert_position = insert_position\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "def bin_search(sorted_seq, value, sorting_key=lambda x: x):\n",
    "    len_ = len(sorted_seq)\n",
    "    if len_ > 0:      \n",
    "        lo, hi = 0, len_ - 1\n",
    "        while hi - lo > 0:\n",
    "            mid = (hi + lo) // 2\n",
    "            if sorting_key(sorted_seq[mid]) < value:\n",
    "                lo = mid + 1\n",
    "            elif sorting_key(sorted_seq[mid]) > value:\n",
    "                hi = mid - 1\n",
    "            else:\n",
    "                return mid\n",
    "        if sorting_key(sorted_seq[lo]) == value:\n",
    "            return lo\n",
    "        if sorting_key(sorted_seq[lo]) > value:\n",
    "            ins_pos = lo\n",
    "        else:\n",
    "            ins_pos = lo + 1\n",
    "    else:\n",
    "        ins_pos = 0\n",
    "    raise NotFoundError(\n",
    "        \"value is not in sequence. \"\n",
    "        \"A position in which value has to be inserted is\"\n",
    "        \" available in error.insert_position. error.insert_position == {}\".format(ins_pos),\n",
    "        ins_pos\n",
    "    )\n",
    "    \n",
    "    \n",
    "def search_insert_position(sorted_seq, value, sorting_key=lambda x: x):\n",
    "    try:\n",
    "        idx = bin_search(sorted_seq, value, sorting_key)\n",
    "    except NotFoundError as e:\n",
    "        ins_pos = e.insert_position\n",
    "    else:\n",
    "        ins_pos = idx + 1\n",
    "    return ins_pos\n",
    "\n",
    "\n",
    "class SortedDict(MutableMapping):\n",
    "    __slots__ = ('_sorting_key', '_elements_sorting_key', '_elements')\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._sorting_key = str\n",
    "        self._elements_sorting_key = lambda x: self._sorting_key(x[0])\n",
    "        self._elements = []\n",
    "        if len(args) == 1:\n",
    "            try:\n",
    "                iter(args[0])\n",
    "            except TypeError:\n",
    "                raise TypeError(\"args[0] is not iterable\")\n",
    "            try:\n",
    "                items = args[0].items()\n",
    "                first_arg = 'dict'\n",
    "            except AttributeError:\n",
    "                items = args[0]\n",
    "                first_arg = 'seq'\n",
    "            for idx, element in enumerate(items):\n",
    "                try:\n",
    "                    iter(element)\n",
    "                except TypeError:\n",
    "                    raise TypeError(\n",
    "                        \"elements of args[0] have to be \"\n",
    "                        \"iterables of at least 2 elements\"\n",
    "                    )\n",
    "                counter = 0\n",
    "                _element = []\n",
    "                for v in element:\n",
    "                    _element.append(v)\n",
    "                    counter += 1\n",
    "                    if counter >= 2:\n",
    "                        break\n",
    "                if counter < 2:\n",
    "                    if first_arg == 'seq':\n",
    "                        msg = (\"cannot convert dictionary update sequence \"\n",
    "                               \"element #{} to a sequence of 2 or \"\n",
    "                               \"more elements\".format(idx))\n",
    "                    else:\n",
    "                        msg = (\"broken update dictionary. Dictionary\"\n",
    "                               \" element does not have both key and value\")\n",
    "                    raise TypeError(msg)\n",
    "                self._elements.append(_element)\n",
    "        elif len(args) > 1:\n",
    "            raise TypeError(\"SortedDict expected at most 1 positional arguments, got 2\")\n",
    "        for key, value in kwargs.items():\n",
    "            self._elements.append([key, value])\n",
    "        self._sort()\n",
    "\n",
    "    def _sort(self):\n",
    "        self._elements.sort(key=self._elements_sorting_key)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._elements)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        try:\n",
    "            idx = bin_search(self._elements, self._sorting_key(key), self._elements_sorting_key)\n",
    "        except NotFoundError:\n",
    "            raise KeyError(\"key {} is not in dictionary\".format(key))\n",
    "        return self._elements[idx][1]\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        try:\n",
    "            idx = bin_search(self._elements, self._sorting_key(key), self._elements_sorting_key)\n",
    "            self._elements[idx] = [key, value]\n",
    "        except NotFoundError as e:\n",
    "            ins_pos = e.insert_position\n",
    "            self._elements.insert(ins_pos, [key, value])\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        try:\n",
    "            idx = bin_search(self._elements, self._sorting_key(key), self._elements_sorting_key)\n",
    "            del self._elements[idx]\n",
    "        except NotFoundError:\n",
    "            raise KeyError(\"key {} is not in dictionary\".format(key))\n",
    "\n",
    "    def __iter__(self):\n",
    "        for elem in self._elements:\n",
    "            yield elem[0]\n",
    "\n",
    "    def set_sorting_key(self, sorting_key):\n",
    "        self._sorting_key = sorting_key\n",
    "        self._sort()\n",
    "        \n",
    "    def get_ith_element(self, i):\n",
    "        return self._elements[i]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        elements = ', '.join(['({}, {})'.format(repr(k), repr(v)) for k, v in self.items()])\n",
    "        return 'SortedDict([{}])'.format(elements)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return repr(self)\n",
    "        \n",
    "\n",
    "class Line(SortedDict):\n",
    "    allowed_keys = ['x', 'y', 'xerr', 'yerr']\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if not set(self.keys()) <= set(self.allowed_keys):\n",
    "            raise ValueError(\"only keys 'x', 'y', 'xerr', 'yerr' are allowed\")\n",
    "        super().set_sorting_key(lambda x: self.allowed_keys.index(x))\n",
    "\n",
    "    def set_sorting_key(*args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        return self['x']\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, xv):\n",
    "        self['x'] = xv\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self['y']\n",
    "\n",
    "    @y.setter\n",
    "    def y(self, yv):\n",
    "        self['y'] = yv\n",
    "\n",
    "    @property\n",
    "    def xerr(self):\n",
    "        return self['xerr']\n",
    "\n",
    "    @xerr.setter\n",
    "    def xerr(self, xerrv):\n",
    "        self['xerr'] = xerrv\n",
    "\n",
    "    @property\n",
    "    def yerr(self):\n",
    "        return self['yerr']\n",
    "\n",
    "    @yerr.setter\n",
    "    def yerr(self, yerrv):\n",
    "        self['yerr'] = yerrv\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key not in self.allowed_keys:\n",
    "            raise ValueError(\"only keys 'x', 'y', 'xerr', 'yerr' are allowed\")\n",
    "        super().__setitem__(key, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Line' + super().__repr__().lstrip(string.ascii_letters)\n",
    "\n",
    "\n",
    "class PlotData(SortedDict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._transform_keys_to_str()\n",
    "        self._transform_values_to_lines()\n",
    "\n",
    "    def _transform_keys_to_str(self):\n",
    "        for key, value in self.items():\n",
    "            if not isinstance(key, str):\n",
    "                new_key = str(key)\n",
    "                if new_key in self:\n",
    "                    warnings.warn(\n",
    "                        \"replacing value of element `('{}', VALUE)` with\"\n",
    "                        \" value of element `({}, VALUE)`. Conflict between\"\n",
    "                        \" line labels occured during transforming labels to type\"\n",
    "                        \" str. The element `({}, VALUE)` is going to be \"\n",
    "                        \"removed\".format(new_key, key, key)\n",
    "                    )\n",
    "                self[new_key] = self[key]\n",
    "                del self[key]\n",
    "\n",
    "    def _transform_values_to_lines(self):\n",
    "        for key, value in self.items():\n",
    "            self[key] = Line(value)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.keys())\n",
    "\n",
    "    def get_lines(self):\n",
    "        return list(self.values())\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if not isinstance(key, str):\n",
    "            warnings.warn(\n",
    "                \"only keys of type `str` are allowed.\"\n",
    "                \" Element with key '{}' will be set.\".format(str(key))\n",
    "            )\n",
    "            key = str(key)\n",
    "        super().__setitem__(key, Line(value))\n",
    "\n",
    "    def get_spec(self, spec, labels=None):\n",
    "        if labels is None:\n",
    "            labels = self.get_labels()\n",
    "        res = []\n",
    "        for lbl in labels:\n",
    "            res.append(self[lbl][spec])\n",
    "        return res\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'PlotData' + super().__repr__().lstrip(string.ascii_letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlotData([('dropout', Line([('x', [1, 2, 3]), ('y', [5, 6, 7]), ('xerr', [8, 9, 10]), ('yerr', [11, 12, 13])])), ('nodrop', Line([('x', [41, 42, 43]), ('y', [45, 46, 47]), ('xerr', [48, 49, 410]), ('yerr', [411, 412, 413])]))])\n",
      "Line([('x', [41, 42, 43]), ('y', [45, 46, 47]), ('xerr', [48, 49, 410]), ('yerr', [411, 412, 413])])\n"
     ]
    }
   ],
   "source": [
    "pd = PlotData()\n",
    "\n",
    "pd['dropout'] = dict(\n",
    "    x=[1, 2, 3],\n",
    "    y=[5, 6, 7],\n",
    "    xerr=[8, 9, 10],\n",
    "    yerr=[11, 12, 13],\n",
    ")\n",
    "pd['nodrop'] = dict(\n",
    "    x=[41, 42, 43],\n",
    "    y=[45, 46, 47],\n",
    "    xerr=[48, 49, 410],\n",
    "    yerr=[411, 412, 413],\n",
    ")\n",
    "\n",
    "print(pd)\n",
    "print(pd['nodrop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-015e013b0ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3155\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1813\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1814\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1706\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m         \"\"\"\n\u001b[0;32m-> 1730\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \"\"\"\n\u001b[1;32m    924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'c'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.colors' has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.colors' has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot('c', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-8a6875dce3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'123'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "l = '123'\n",
    "l.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 0\n",
      "(array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_1_squash(borders, i):\n",
    "    print(borders, i)\n",
    "#     left, right = borders[0], borders[1]\n",
    "#     left_idx, right_idx = round(left), np.ceil(right)\n",
    "#     num_ones = right_idx - left_idx - 1\n",
    "#     if left == left_idx:\n",
    "#         num_ones += 1\n",
    "#     if right == right_idx:\n",
    "#         num_ones += 1\n",
    "#     indices = list(zip(range(left_idx, right_idx+1), [i]*(right_idx - left_idx + 1)))\n",
    "#     values = [np.ceil(left) - left] if left_idx < left else []\n",
    "#     values += [1] * num_ones\n",
    "#     if right != right_idx:\n",
    "#         values.append(right - round(right))\n",
    "#     return indices, values\n",
    "\n",
    "def squash_sparse_matrix(N, M):\n",
    "    factor = N / M\n",
    "    borders = np.stack([np.arange(N, 0, -1), np.arange(1, N+1)]) * factor\n",
    "    # print(borders.shape)\n",
    "    borders_sep = np.split(borders, borders.shape[0])\n",
    "    # print(borders_sep)\n",
    "    vfunc = np.vectorize(process_1_squash, otypes=[np.int32, np.float32])\n",
    "    return vfunc(borders, tuple(range(N)))\n",
    "    \n",
    "print(squash_sparse_matrix(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('напишите', 1), ('программу', 1), ('вычисляющую', 1), ('каждое', 1), ('встречается', 1), ('поданной', 1), ('на', 1), ('вход', 1), ('результаты', 1), ('подсчета', 1), ('поместите', 1), ('распечатайте', 1), ('порядке', 1), ('убывания', 1), ('слов', 1), ('каждой', 1), ('сначала', 1), ('печатается', 1), ('номер', 1), ('места', 1), ('по', 1), ('которое', 1), ('заняло', 1), ('через', 1), ('пробел', 1), ('то', 1), ('оно', 1), ('встретилось', 1), ('само', 1), ('гарантируется', 1), ('что', 1), ('во', 1), ('входном', 1), ('не', 1), ('будет', 1), ('символов', 1), ('кроме', 1), ('букв', 1), ('пробелов', 1), ('перед', 1), ('сортировкой', 1), ('весь', 1), ('текст', 1), ('следует', 1), ('перевести', 1), ('нижний', 1), ('регистр', 1), ('с', 1), ('помощью', 1), ('метода', 1), ('strlower', 1), ('сколько', 2), ('раз', 2), ('тексте', 2), ('строке', 2), ('словарь', 2), ('а', 2), ('затем', 2), ('встречаемости', 2), ('и', 2), ('слово', 3), ('в', 5)]\n"
     ]
    }
   ],
   "source": [
    "text = \"Напишите программу вычисляющую сколько раз каждое слово \\\n",
    "встречается в поданной на вход тексте строке Результаты подсчета \\\n",
    "поместите в словарь а затем распечатайте словарь в порядке убывания \\\n",
    "встречаемости слов В каждой строке сначала печатается номер места \\\n",
    "по встречаемости которое заняло слово а затем через пробел то \\\n",
    "сколько раз оно встретилось и само слово  Гарантируется что во \\\n",
    "входном тексте не будет символов кроме букв и пробелов Перед \\\n",
    "сортировкой весь текст следует перевести в нижний регистр с помощью метода strlower\"\n",
    "m = text.lower().split()\n",
    "t = []\n",
    "d = {}\n",
    "for i in m:\n",
    "    t = m.count(i)\n",
    "    d[i] = t\n",
    "d1 = sorted(d.items(), key=lambda x: x[1])\n",
    "#print(t)\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-00010c0e432b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequence' is not defined"
     ]
    }
   ],
   "source": [
    "isinstance([], Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 7, 7, 8)\n",
      "[[[[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.096e-01 -1.802e-01 -1.786e-01 -1.801e-01 -8.473e-04  1.085e-01 -2.087e-01  1.335e-01]\n",
      "    [-1.247e-01 -2.044e-01  1.059e-01  1.963e-01  2.107e-01  7.044e-02 -1.388e-02  2.636e-02]\n",
      "    [ 7.015e-02  6.669e-03  1.606e-01 -2.798e-02  1.208e-01 -1.325e-01  3.181e-01 -5.033e-02]\n",
      "    [-6.584e-02 -9.931e-02 -3.846e-01 -1.510e-01  1.554e-01 -7.803e-03  1.518e-01 -1.723e-02]\n",
      "    [-1.958e-01  1.965e-01  6.363e-03 -2.178e-01  5.689e-02 -1.374e-02  1.368e-01 -1.021e-01]\n",
      "    [ 1.550e-01 -4.323e-02  2.239e-01  3.748e-01 -1.084e-01  2.267e-03  2.646e-01  1.043e-01]]\n",
      "\n",
      "   [[-1.096e-01 -1.802e-01 -1.786e-01 -1.801e-01 -8.473e-04  1.085e-01 -2.087e-01  1.335e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.162e-01  4.158e-01 -9.634e-02  6.855e-02  2.002e-01  2.842e-01 -9.005e-03 -1.199e-01]\n",
      "    [-2.153e-01  9.071e-02  2.484e-01  2.981e-01  1.641e-01 -1.933e-01 -2.347e-01  9.671e-02]\n",
      "    [-1.571e-01 -4.412e-02  7.858e-02  7.732e-02  7.822e-02 -9.912e-02 -1.700e-01 -7.418e-02]\n",
      "    [ 1.024e-01 -1.120e-03  1.614e-01  1.455e-01  1.225e-01 -4.813e-02 -5.576e-02  2.224e-01]\n",
      "    [ 2.194e-03 -4.185e-02 -1.054e-01  4.380e-02 -7.028e-02 -8.369e-02 -1.558e-01  9.698e-03]]\n",
      "\n",
      "   [[-1.247e-01 -2.044e-01  1.059e-01  1.963e-01  2.107e-01  7.044e-02 -1.388e-02  2.636e-02]\n",
      "    [ 2.162e-01  4.158e-01 -9.634e-02  6.855e-02  2.002e-01  2.842e-01 -9.005e-03 -1.199e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.860e-01  8.311e-02 -1.998e-01 -3.509e-02 -3.100e-01 -2.427e-01 -3.209e-02 -1.136e-01]\n",
      "    [-2.138e-01 -1.456e-01  1.160e-01 -3.189e-02 -7.218e-02  3.423e-02  1.095e-01 -8.143e-03]\n",
      "    [ 1.128e-01 -4.252e-03  4.736e-02  1.362e-01  1.211e-01 -5.940e-02  6.691e-02 -1.082e-02]\n",
      "    [-1.270e-01 -2.043e-02 -1.498e-02  9.200e-02 -4.315e-02  1.581e-01 -1.441e-01  1.033e-01]]\n",
      "\n",
      "   [[ 7.015e-02  6.669e-03  1.606e-01 -2.798e-02  1.208e-01 -1.325e-01  3.181e-01 -5.033e-02]\n",
      "    [-2.153e-01  9.071e-02  2.484e-01  2.981e-01  1.641e-01 -1.933e-01 -2.347e-01  9.671e-02]\n",
      "    [-3.860e-01  8.311e-02 -1.998e-01 -3.509e-02 -3.100e-01 -2.427e-01 -3.209e-02 -1.136e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-7.821e-02 -1.070e-01  7.468e-03  2.285e-02 -1.507e-02 -5.956e-02  6.558e-02 -6.142e-03]\n",
      "    [-3.000e-01 -3.808e-01  1.915e-01  4.705e-02  1.122e-02  1.691e-01 -2.978e-01 -3.352e-02]\n",
      "    [-3.290e-02 -1.138e-01 -6.234e-02  9.867e-02 -2.252e-01 -4.585e-02 -5.078e-02 -1.828e-01]]\n",
      "\n",
      "   [[-6.584e-02 -9.931e-02 -3.846e-01 -1.510e-01  1.554e-01 -7.803e-03  1.518e-01 -1.723e-02]\n",
      "    [-1.571e-01 -4.412e-02  7.858e-02  7.732e-02  7.822e-02 -9.912e-02 -1.700e-01 -7.418e-02]\n",
      "    [-2.138e-01 -1.456e-01  1.160e-01 -3.189e-02 -7.218e-02  3.423e-02  1.095e-01 -8.143e-03]\n",
      "    [-7.821e-02 -1.070e-01  7.468e-03  2.285e-02 -1.507e-02 -5.956e-02  6.558e-02 -6.142e-03]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.236e-02  7.121e-02  9.198e-02  3.524e-01 -1.104e-04  6.737e-02  1.623e-01  4.576e-02]\n",
      "    [-1.953e-01  1.168e-01  7.041e-03 -9.017e-02 -4.994e-01 -1.743e-01  2.246e-01 -8.202e-02]]\n",
      "\n",
      "   [[-1.958e-01  1.965e-01  6.363e-03 -2.178e-01  5.689e-02 -1.374e-02  1.368e-01 -1.021e-01]\n",
      "    [ 1.024e-01 -1.120e-03  1.614e-01  1.455e-01  1.225e-01 -4.813e-02 -5.576e-02  2.224e-01]\n",
      "    [ 1.128e-01 -4.252e-03  4.736e-02  1.362e-01  1.211e-01 -5.940e-02  6.691e-02 -1.082e-02]\n",
      "    [-3.000e-01 -3.808e-01  1.915e-01  4.705e-02  1.122e-02  1.691e-01 -2.978e-01 -3.352e-02]\n",
      "    [ 2.236e-02  7.121e-02  9.198e-02  3.524e-01 -1.104e-04  6.737e-02  1.623e-01  4.576e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.928e-01 -2.438e-02 -2.127e-01 -1.591e-01 -8.339e-03 -1.783e-01  8.203e-03  1.377e-02]]\n",
      "\n",
      "   [[ 1.550e-01 -4.323e-02  2.239e-01  3.748e-01 -1.084e-01  2.267e-03  2.646e-01  1.043e-01]\n",
      "    [ 2.194e-03 -4.185e-02 -1.054e-01  4.380e-02 -7.028e-02 -8.369e-02 -1.558e-01  9.698e-03]\n",
      "    [-1.270e-01 -2.043e-02 -1.498e-02  9.200e-02 -4.315e-02  1.581e-01 -1.441e-01  1.033e-01]\n",
      "    [-3.290e-02 -1.138e-01 -6.234e-02  9.867e-02 -2.252e-01 -4.585e-02 -5.078e-02 -1.828e-01]\n",
      "    [-1.953e-01  1.168e-01  7.041e-03 -9.017e-02 -4.994e-01 -1.743e-01  2.246e-01 -8.202e-02]\n",
      "    [ 2.928e-01 -2.438e-02 -2.127e-01 -1.591e-01 -8.339e-03 -1.783e-01  8.203e-03  1.377e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.335e-01 -2.404e-01 -6.311e-02  1.116e-03  2.900e-02  3.785e-02 -1.885e-01 -1.155e-01]\n",
      "    [-7.542e-02 -3.645e-01  7.442e-02  2.196e-01 -2.955e-01  2.625e-02  7.420e-02  8.822e-02]\n",
      "    [-2.504e-02 -1.282e-01 -1.304e-01 -1.234e-01 -1.043e-01 -4.033e-02  3.108e-01  3.785e-02]\n",
      "    [ 7.209e-02  6.648e-02 -2.694e-01  1.576e-01  2.431e-01 -1.290e-02 -6.212e-02 -2.907e-01]\n",
      "    [ 6.396e-02 -5.224e-02 -1.211e-01  1.829e-01 -2.589e-02  2.486e-01 -1.197e-01  9.929e-02]\n",
      "    [-2.066e-01  5.615e-02  4.469e-01 -1.898e-01 -5.434e-03 -3.699e-01  2.677e-02  2.613e-01]]\n",
      "\n",
      "   [[ 1.335e-01 -2.404e-01 -6.311e-02  1.116e-03  2.900e-02  3.785e-02 -1.885e-01 -1.155e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.287e-02 -8.796e-02  9.270e-02 -2.871e-01 -2.027e-01  2.234e-01 -1.281e-02  6.121e-02]\n",
      "    [-6.017e-02 -2.141e-01 -1.041e-01 -3.857e-02 -6.327e-04 -2.068e-01 -1.497e-01 -3.132e-01]\n",
      "    [-1.258e-01 -1.496e-01  2.628e-02  1.216e-02 -1.530e-01 -1.031e-01 -1.477e-02  1.188e-01]\n",
      "    [-2.684e-02 -1.013e-01  4.865e-02 -3.099e-01  3.192e-02 -2.317e-01 -1.190e-01 -8.391e-02]\n",
      "    [-6.700e-02  1.279e-01 -2.156e-01  2.247e-01  2.028e-01  1.079e-01 -1.579e-01 -2.762e-01]]\n",
      "\n",
      "   [[-7.542e-02 -3.645e-01  7.442e-02  2.196e-01 -2.955e-01  2.625e-02  7.420e-02  8.822e-02]\n",
      "    [-3.287e-02 -8.796e-02  9.270e-02 -2.871e-01 -2.027e-01  2.234e-01 -1.281e-02  6.121e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.829e-01  3.573e-01  6.467e-02  2.296e-01  4.961e-02  2.012e-02 -1.358e-01  2.225e-01]\n",
      "    [-6.606e-02  2.079e-01  8.428e-02 -8.388e-02 -1.790e-02  1.117e-02  1.721e-01  8.092e-02]\n",
      "    [ 1.743e-01  4.483e-02  9.887e-02  3.851e-02 -2.472e-01 -1.293e-01  4.940e-02  9.359e-02]\n",
      "    [ 3.096e-01 -4.865e-02  9.798e-03 -5.666e-02 -1.445e-01  1.569e-01 -1.159e-01 -2.364e-01]]\n",
      "\n",
      "   [[-2.504e-02 -1.282e-01 -1.304e-01 -1.234e-01 -1.043e-01 -4.033e-02  3.108e-01  3.785e-02]\n",
      "    [-6.017e-02 -2.141e-01 -1.041e-01 -3.857e-02 -6.327e-04 -2.068e-01 -1.497e-01 -3.132e-01]\n",
      "    [ 2.829e-01  3.573e-01  6.467e-02  2.296e-01  4.961e-02  2.012e-02 -1.358e-01  2.225e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-8.834e-02  1.941e-01 -5.045e-02 -1.465e-01  7.116e-02 -3.346e-02 -5.079e-02 -1.145e-01]\n",
      "    [ 2.980e-01  1.922e-01  5.454e-02  2.302e-02 -2.551e-02  1.311e-01  1.452e-01  1.219e-01]\n",
      "    [ 2.984e-01 -1.211e-01  7.815e-02  1.129e-01 -1.209e-01 -8.585e-02 -9.084e-02  2.168e-01]]\n",
      "\n",
      "   [[ 7.209e-02  6.648e-02 -2.694e-01  1.576e-01  2.431e-01 -1.290e-02 -6.212e-02 -2.907e-01]\n",
      "    [-1.258e-01 -1.496e-01  2.628e-02  1.216e-02 -1.530e-01 -1.031e-01 -1.477e-02  1.188e-01]\n",
      "    [-6.606e-02  2.079e-01  8.428e-02 -8.388e-02 -1.790e-02  1.117e-02  1.721e-01  8.092e-02]\n",
      "    [-8.834e-02  1.941e-01 -5.045e-02 -1.465e-01  7.116e-02 -3.346e-02 -5.079e-02 -1.145e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.060e-01  2.507e-01 -3.398e-02 -1.887e-01 -2.538e-01 -1.492e-01  6.207e-02 -1.651e-01]\n",
      "    [ 6.515e-02 -1.810e-01 -4.841e-01 -1.767e-01 -1.416e-01 -5.040e-02  4.704e-02 -2.599e-01]]\n",
      "\n",
      "   [[ 6.396e-02 -5.224e-02 -1.211e-01  1.829e-01 -2.589e-02  2.486e-01 -1.197e-01  9.929e-02]\n",
      "    [-2.684e-02 -1.013e-01  4.865e-02 -3.099e-01  3.192e-02 -2.317e-01 -1.190e-01 -8.391e-02]\n",
      "    [ 1.743e-01  4.483e-02  9.887e-02  3.851e-02 -2.472e-01 -1.293e-01  4.940e-02  9.359e-02]\n",
      "    [ 2.980e-01  1.922e-01  5.454e-02  2.302e-02 -2.551e-02  1.311e-01  1.452e-01  1.219e-01]\n",
      "    [ 1.060e-01  2.507e-01 -3.398e-02 -1.887e-01 -2.538e-01 -1.492e-01  6.207e-02 -1.651e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.655e-01 -7.410e-02 -1.007e-01 -2.313e-01  1.172e-02 -3.053e-01 -1.524e-01  1.390e-01]]\n",
      "\n",
      "   [[-2.066e-01  5.615e-02  4.469e-01 -1.898e-01 -5.434e-03 -3.699e-01  2.677e-02  2.613e-01]\n",
      "    [-6.700e-02  1.279e-01 -2.156e-01  2.247e-01  2.028e-01  1.079e-01 -1.579e-01 -2.762e-01]\n",
      "    [ 3.096e-01 -4.865e-02  9.798e-03 -5.666e-02 -1.445e-01  1.569e-01 -1.159e-01 -2.364e-01]\n",
      "    [ 2.984e-01 -1.211e-01  7.815e-02  1.129e-01 -1.209e-01 -8.585e-02 -9.084e-02  2.168e-01]\n",
      "    [ 6.515e-02 -1.810e-01 -4.841e-01 -1.767e-01 -1.416e-01 -5.040e-02  4.704e-02 -2.599e-01]\n",
      "    [ 1.655e-01 -7.410e-02 -1.007e-01 -2.313e-01  1.172e-02 -3.053e-01 -1.524e-01  1.390e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.452e-01  7.307e-02  6.088e-02 -1.258e-01  1.130e-01  1.273e-01  1.477e-01 -1.655e-01]\n",
      "    [-6.687e-02  1.397e-02  1.229e-01 -8.827e-02  6.565e-02  9.803e-02 -5.751e-02  6.253e-03]\n",
      "    [-4.007e-01  8.886e-02 -1.104e-01 -8.351e-02  1.809e-01  1.112e-01 -1.293e-01  6.947e-02]\n",
      "    [-2.207e-01 -1.856e-01 -6.299e-02 -1.623e-02 -1.935e-01  1.230e-02 -4.607e-02 -2.962e-01]\n",
      "    [ 2.944e-02  5.148e-02  1.417e-01 -3.462e-01 -6.753e-02 -3.477e-01 -2.771e-01  2.550e-01]\n",
      "    [ 1.544e-01  1.531e-02 -2.038e-03  1.851e-02  1.702e-01 -6.066e-02  7.838e-02  8.430e-02]]\n",
      "\n",
      "   [[ 2.452e-01  7.307e-02  6.088e-02 -1.258e-01  1.130e-01  1.273e-01  1.477e-01 -1.655e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.896e-01 -2.737e-02 -1.702e-01  2.546e-01  6.462e-02  1.194e-01 -8.212e-02 -1.391e-01]\n",
      "    [ 5.545e-02  1.641e-01  8.559e-02 -4.247e-02  2.911e-01  3.312e-01 -1.119e-01 -1.070e-01]\n",
      "    [ 2.245e-01  6.486e-02 -1.657e-01  1.660e-01  1.528e-01 -3.041e-01 -1.316e-01  1.381e-01]\n",
      "    [ 2.579e-01 -2.339e-01  2.945e-01  2.521e-02 -3.029e-03  7.941e-02 -1.778e-01  4.449e-02]\n",
      "    [ 1.791e-01  9.309e-03 -7.476e-03  2.565e-01 -1.666e-01 -1.927e-01  9.819e-02 -1.621e-02]]\n",
      "\n",
      "   [[-6.687e-02  1.397e-02  1.229e-01 -8.827e-02  6.565e-02  9.803e-02 -5.751e-02  6.253e-03]\n",
      "    [-1.896e-01 -2.737e-02 -1.702e-01  2.546e-01  6.462e-02  1.194e-01 -8.212e-02 -1.391e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.789e-02  1.830e-01 -6.794e-02 -1.344e-01  3.901e-01  1.470e-01  2.866e-01  6.049e-02]\n",
      "    [-1.541e-01 -2.064e-01  2.354e-01 -3.528e-01  1.919e-01 -2.791e-01 -1.223e-01  3.314e-02]\n",
      "    [-2.696e-01 -4.093e-02 -1.250e-01  4.106e-01 -3.389e-02  3.152e-01 -1.143e-01 -6.755e-02]\n",
      "    [ 1.924e-01 -3.009e-01 -2.029e-01 -4.352e-02  5.063e-02  3.176e-02  8.502e-02 -1.234e-01]]\n",
      "\n",
      "   [[-4.007e-01  8.886e-02 -1.104e-01 -8.351e-02  1.809e-01  1.112e-01 -1.293e-01  6.947e-02]\n",
      "    [ 5.545e-02  1.641e-01  8.559e-02 -4.247e-02  2.911e-01  3.312e-01 -1.119e-01 -1.070e-01]\n",
      "    [ 1.789e-02  1.830e-01 -6.794e-02 -1.344e-01  3.901e-01  1.470e-01  2.866e-01  6.049e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 6.753e-02 -1.084e-01  3.066e-02  4.254e-02 -5.713e-02 -1.355e-01  2.543e-01  1.826e-01]\n",
      "    [-4.160e-02  5.737e-02 -3.728e-01  7.922e-02 -2.032e-02  2.652e-01 -8.650e-02  4.005e-02]\n",
      "    [-2.753e-02 -1.781e-01  6.309e-02  9.429e-02  2.746e-01 -2.535e-01  5.489e-02  5.809e-02]]\n",
      "\n",
      "   [[-2.207e-01 -1.856e-01 -6.299e-02 -1.623e-02 -1.935e-01  1.230e-02 -4.607e-02 -2.962e-01]\n",
      "    [ 2.245e-01  6.486e-02 -1.657e-01  1.660e-01  1.528e-01 -3.041e-01 -1.316e-01  1.381e-01]\n",
      "    [-1.541e-01 -2.064e-01  2.354e-01 -3.528e-01  1.919e-01 -2.791e-01 -1.223e-01  3.314e-02]\n",
      "    [ 6.753e-02 -1.084e-01  3.066e-02  4.254e-02 -5.713e-02 -1.355e-01  2.543e-01  1.826e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.531e-02 -1.096e-01 -1.239e-01 -3.003e-02  2.176e-02 -2.450e-03 -2.145e-01 -1.827e-01]\n",
      "    [-1.144e-02  4.298e-01  5.660e-02  1.455e-02 -1.823e-01 -2.454e-01  1.168e-01 -2.224e-01]]\n",
      "\n",
      "   [[ 2.944e-02  5.148e-02  1.417e-01 -3.462e-01 -6.753e-02 -3.477e-01 -2.771e-01  2.550e-01]\n",
      "    [ 2.579e-01 -2.339e-01  2.945e-01  2.521e-02 -3.029e-03  7.941e-02 -1.778e-01  4.449e-02]\n",
      "    [-2.696e-01 -4.093e-02 -1.250e-01  4.106e-01 -3.389e-02  3.152e-01 -1.143e-01 -6.755e-02]\n",
      "    [-4.160e-02  5.737e-02 -3.728e-01  7.922e-02 -2.032e-02  2.652e-01 -8.650e-02  4.005e-02]\n",
      "    [-2.531e-02 -1.096e-01 -1.239e-01 -3.003e-02  2.176e-02 -2.450e-03 -2.145e-01 -1.827e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.241e-01  1.383e-02  1.277e-02 -1.105e-01  5.761e-02 -2.648e-01 -2.969e-02  7.101e-02]]\n",
      "\n",
      "   [[ 1.544e-01  1.531e-02 -2.038e-03  1.851e-02  1.702e-01 -6.066e-02  7.838e-02  8.430e-02]\n",
      "    [ 1.791e-01  9.309e-03 -7.476e-03  2.565e-01 -1.666e-01 -1.927e-01  9.819e-02 -1.621e-02]\n",
      "    [ 1.924e-01 -3.009e-01 -2.029e-01 -4.352e-02  5.063e-02  3.176e-02  8.502e-02 -1.234e-01]\n",
      "    [-2.753e-02 -1.781e-01  6.309e-02  9.429e-02  2.746e-01 -2.535e-01  5.489e-02  5.809e-02]\n",
      "    [-1.144e-02  4.298e-01  5.660e-02  1.455e-02 -1.823e-01 -2.454e-01  1.168e-01 -2.224e-01]\n",
      "    [-3.241e-01  1.383e-02  1.277e-02 -1.105e-01  5.761e-02 -2.648e-01 -2.969e-02  7.101e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 8.816e-02 -2.472e-01 -6.651e-02  2.681e-01  5.759e-02 -2.123e-01 -2.190e-02 -6.550e-02]\n",
      "    [ 4.062e-02  1.963e-01  1.445e-01  1.318e-01 -4.065e-02 -2.365e-01 -3.009e-01 -1.563e-01]\n",
      "    [-3.129e-04  2.589e-01  1.027e-01 -6.114e-02 -1.828e-01  3.848e-01 -3.836e-01 -3.003e-01]\n",
      "    [ 1.124e-02  7.816e-02  3.054e-01 -1.336e-03 -2.966e-01  4.472e-02  1.050e-01 -1.033e-01]\n",
      "    [-1.666e-01 -1.671e-01 -1.588e-01 -1.704e-02 -2.006e-01  1.078e-02 -2.379e-01 -9.300e-02]\n",
      "    [ 1.279e-01  1.663e-01  1.632e-01  6.332e-02 -7.766e-02  1.546e-01  3.405e-01 -1.409e-01]]\n",
      "\n",
      "   [[ 8.816e-02 -2.472e-01 -6.651e-02  2.681e-01  5.759e-02 -2.123e-01 -2.190e-02 -6.550e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.667e-01 -2.511e-01 -1.189e-01  9.719e-02  1.717e-01 -4.221e-02 -2.800e-01 -2.669e-01]\n",
      "    [ 2.060e-02  8.896e-02 -5.181e-02 -1.162e-01 -7.695e-02 -3.373e-01 -8.122e-02 -5.654e-02]\n",
      "    [-1.135e-01  2.452e-02  5.205e-02  1.172e-01 -1.265e-01  9.316e-02  1.680e-01 -4.363e-02]\n",
      "    [ 3.197e-01 -1.071e-01 -1.580e-01 -1.369e-02 -5.149e-02 -1.904e-01 -1.500e-02  6.216e-03]\n",
      "    [ 9.295e-02  1.022e-01 -1.402e-01  1.332e-01 -3.097e-02 -1.834e-01  1.292e-01  5.214e-02]]\n",
      "\n",
      "   [[ 4.062e-02  1.963e-01  1.445e-01  1.318e-01 -4.065e-02 -2.365e-01 -3.009e-01 -1.563e-01]\n",
      "    [ 1.667e-01 -2.511e-01 -1.189e-01  9.719e-02  1.717e-01 -4.221e-02 -2.800e-01 -2.669e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 4.521e-01 -1.723e-01  2.303e-01  7.887e-02  1.658e-01  1.412e-01  2.664e-01 -6.174e-02]\n",
      "    [-2.106e-02  1.446e-01  2.764e-02 -4.116e-01 -1.832e-01 -3.105e-02  1.189e-01  6.775e-03]\n",
      "    [-1.448e-01 -1.238e-01  1.194e-01  2.947e-02  1.581e-01  8.188e-02  1.878e-02  9.213e-02]\n",
      "    [ 1.077e-01 -8.543e-02  2.443e-01 -1.127e-02 -1.494e-01  3.389e-02 -2.631e-01 -1.716e-02]]\n",
      "\n",
      "   [[-3.129e-04  2.589e-01  1.027e-01 -6.114e-02 -1.828e-01  3.848e-01 -3.836e-01 -3.003e-01]\n",
      "    [ 2.060e-02  8.896e-02 -5.181e-02 -1.162e-01 -7.695e-02 -3.373e-01 -8.122e-02 -5.654e-02]\n",
      "    [ 4.521e-01 -1.723e-01  2.303e-01  7.887e-02  1.658e-01  1.412e-01  2.664e-01 -6.174e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-5.890e-02  4.119e-02 -3.505e-02 -2.589e-01  8.217e-02 -1.157e-01  2.644e-02  5.703e-02]\n",
      "    [ 2.146e-02  1.208e-02  3.648e-01 -1.272e-01  1.597e-02  2.292e-01  8.394e-02  1.681e-01]\n",
      "    [ 1.885e-01  2.023e-01  2.078e-01 -4.061e-01  1.107e-01  1.872e-01 -1.319e-01  1.565e-01]]\n",
      "\n",
      "   [[ 1.124e-02  7.816e-02  3.054e-01 -1.336e-03 -2.966e-01  4.472e-02  1.050e-01 -1.033e-01]\n",
      "    [-1.135e-01  2.452e-02  5.205e-02  1.172e-01 -1.265e-01  9.316e-02  1.680e-01 -4.363e-02]\n",
      "    [-2.106e-02  1.446e-01  2.764e-02 -4.116e-01 -1.832e-01 -3.105e-02  1.189e-01  6.775e-03]\n",
      "    [-5.890e-02  4.119e-02 -3.505e-02 -2.589e-01  8.217e-02 -1.157e-01  2.644e-02  5.703e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-9.179e-02 -2.857e-02 -2.935e-01  3.389e-02  9.435e-02 -1.924e-01 -1.216e-01  6.823e-02]\n",
      "    [-1.481e-01 -7.829e-02 -1.340e-01 -9.085e-03 -2.570e-01  8.878e-02  2.752e-01  5.365e-02]]\n",
      "\n",
      "   [[-1.666e-01 -1.671e-01 -1.588e-01 -1.704e-02 -2.006e-01  1.078e-02 -2.379e-01 -9.300e-02]\n",
      "    [ 3.197e-01 -1.071e-01 -1.580e-01 -1.369e-02 -5.149e-02 -1.904e-01 -1.500e-02  6.216e-03]\n",
      "    [-1.448e-01 -1.238e-01  1.194e-01  2.947e-02  1.581e-01  8.188e-02  1.878e-02  9.213e-02]\n",
      "    [ 2.146e-02  1.208e-02  3.648e-01 -1.272e-01  1.597e-02  2.292e-01  8.394e-02  1.681e-01]\n",
      "    [-9.179e-02 -2.857e-02 -2.935e-01  3.389e-02  9.435e-02 -1.924e-01 -1.216e-01  6.823e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 8.452e-02  2.243e-01  2.780e-01  5.516e-02 -3.498e-01  5.950e-02  6.636e-02 -9.257e-02]]\n",
      "\n",
      "   [[ 1.279e-01  1.663e-01  1.632e-01  6.332e-02 -7.766e-02  1.546e-01  3.405e-01 -1.409e-01]\n",
      "    [ 9.295e-02  1.022e-01 -1.402e-01  1.332e-01 -3.097e-02 -1.834e-01  1.292e-01  5.214e-02]\n",
      "    [ 1.077e-01 -8.543e-02  2.443e-01 -1.127e-02 -1.494e-01  3.389e-02 -2.631e-01 -1.716e-02]\n",
      "    [ 1.885e-01  2.023e-01  2.078e-01 -4.061e-01  1.107e-01  1.872e-01 -1.319e-01  1.565e-01]\n",
      "    [-1.481e-01 -7.829e-02 -1.340e-01 -9.085e-03 -2.570e-01  8.878e-02  2.752e-01  5.365e-02]\n",
      "    [ 8.452e-02  2.243e-01  2.780e-01  5.516e-02 -3.498e-01  5.950e-02  6.636e-02 -9.257e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-5.410e-02 -1.807e-01  2.981e-01 -1.322e-01 -3.944e-02 -1.685e-01  1.187e-01 -1.113e-01]\n",
      "    [ 3.806e-02  8.345e-02 -1.523e-01 -1.472e-01 -1.925e-03  1.353e-01  2.047e-01  1.892e-01]\n",
      "    [ 1.622e-01 -1.172e-01 -2.530e-01  8.995e-02  8.998e-02 -3.860e-02 -2.003e-01 -5.673e-02]\n",
      "    [-5.815e-02 -3.267e-01  3.544e-02  1.223e-01 -1.489e-02 -2.343e-01  8.980e-02 -1.297e-01]\n",
      "    [ 1.069e-01 -6.261e-02 -1.013e-01 -6.156e-02 -4.228e-02  1.816e-01 -1.968e-01 -1.069e-02]\n",
      "    [-1.313e-02  1.253e-03  1.386e-01 -1.885e-01 -3.040e-01  1.290e-02  6.611e-03 -1.651e-01]]\n",
      "\n",
      "   [[-5.410e-02 -1.807e-01  2.981e-01 -1.322e-01 -3.944e-02 -1.685e-01  1.187e-01 -1.113e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.379e-01 -3.914e-01 -2.349e-01  7.939e-02  1.992e-02 -1.966e-01  5.094e-02 -2.190e-01]\n",
      "    [-2.387e-01  2.745e-01 -1.128e-01 -9.879e-02 -5.323e-02 -1.280e-01 -1.702e-01  2.919e-01]\n",
      "    [ 6.521e-02 -2.713e-02  1.297e-01  1.382e-01 -6.125e-02  1.322e-01 -1.639e-01 -9.633e-02]\n",
      "    [-3.227e-02  1.410e-01  2.510e-02  9.150e-02 -8.368e-02  1.160e-01 -3.511e-01  8.366e-02]\n",
      "    [-1.930e-01  8.777e-03  4.504e-01  1.433e-01 -6.381e-02 -6.715e-03 -1.053e-01 -2.645e-01]]\n",
      "\n",
      "   [[ 3.806e-02  8.345e-02 -1.523e-01 -1.472e-01 -1.925e-03  1.353e-01  2.047e-01  1.892e-01]\n",
      "    [-2.379e-01 -3.914e-01 -2.349e-01  7.939e-02  1.992e-02 -1.966e-01  5.094e-02 -2.190e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.364e-01 -2.653e-01 -1.225e-01  2.555e-02  1.356e-01  1.009e-02  8.564e-02  3.082e-02]\n",
      "    [-3.370e-01  1.758e-02 -1.731e-01 -3.194e-01  1.495e-01 -1.675e-01 -4.875e-02 -7.881e-02]\n",
      "    [ 1.968e-01  1.202e-01 -2.364e-01  4.443e-02  1.567e-01  1.294e-01 -6.039e-02  1.274e-01]\n",
      "    [-2.825e-01  1.210e-01 -2.266e-01 -1.167e-01 -2.080e-01 -4.020e-02  1.578e-01  8.162e-02]]\n",
      "\n",
      "   [[ 1.622e-01 -1.172e-01 -2.530e-01  8.995e-02  8.998e-02 -3.860e-02 -2.003e-01 -5.673e-02]\n",
      "    [-2.387e-01  2.745e-01 -1.128e-01 -9.879e-02 -5.323e-02 -1.280e-01 -1.702e-01  2.919e-01]\n",
      "    [ 2.364e-01 -2.653e-01 -1.225e-01  2.555e-02  1.356e-01  1.009e-02  8.564e-02  3.082e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.649e-01 -7.515e-02 -2.842e-02  1.179e-01  7.018e-02  2.933e-02 -8.161e-02 -5.938e-02]\n",
      "    [ 8.030e-04 -1.621e-01  2.770e-03  1.789e-01 -3.283e-01  6.183e-02  8.241e-02 -1.205e-01]\n",
      "    [-4.483e-02  1.597e-01 -1.862e-01  3.503e-02  2.996e-02  1.645e-01 -2.852e-01  1.347e-01]]\n",
      "\n",
      "   [[-5.815e-02 -3.267e-01  3.544e-02  1.223e-01 -1.489e-02 -2.343e-01  8.980e-02 -1.297e-01]\n",
      "    [ 6.521e-02 -2.713e-02  1.297e-01  1.382e-01 -6.125e-02  1.322e-01 -1.639e-01 -9.633e-02]\n",
      "    [-3.370e-01  1.758e-02 -1.731e-01 -3.194e-01  1.495e-01 -1.675e-01 -4.875e-02 -7.881e-02]\n",
      "    [-3.649e-01 -7.515e-02 -2.842e-02  1.179e-01  7.018e-02  2.933e-02 -8.161e-02 -5.938e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.234e-01  3.240e-03  1.252e-02 -8.422e-02  1.721e-01 -1.642e-01  1.246e-02 -2.511e-03]\n",
      "    [ 4.495e-03  1.691e-01 -1.155e-01 -1.060e-01 -2.025e-01  4.342e-02  1.511e-01 -1.110e-01]]\n",
      "\n",
      "   [[ 1.069e-01 -6.261e-02 -1.013e-01 -6.156e-02 -4.228e-02  1.816e-01 -1.968e-01 -1.069e-02]\n",
      "    [-3.227e-02  1.410e-01  2.510e-02  9.150e-02 -8.368e-02  1.160e-01 -3.511e-01  8.366e-02]\n",
      "    [ 1.968e-01  1.202e-01 -2.364e-01  4.443e-02  1.567e-01  1.294e-01 -6.039e-02  1.274e-01]\n",
      "    [ 8.030e-04 -1.621e-01  2.770e-03  1.789e-01 -3.283e-01  6.183e-02  8.241e-02 -1.205e-01]\n",
      "    [ 1.234e-01  3.240e-03  1.252e-02 -8.422e-02  1.721e-01 -1.642e-01  1.246e-02 -2.511e-03]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.657e-02 -1.218e-01 -2.196e-02  2.119e-01 -1.569e-01  1.138e-01 -5.889e-02 -3.826e-02]]\n",
      "\n",
      "   [[-1.313e-02  1.253e-03  1.386e-01 -1.885e-01 -3.040e-01  1.290e-02  6.611e-03 -1.651e-01]\n",
      "    [-1.930e-01  8.777e-03  4.504e-01  1.433e-01 -6.381e-02 -6.715e-03 -1.053e-01 -2.645e-01]\n",
      "    [-2.825e-01  1.210e-01 -2.266e-01 -1.167e-01 -2.080e-01 -4.020e-02  1.578e-01  8.162e-02]\n",
      "    [-4.483e-02  1.597e-01 -1.862e-01  3.503e-02  2.996e-02  1.645e-01 -2.852e-01  1.347e-01]\n",
      "    [ 4.495e-03  1.691e-01 -1.155e-01 -1.060e-01 -2.025e-01  4.342e-02  1.511e-01 -1.110e-01]\n",
      "    [-3.657e-02 -1.218e-01 -2.196e-02  2.119e-01 -1.569e-01  1.138e-01 -5.889e-02 -3.826e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.069e-01  1.116e-01  2.500e-01  1.443e-01  1.433e-01 -1.070e-01 -1.265e-02 -1.400e-01]\n",
      "    [ 2.306e-01 -2.684e-03  2.076e-01 -3.367e-02 -3.760e-02  1.324e-01  7.842e-02 -8.111e-02]\n",
      "    [-9.702e-02 -5.843e-02  1.211e-02  8.044e-02 -3.808e-01 -2.644e-02  1.834e-01  4.081e-02]\n",
      "    [-4.331e-02 -1.510e-01  1.120e-01 -7.065e-02  1.485e-01  6.597e-02 -3.229e-02  1.029e-01]\n",
      "    [-1.489e-01 -1.899e-01 -1.141e-01 -6.311e-02 -9.348e-02 -3.053e-01  1.262e-01  5.855e-02]\n",
      "    [ 3.255e-02 -1.601e-01 -5.214e-02  2.679e-01 -2.370e-03 -1.141e-01 -2.667e-02 -3.741e-03]]\n",
      "\n",
      "   [[ 1.069e-01  1.116e-01  2.500e-01  1.443e-01  1.433e-01 -1.070e-01 -1.265e-02 -1.400e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.731e-01  8.537e-02  8.259e-03  7.538e-02  7.533e-02 -4.526e-02  1.396e-01  2.870e-01]\n",
      "    [ 1.726e-01  4.990e-03 -2.220e-01 -7.950e-02 -7.738e-02 -7.722e-02 -3.790e-02  2.633e-01]\n",
      "    [ 4.829e-02  2.401e-01  1.264e-01  2.318e-02 -1.118e-01  3.808e-02 -2.087e-01  4.649e-03]\n",
      "    [-1.080e-01  2.495e-02 -2.119e-01  1.887e-01 -1.437e-01  2.249e-01  6.495e-02 -2.240e-01]\n",
      "    [ 1.316e-01 -2.244e-03  9.872e-02 -2.747e-02 -1.129e-01 -1.454e-01 -1.096e-01  1.055e-01]]\n",
      "\n",
      "   [[ 2.306e-01 -2.684e-03  2.076e-01 -3.367e-02 -3.760e-02  1.324e-01  7.842e-02 -8.111e-02]\n",
      "    [-1.731e-01  8.537e-02  8.259e-03  7.538e-02  7.533e-02 -4.526e-02  1.396e-01  2.870e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.844e-01 -2.588e-01 -1.618e-01 -2.164e-01 -1.471e-01  4.212e-01 -1.196e-01  2.912e-01]\n",
      "    [ 2.019e-01 -1.309e-01  3.547e-01  3.009e-01 -2.741e-02 -3.298e-01  2.062e-01  2.182e-02]\n",
      "    [ 6.117e-02 -5.776e-02 -1.231e-01  1.154e-01  1.444e-01  3.568e-02  1.304e-01 -1.892e-01]\n",
      "    [-1.880e-01  6.558e-02 -2.867e-02 -8.659e-02 -8.186e-02 -4.174e-02 -2.270e-01 -1.073e-01]]\n",
      "\n",
      "   [[-9.702e-02 -5.843e-02  1.211e-02  8.044e-02 -3.808e-01 -2.644e-02  1.834e-01  4.081e-02]\n",
      "    [ 1.726e-01  4.990e-03 -2.220e-01 -7.950e-02 -7.738e-02 -7.722e-02 -3.790e-02  2.633e-01]\n",
      "    [-1.844e-01 -2.588e-01 -1.618e-01 -2.164e-01 -1.471e-01  4.212e-01 -1.196e-01  2.912e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.199e-01  6.121e-02 -1.295e-01  1.426e-01  3.341e-02 -3.304e-01 -3.010e-01 -1.234e-01]\n",
      "    [ 6.106e-02  6.941e-02  1.369e-01 -1.115e-01 -7.561e-02 -2.378e-02  1.947e-01  4.383e-02]\n",
      "    [ 2.142e-01 -3.654e-01 -3.322e-01  1.758e-02  3.467e-01 -1.714e-01  1.426e-01  1.680e-01]]\n",
      "\n",
      "   [[-4.331e-02 -1.510e-01  1.120e-01 -7.065e-02  1.485e-01  6.597e-02 -3.229e-02  1.029e-01]\n",
      "    [ 4.829e-02  2.401e-01  1.264e-01  2.318e-02 -1.118e-01  3.808e-02 -2.087e-01  4.649e-03]\n",
      "    [ 2.019e-01 -1.309e-01  3.547e-01  3.009e-01 -2.741e-02 -3.298e-01  2.062e-01  2.182e-02]\n",
      "    [ 1.199e-01  6.121e-02 -1.295e-01  1.426e-01  3.341e-02 -3.304e-01 -3.010e-01 -1.234e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.236e-01  4.780e-02 -5.118e-02  1.618e-01  3.342e-02 -8.466e-02 -1.373e-01  5.808e-02]\n",
      "    [ 6.519e-02  2.422e-03  1.825e-01  1.956e-01 -6.527e-02  1.543e-01 -7.356e-02  2.404e-02]]\n",
      "\n",
      "   [[-1.489e-01 -1.899e-01 -1.141e-01 -6.311e-02 -9.348e-02 -3.053e-01  1.262e-01  5.855e-02]\n",
      "    [-1.080e-01  2.495e-02 -2.119e-01  1.887e-01 -1.437e-01  2.249e-01  6.495e-02 -2.240e-01]\n",
      "    [ 6.117e-02 -5.776e-02 -1.231e-01  1.154e-01  1.444e-01  3.568e-02  1.304e-01 -1.892e-01]\n",
      "    [ 6.106e-02  6.941e-02  1.369e-01 -1.115e-01 -7.561e-02 -2.378e-02  1.947e-01  4.383e-02]\n",
      "    [-1.236e-01  4.780e-02 -5.118e-02  1.618e-01  3.342e-02 -8.466e-02 -1.373e-01  5.808e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.311e-01  1.071e-01 -3.095e-01 -1.427e-01 -5.201e-02  7.130e-02 -1.291e-01 -1.578e-01]]\n",
      "\n",
      "   [[ 3.255e-02 -1.601e-01 -5.214e-02  2.679e-01 -2.370e-03 -1.141e-01 -2.667e-02 -3.741e-03]\n",
      "    [ 1.316e-01 -2.244e-03  9.872e-02 -2.747e-02 -1.129e-01 -1.454e-01 -1.096e-01  1.055e-01]\n",
      "    [-1.880e-01  6.558e-02 -2.867e-02 -8.659e-02 -8.186e-02 -4.174e-02 -2.270e-01 -1.073e-01]\n",
      "    [ 2.142e-01 -3.654e-01 -3.322e-01  1.758e-02  3.467e-01 -1.714e-01  1.426e-01  1.680e-01]\n",
      "    [ 6.519e-02  2.422e-03  1.825e-01  1.956e-01 -6.527e-02  1.543e-01 -7.356e-02  2.404e-02]\n",
      "    [-2.311e-01  1.071e-01 -3.095e-01 -1.427e-01 -5.201e-02  7.130e-02 -1.291e-01 -1.578e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.160e-02  2.017e-01 -2.022e-01  7.016e-02 -2.380e-01 -1.004e-01  4.999e-02 -1.187e-01]\n",
      "    [ 1.846e-01 -8.001e-02  1.570e-01  4.373e-02  1.993e-01 -1.567e-01  1.426e-01 -8.227e-02]\n",
      "    [ 1.515e-01  1.146e-01  2.892e-03 -5.299e-02  2.075e-01  2.099e-01  7.812e-02 -3.411e-02]\n",
      "    [ 2.984e-02 -2.463e-01  3.606e-01 -1.286e-01 -1.610e-01 -2.425e-01  1.226e-01  1.404e-01]\n",
      "    [ 8.491e-02 -1.537e-01 -5.514e-02  4.007e-02  2.523e-01  1.353e-01  6.988e-02 -4.887e-02]\n",
      "    [ 1.895e-01  2.226e-01  1.601e-01 -6.387e-02  3.249e-01  1.087e-01  1.086e-02 -1.782e-01]]\n",
      "\n",
      "   [[-3.160e-02  2.017e-01 -2.022e-01  7.016e-02 -2.380e-01 -1.004e-01  4.999e-02 -1.187e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.916e-01 -5.672e-03  3.394e-01  8.357e-02  1.612e-01  2.713e-01 -2.432e-01 -6.353e-02]\n",
      "    [ 2.734e-02 -2.930e-02 -2.305e-01  2.250e-04  1.109e-01 -2.190e-01 -1.033e-01  1.070e-01]\n",
      "    [ 4.373e-02  7.323e-02 -2.452e-03  2.905e-02  1.473e-01 -2.405e-01 -4.710e-01 -3.327e-01]\n",
      "    [-1.127e-01  2.198e-01  3.231e-01 -1.210e-01 -2.122e-01 -8.469e-02  1.867e-01  7.362e-02]\n",
      "    [-5.638e-03  2.877e-01  1.264e-01 -6.131e-02  1.920e-01 -6.741e-03  1.844e-01  3.051e-02]]\n",
      "\n",
      "   [[ 1.846e-01 -8.001e-02  1.570e-01  4.373e-02  1.993e-01 -1.567e-01  1.426e-01 -8.227e-02]\n",
      "    [-2.916e-01 -5.672e-03  3.394e-01  8.357e-02  1.612e-01  2.713e-01 -2.432e-01 -6.353e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.284e-01 -1.672e-01 -9.528e-02 -2.497e-02  4.816e-02  4.062e-01 -1.976e-02  6.088e-02]\n",
      "    [-3.291e-01  3.270e-01  1.138e-01  1.924e-02  4.261e-02  1.351e-01  1.107e-01 -1.983e-01]\n",
      "    [-2.107e-01  3.793e-02  2.348e-01 -9.864e-02  4.145e-02 -2.633e-01  2.133e-01  2.508e-01]\n",
      "    [-1.566e-01  6.860e-02  4.949e-02 -1.563e-01  1.176e-01 -2.352e-01  1.971e-01 -2.073e-01]]\n",
      "\n",
      "   [[ 1.515e-01  1.146e-01  2.892e-03 -5.299e-02  2.075e-01  2.099e-01  7.812e-02 -3.411e-02]\n",
      "    [ 2.734e-02 -2.930e-02 -2.305e-01  2.250e-04  1.109e-01 -2.190e-01 -1.033e-01  1.070e-01]\n",
      "    [ 1.284e-01 -1.672e-01 -9.528e-02 -2.497e-02  4.816e-02  4.062e-01 -1.976e-02  6.088e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.657e-01  7.868e-02  2.530e-02  2.468e-01 -1.137e-01  2.274e-01  1.192e-01  1.003e-01]\n",
      "    [ 8.492e-02  5.330e-02 -1.699e-02  3.477e-01  3.563e-02 -3.276e-01 -8.472e-02 -8.024e-02]\n",
      "    [ 2.804e-01 -1.811e-01 -6.570e-02 -6.469e-02  8.236e-02 -2.347e-01 -5.040e-01 -3.778e-02]]\n",
      "\n",
      "   [[ 2.984e-02 -2.463e-01  3.606e-01 -1.286e-01 -1.610e-01 -2.425e-01  1.226e-01  1.404e-01]\n",
      "    [ 4.373e-02  7.323e-02 -2.452e-03  2.905e-02  1.473e-01 -2.405e-01 -4.710e-01 -3.327e-01]\n",
      "    [-3.291e-01  3.270e-01  1.138e-01  1.924e-02  4.261e-02  1.351e-01  1.107e-01 -1.983e-01]\n",
      "    [ 2.657e-01  7.868e-02  2.530e-02  2.468e-01 -1.137e-01  2.274e-01  1.192e-01  1.003e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.061e-01  2.444e-01 -1.101e-01 -1.511e-01 -9.133e-02 -8.078e-02 -2.268e-01 -5.427e-01]\n",
      "    [ 7.787e-02  1.057e-02 -2.626e-02 -8.868e-02  2.056e-01 -1.726e-01 -1.450e-01 -1.091e-01]]\n",
      "\n",
      "   [[ 8.491e-02 -1.537e-01 -5.514e-02  4.007e-02  2.523e-01  1.353e-01  6.988e-02 -4.887e-02]\n",
      "    [-1.127e-01  2.198e-01  3.231e-01 -1.210e-01 -2.122e-01 -8.469e-02  1.867e-01  7.362e-02]\n",
      "    [-2.107e-01  3.793e-02  2.348e-01 -9.864e-02  4.145e-02 -2.633e-01  2.133e-01  2.508e-01]\n",
      "    [ 8.492e-02  5.330e-02 -1.699e-02  3.477e-01  3.563e-02 -3.276e-01 -8.472e-02 -8.024e-02]\n",
      "    [ 1.061e-01  2.444e-01 -1.101e-01 -1.511e-01 -9.133e-02 -8.078e-02 -2.268e-01 -5.427e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.261e-02 -2.592e-02  8.219e-02  2.001e-02 -1.996e-01  1.002e-01  3.369e-01 -9.827e-03]]\n",
      "\n",
      "   [[ 1.895e-01  2.226e-01  1.601e-01 -6.387e-02  3.249e-01  1.087e-01  1.086e-02 -1.782e-01]\n",
      "    [-5.638e-03  2.877e-01  1.264e-01 -6.131e-02  1.920e-01 -6.741e-03  1.844e-01  3.051e-02]\n",
      "    [-1.566e-01  6.860e-02  4.949e-02 -1.563e-01  1.176e-01 -2.352e-01  1.971e-01 -2.073e-01]\n",
      "    [ 2.804e-01 -1.811e-01 -6.570e-02 -6.469e-02  8.236e-02 -2.347e-01 -5.040e-01 -3.778e-02]\n",
      "    [ 7.787e-02  1.057e-02 -2.626e-02 -8.868e-02  2.056e-01 -1.726e-01 -1.450e-01 -1.091e-01]\n",
      "    [-3.261e-02 -2.592e-02  8.219e-02  2.001e-02 -1.996e-01  1.002e-01  3.369e-01 -9.827e-03]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.935e-01  3.002e-02  4.270e-02  1.227e-01  2.481e-01 -1.527e-01  4.824e-02  1.616e-02]\n",
      "    [-9.115e-02 -2.156e-02 -6.353e-02 -1.924e-01 -1.339e-01 -9.104e-02  1.165e-01  2.425e-01]\n",
      "    [-3.906e-01 -3.487e-03  7.845e-02  1.293e-01  6.254e-02  2.145e-01  1.151e-01 -1.329e-01]\n",
      "    [ 2.618e-01 -2.611e-02  2.561e-01  1.359e-01 -7.628e-02 -2.360e-01 -9.292e-02 -9.449e-02]\n",
      "    [ 1.151e-01  2.887e-01  1.590e-01 -1.058e-01  1.518e-01 -1.019e-01  7.921e-02 -9.384e-02]\n",
      "    [-1.106e-01  2.211e-01 -5.560e-02 -2.623e-01 -7.644e-02  1.106e-01 -1.159e-01 -7.087e-02]]\n",
      "\n",
      "   [[-2.935e-01  3.002e-02  4.270e-02  1.227e-01  2.481e-01 -1.527e-01  4.824e-02  1.616e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-4.397e-02  2.354e-01  2.369e-02 -2.575e-01  7.313e-02  6.444e-02  1.798e-01 -1.321e-01]\n",
      "    [-8.697e-02 -1.098e-01 -1.034e-02 -5.405e-02  2.638e-01  2.277e-02 -1.064e-01  8.368e-02]\n",
      "    [-4.288e-02  2.700e-01  8.453e-02 -1.682e-01  1.098e-01 -4.349e-02 -4.568e-03 -1.046e-01]\n",
      "    [-4.497e-03  8.417e-02  6.960e-02 -2.590e-01  1.565e-01  2.059e-01  2.972e-01 -4.742e-02]\n",
      "    [ 1.649e-01  1.715e-01  2.277e-02 -2.191e-01 -2.250e-01  1.182e-01 -2.993e-02  3.395e-02]]\n",
      "\n",
      "   [[-9.115e-02 -2.156e-02 -6.353e-02 -1.924e-01 -1.339e-01 -9.104e-02  1.165e-01  2.425e-01]\n",
      "    [-4.397e-02  2.354e-01  2.369e-02 -2.575e-01  7.313e-02  6.444e-02  1.798e-01 -1.321e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.029e-01 -2.334e-01  3.424e-01  1.021e-02 -1.740e-01  5.390e-02 -1.408e-01  5.363e-02]\n",
      "    [-2.045e-01  1.275e-01 -1.114e-01  1.608e-01  1.221e-01  3.655e-02 -1.466e-01 -8.635e-02]\n",
      "    [-2.410e-01  3.478e-01 -8.977e-02 -5.360e-02 -2.539e-01  2.740e-01 -2.827e-01 -1.473e-02]\n",
      "    [ 4.787e-02 -1.784e-01 -1.686e-01  1.434e-01  7.756e-02 -1.705e-01  9.369e-02 -4.081e-02]]\n",
      "\n",
      "   [[-3.906e-01 -3.487e-03  7.845e-02  1.293e-01  6.254e-02  2.145e-01  1.151e-01 -1.329e-01]\n",
      "    [-8.697e-02 -1.098e-01 -1.034e-02 -5.405e-02  2.638e-01  2.277e-02 -1.064e-01  8.368e-02]\n",
      "    [ 1.029e-01 -2.334e-01  3.424e-01  1.021e-02 -1.740e-01  5.390e-02 -1.408e-01  5.363e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.182e-01 -7.487e-03  1.387e-01  8.857e-02  4.995e-02 -7.673e-02 -3.143e-01 -1.644e-01]\n",
      "    [ 1.047e-01  2.406e-01 -4.353e-02  1.418e-01  6.907e-02  2.103e-01  9.768e-02 -1.550e-01]\n",
      "    [-8.633e-02  4.386e-02 -2.826e-01  7.539e-02 -1.110e-02 -2.961e-02  1.312e-01  2.882e-01]]\n",
      "\n",
      "   [[ 2.618e-01 -2.611e-02  2.561e-01  1.359e-01 -7.628e-02 -2.360e-01 -9.292e-02 -9.449e-02]\n",
      "    [-4.288e-02  2.700e-01  8.453e-02 -1.682e-01  1.098e-01 -4.349e-02 -4.568e-03 -1.046e-01]\n",
      "    [-2.045e-01  1.275e-01 -1.114e-01  1.608e-01  1.221e-01  3.655e-02 -1.466e-01 -8.635e-02]\n",
      "    [-1.182e-01 -7.487e-03  1.387e-01  8.857e-02  4.995e-02 -7.673e-02 -3.143e-01 -1.644e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.432e-01 -2.783e-01  1.802e-03 -1.110e-02 -1.021e-01 -9.074e-02  2.615e-01 -1.839e-01]\n",
      "    [ 5.973e-02  3.002e-02  2.249e-02  3.690e-02 -1.267e-01 -1.054e-01 -2.688e-01  1.339e-02]]\n",
      "\n",
      "   [[ 1.151e-01  2.887e-01  1.590e-01 -1.058e-01  1.518e-01 -1.019e-01  7.921e-02 -9.384e-02]\n",
      "    [-4.497e-03  8.417e-02  6.960e-02 -2.590e-01  1.565e-01  2.059e-01  2.972e-01 -4.742e-02]\n",
      "    [-2.410e-01  3.478e-01 -8.977e-02 -5.360e-02 -2.539e-01  2.740e-01 -2.827e-01 -1.473e-02]\n",
      "    [ 1.047e-01  2.406e-01 -4.353e-02  1.418e-01  6.907e-02  2.103e-01  9.768e-02 -1.550e-01]\n",
      "    [-2.432e-01 -2.783e-01  1.802e-03 -1.110e-02 -1.021e-01 -9.074e-02  2.615e-01 -1.839e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.916e-01  7.507e-03 -2.585e-01 -1.938e-01  4.138e-02 -2.375e-01  1.375e-01  1.180e-01]]\n",
      "\n",
      "   [[-1.106e-01  2.211e-01 -5.560e-02 -2.623e-01 -7.644e-02  1.106e-01 -1.159e-01 -7.087e-02]\n",
      "    [ 1.649e-01  1.715e-01  2.277e-02 -2.191e-01 -2.250e-01  1.182e-01 -2.993e-02  3.395e-02]\n",
      "    [ 4.787e-02 -1.784e-01 -1.686e-01  1.434e-01  7.756e-02 -1.705e-01  9.369e-02 -4.081e-02]\n",
      "    [-8.633e-02  4.386e-02 -2.826e-01  7.539e-02 -1.110e-02 -2.961e-02  1.312e-01  2.882e-01]\n",
      "    [ 5.973e-02  3.002e-02  2.249e-02  3.690e-02 -1.267e-01 -1.054e-01 -2.688e-01  1.339e-02]\n",
      "    [-1.916e-01  7.507e-03 -2.585e-01 -1.938e-01  4.138e-02 -2.375e-01  1.375e-01  1.180e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 8.111e-02  4.564e-01  3.273e-02 -9.920e-02 -4.561e-02 -1.506e-01 -3.400e-02 -1.253e-02]\n",
      "    [ 2.907e-01 -1.172e-02  1.335e-02  5.360e-02  3.620e-02 -1.369e-01  1.824e-01 -1.208e-02]\n",
      "    [ 1.771e-03  9.020e-02 -3.039e-02 -1.996e-01 -1.200e-01  8.578e-02  4.667e-01  6.965e-02]\n",
      "    [ 7.274e-02 -2.493e-01 -1.840e-01  2.262e-01 -4.570e-02  1.067e-01  5.629e-02 -1.486e-01]\n",
      "    [-1.123e-01  6.101e-02 -1.373e-01  3.771e-01 -2.583e-02  2.338e-01 -1.462e-01 -1.054e-01]\n",
      "    [ 2.218e-01  5.651e-02  1.363e-01  4.510e-02 -5.015e-02  9.029e-03  1.190e-01 -2.942e-01]]\n",
      "\n",
      "   [[ 8.111e-02  4.564e-01  3.273e-02 -9.920e-02 -4.561e-02 -1.506e-01 -3.400e-02 -1.253e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-4.542e-02 -3.328e-02  3.076e-01 -1.162e-01  2.406e-01  1.685e-01  1.175e-01 -1.937e-01]\n",
      "    [-3.030e-01  3.533e-01  2.200e-01  5.423e-03  5.553e-02 -3.295e-01  1.387e-04 -2.810e-01]\n",
      "    [ 5.075e-02 -2.155e-01 -3.170e-01 -2.570e-01 -5.240e-02 -1.539e-01  3.406e-01 -1.078e-01]\n",
      "    [-3.512e-02  7.139e-02 -8.540e-02 -5.083e-01  6.208e-02  5.706e-02  1.891e-01 -7.264e-02]\n",
      "    [ 3.702e-02  2.254e-01 -2.368e-01 -3.132e-01 -5.213e-02  1.680e-01  1.823e-02  5.608e-03]]\n",
      "\n",
      "   [[ 2.907e-01 -1.172e-02  1.335e-02  5.360e-02  3.620e-02 -1.369e-01  1.824e-01 -1.208e-02]\n",
      "    [-4.542e-02 -3.328e-02  3.076e-01 -1.162e-01  2.406e-01  1.685e-01  1.175e-01 -1.937e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-9.232e-02  2.044e-01  5.424e-02  4.821e-02  1.799e-01 -6.556e-02  2.511e-01 -1.101e-01]\n",
      "    [-2.030e-02  1.053e-02 -1.854e-01  2.001e-01  2.919e-01 -3.366e-01  1.266e-01  6.517e-02]\n",
      "    [ 1.345e-01 -3.915e-02  8.727e-03 -1.883e-02  1.241e-01 -7.172e-02 -1.296e-01  2.626e-01]\n",
      "    [ 1.841e-02 -5.806e-02  1.143e-02  4.110e-02 -1.440e-01 -8.195e-02  1.372e-01  5.526e-02]]\n",
      "\n",
      "   [[ 1.771e-03  9.020e-02 -3.039e-02 -1.996e-01 -1.200e-01  8.578e-02  4.667e-01  6.965e-02]\n",
      "    [-3.030e-01  3.533e-01  2.200e-01  5.423e-03  5.553e-02 -3.295e-01  1.387e-04 -2.810e-01]\n",
      "    [-9.232e-02  2.044e-01  5.424e-02  4.821e-02  1.799e-01 -6.556e-02  2.511e-01 -1.101e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.042e-02 -1.805e-01 -1.477e-01  1.660e-02  1.442e-02 -6.214e-02  1.159e-01  1.926e-01]\n",
      "    [ 2.789e-01 -2.864e-01  7.467e-02 -2.847e-01  3.074e-01 -1.359e-01 -3.310e-01 -1.731e-01]\n",
      "    [-1.694e-01  2.947e-02  2.933e-01  1.396e-01 -1.511e-01 -1.063e-01  2.562e-01 -6.171e-02]]\n",
      "\n",
      "   [[ 7.274e-02 -2.493e-01 -1.840e-01  2.262e-01 -4.570e-02  1.067e-01  5.629e-02 -1.486e-01]\n",
      "    [ 5.075e-02 -2.155e-01 -3.170e-01 -2.570e-01 -5.240e-02 -1.539e-01  3.406e-01 -1.078e-01]\n",
      "    [-2.030e-02  1.053e-02 -1.854e-01  2.001e-01  2.919e-01 -3.366e-01  1.266e-01  6.517e-02]\n",
      "    [-1.042e-02 -1.805e-01 -1.477e-01  1.660e-02  1.442e-02 -6.214e-02  1.159e-01  1.926e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.871e-01  1.897e-02  7.177e-02  1.342e-01  8.730e-02 -9.726e-02  5.624e-02 -1.027e-01]\n",
      "    [ 2.632e-01  3.477e-02  4.442e-02  1.182e-01  4.753e-02  1.556e-02  4.465e-01  1.390e-01]]\n",
      "\n",
      "   [[-1.123e-01  6.101e-02 -1.373e-01  3.771e-01 -2.583e-02  2.338e-01 -1.462e-01 -1.054e-01]\n",
      "    [-3.512e-02  7.139e-02 -8.540e-02 -5.083e-01  6.208e-02  5.706e-02  1.891e-01 -7.264e-02]\n",
      "    [ 1.345e-01 -3.915e-02  8.727e-03 -1.883e-02  1.241e-01 -7.172e-02 -1.296e-01  2.626e-01]\n",
      "    [ 2.789e-01 -2.864e-01  7.467e-02 -2.847e-01  3.074e-01 -1.359e-01 -3.310e-01 -1.731e-01]\n",
      "    [-1.871e-01  1.897e-02  7.177e-02  1.342e-01  8.730e-02 -9.726e-02  5.624e-02 -1.027e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.580e-02  1.573e-01 -1.022e-01  2.359e-01  3.138e-03  1.958e-02 -1.846e-01 -7.506e-02]]\n",
      "\n",
      "   [[ 2.218e-01  5.651e-02  1.363e-01  4.510e-02 -5.015e-02  9.029e-03  1.190e-01 -2.942e-01]\n",
      "    [ 3.702e-02  2.254e-01 -2.368e-01 -3.132e-01 -5.213e-02  1.680e-01  1.823e-02  5.608e-03]\n",
      "    [ 1.841e-02 -5.806e-02  1.143e-02  4.110e-02 -1.440e-01 -8.195e-02  1.372e-01  5.526e-02]\n",
      "    [-1.694e-01  2.947e-02  2.933e-01  1.396e-01 -1.511e-01 -1.063e-01  2.562e-01 -6.171e-02]\n",
      "    [ 2.632e-01  3.477e-02  4.442e-02  1.182e-01  4.753e-02  1.556e-02  4.465e-01  1.390e-01]\n",
      "    [-3.580e-02  1.573e-01 -1.022e-01  2.359e-01  3.138e-03  1.958e-02 -1.846e-01 -7.506e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.925e-02 -1.747e-01 -1.128e-04 -1.197e-01  2.271e-01 -2.870e-02  8.791e-02  3.201e-02]\n",
      "    [ 1.424e-01 -3.637e-01 -1.821e-01  3.574e-02 -2.798e-01 -1.545e-01  7.446e-02  3.299e-01]\n",
      "    [-3.817e-01  2.663e-01 -1.793e-01  1.485e-01 -5.519e-03  1.243e-01  1.118e-01 -7.015e-03]\n",
      "    [-6.300e-02 -1.665e-01 -6.172e-02  3.671e-02  1.914e-01 -1.020e-01  4.212e-02  2.078e-01]\n",
      "    [-2.145e-01 -9.554e-02 -2.235e-01 -1.638e-01  8.389e-02  1.506e-01 -1.709e-01  1.498e-01]\n",
      "    [ 6.673e-02 -7.334e-02  2.555e-01  2.180e-01  5.233e-02 -1.560e-01 -2.177e-01 -6.046e-02]]\n",
      "\n",
      "   [[-2.925e-02 -1.747e-01 -1.128e-04 -1.197e-01  2.271e-01 -2.870e-02  8.791e-02  3.201e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.179e-01  8.632e-02  6.502e-03  2.312e-01 -7.109e-02  1.958e-01  5.009e-02 -1.208e-01]\n",
      "    [-1.070e-01 -9.058e-02  1.565e-01 -7.777e-03 -4.487e-01  4.560e-02  1.937e-01  1.529e-01]\n",
      "    [ 6.734e-02 -9.909e-02 -1.729e-01 -2.006e-01 -9.265e-02 -1.884e-01  2.952e-01  2.024e-01]\n",
      "    [-2.255e-01 -2.909e-02 -1.893e-01 -9.397e-02  3.120e-02 -2.801e-01  8.016e-02 -1.209e-01]\n",
      "    [-1.191e-01 -1.873e-01  1.390e-01  7.490e-02 -4.031e-02 -9.374e-03 -8.400e-03  3.247e-01]]\n",
      "\n",
      "   [[ 1.424e-01 -3.637e-01 -1.821e-01  3.574e-02 -2.798e-01 -1.545e-01  7.446e-02  3.299e-01]\n",
      "    [ 2.179e-01  8.632e-02  6.502e-03  2.312e-01 -7.109e-02  1.958e-01  5.009e-02 -1.208e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.853e-01 -2.422e-01  3.614e-01 -1.038e-01  1.831e-01 -3.237e-02  1.660e-01  2.859e-02]\n",
      "    [ 2.874e-01 -1.299e-02 -2.105e-01 -2.282e-01 -1.318e-01 -2.342e-02  1.334e-01  7.596e-02]\n",
      "    [-1.396e-01  9.562e-02  1.509e-01 -1.816e-01  8.624e-02 -1.168e-01 -1.495e-01  3.070e-01]\n",
      "    [ 8.960e-02 -3.437e-02 -4.437e-02  7.573e-02  1.625e-01  7.404e-04 -8.506e-02 -9.310e-02]]\n",
      "\n",
      "   [[-3.817e-01  2.663e-01 -1.793e-01  1.485e-01 -5.519e-03  1.243e-01  1.118e-01 -7.015e-03]\n",
      "    [-1.070e-01 -9.058e-02  1.565e-01 -7.777e-03 -4.487e-01  4.560e-02  1.937e-01  1.529e-01]\n",
      "    [-1.853e-01 -2.422e-01  3.614e-01 -1.038e-01  1.831e-01 -3.237e-02  1.660e-01  2.859e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.337e-01 -9.147e-03 -3.233e-01  7.338e-02  9.364e-02 -1.340e-02  2.937e-02 -4.658e-02]\n",
      "    [ 2.303e-02 -2.688e-01  1.194e-01  1.305e-01  5.280e-02  2.241e-01  1.122e-01  9.595e-02]\n",
      "    [ 1.330e-01  1.176e-01  8.441e-02  2.588e-01 -7.786e-02 -1.266e-01 -1.283e-01  6.895e-02]]\n",
      "\n",
      "   [[-6.300e-02 -1.665e-01 -6.172e-02  3.671e-02  1.914e-01 -1.020e-01  4.212e-02  2.078e-01]\n",
      "    [ 6.734e-02 -9.909e-02 -1.729e-01 -2.006e-01 -9.265e-02 -1.884e-01  2.952e-01  2.024e-01]\n",
      "    [ 2.874e-01 -1.299e-02 -2.105e-01 -2.282e-01 -1.318e-01 -2.342e-02  1.334e-01  7.596e-02]\n",
      "    [ 1.337e-01 -9.147e-03 -3.233e-01  7.338e-02  9.364e-02 -1.340e-02  2.937e-02 -4.658e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 3.365e-02  1.903e-01 -9.291e-02 -5.555e-02  1.421e-01 -3.517e-03  2.292e-01 -1.189e-01]\n",
      "    [-3.162e-02  4.166e-01  1.485e-01  1.902e-01  1.458e-01 -1.959e-02  9.997e-02  9.494e-02]]\n",
      "\n",
      "   [[-2.145e-01 -9.554e-02 -2.235e-01 -1.638e-01  8.389e-02  1.506e-01 -1.709e-01  1.498e-01]\n",
      "    [-2.255e-01 -2.909e-02 -1.893e-01 -9.397e-02  3.120e-02 -2.801e-01  8.016e-02 -1.209e-01]\n",
      "    [-1.396e-01  9.562e-02  1.509e-01 -1.816e-01  8.624e-02 -1.168e-01 -1.495e-01  3.070e-01]\n",
      "    [ 2.303e-02 -2.688e-01  1.194e-01  1.305e-01  5.280e-02  2.241e-01  1.122e-01  9.595e-02]\n",
      "    [ 3.365e-02  1.903e-01 -9.291e-02 -5.555e-02  1.421e-01 -3.517e-03  2.292e-01 -1.189e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.330e-01  4.390e-02 -9.437e-02 -1.363e-01 -2.197e-02  4.877e-01  2.730e-01 -1.755e-01]]\n",
      "\n",
      "   [[ 6.673e-02 -7.334e-02  2.555e-01  2.180e-01  5.233e-02 -1.560e-01 -2.177e-01 -6.046e-02]\n",
      "    [-1.191e-01 -1.873e-01  1.390e-01  7.490e-02 -4.031e-02 -9.374e-03 -8.400e-03  3.247e-01]\n",
      "    [ 8.960e-02 -3.437e-02 -4.437e-02  7.573e-02  1.625e-01  7.404e-04 -8.506e-02 -9.310e-02]\n",
      "    [ 1.330e-01  1.176e-01  8.441e-02  2.588e-01 -7.786e-02 -1.266e-01 -1.283e-01  6.895e-02]\n",
      "    [-3.162e-02  4.166e-01  1.485e-01  1.902e-01  1.458e-01 -1.959e-02  9.997e-02  9.494e-02]\n",
      "    [ 1.330e-01  4.390e-02 -9.437e-02 -1.363e-01 -2.197e-02  4.877e-01  2.730e-01 -1.755e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.670e-01 -2.178e-01 -6.360e-02 -5.445e-02  8.095e-02  3.810e-02 -2.497e-01  4.142e-01]\n",
      "    [ 2.315e-01  3.365e-01 -3.408e-02 -2.423e-01  4.184e-02  2.415e-01  6.865e-02 -2.299e-01]\n",
      "    [-1.026e-01 -1.543e-01  5.871e-02  1.998e-01  3.331e-01 -1.379e-01 -2.773e-01 -1.680e-01]\n",
      "    [ 5.443e-02 -1.531e-01  1.722e-02  1.272e-01  8.957e-03 -2.231e-01  3.060e-02 -1.033e-01]\n",
      "    [-9.311e-03  4.827e-02  1.813e-01  1.001e-01 -2.988e-02 -1.861e-01 -2.707e-01  1.510e-01]\n",
      "    [-1.692e-02 -1.715e-02 -6.067e-02  7.328e-02 -2.569e-01 -3.630e-01 -1.534e-01 -2.295e-01]]\n",
      "\n",
      "   [[ 1.670e-01 -2.178e-01 -6.360e-02 -5.445e-02  8.095e-02  3.810e-02 -2.497e-01  4.142e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-6.698e-02 -1.431e-01  9.091e-02 -5.080e-04  1.539e-01  3.022e-01 -1.365e-01 -5.768e-02]\n",
      "    [-2.391e-01  8.017e-02 -1.684e-01  2.251e-01  1.120e-01  1.673e-02  2.177e-01 -2.477e-02]\n",
      "    [-1.338e-02  4.128e-03 -1.088e-01 -7.455e-02 -9.827e-02 -6.018e-02  3.131e-01 -3.191e-02]\n",
      "    [ 8.459e-02 -2.357e-02 -8.353e-02  4.609e-03  8.631e-02 -1.218e-01  6.100e-02  5.442e-01]\n",
      "    [-6.485e-02  2.254e-01 -2.258e-01  2.342e-02  1.638e-01 -1.326e-01 -2.633e-01 -6.923e-02]]\n",
      "\n",
      "   [[ 2.315e-01  3.365e-01 -3.408e-02 -2.423e-01  4.184e-02  2.415e-01  6.865e-02 -2.299e-01]\n",
      "    [-6.698e-02 -1.431e-01  9.091e-02 -5.080e-04  1.539e-01  3.022e-01 -1.365e-01 -5.768e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.195e-02  8.334e-02  3.227e-01 -2.750e-02  9.170e-02  2.404e-02  7.385e-02 -7.944e-02]\n",
      "    [-1.038e-02 -1.084e-01 -1.908e-01  2.777e-02 -1.559e-01 -2.369e-01  8.921e-03  7.793e-02]\n",
      "    [-1.112e-01  8.651e-02  2.411e-01  1.222e-01  8.451e-03  1.154e-01  2.398e-01  1.084e-01]\n",
      "    [ 2.415e-01 -1.538e-01  1.265e-01 -1.176e-02 -6.074e-02 -1.656e-01  1.579e-01 -1.344e-01]]\n",
      "\n",
      "   [[-1.026e-01 -1.543e-01  5.871e-02  1.998e-01  3.331e-01 -1.379e-01 -2.773e-01 -1.680e-01]\n",
      "    [-2.391e-01  8.017e-02 -1.684e-01  2.251e-01  1.120e-01  1.673e-02  2.177e-01 -2.477e-02]\n",
      "    [ 1.195e-02  8.334e-02  3.227e-01 -2.750e-02  9.170e-02  2.404e-02  7.385e-02 -7.944e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.185e-01  8.301e-02 -1.369e-01 -1.657e-01 -1.014e-01  3.616e-01  9.072e-02 -7.640e-02]\n",
      "    [ 2.102e-01  1.173e-01  1.797e-01  5.981e-03 -8.761e-02  2.265e-01  7.890e-02 -6.849e-02]\n",
      "    [-1.190e-01  3.051e-01 -1.589e-01  2.026e-01 -1.555e-01  1.753e-02 -1.099e-01  9.467e-02]]\n",
      "\n",
      "   [[ 5.443e-02 -1.531e-01  1.722e-02  1.272e-01  8.957e-03 -2.231e-01  3.060e-02 -1.033e-01]\n",
      "    [-1.338e-02  4.128e-03 -1.088e-01 -7.455e-02 -9.827e-02 -6.018e-02  3.131e-01 -3.191e-02]\n",
      "    [-1.038e-02 -1.084e-01 -1.908e-01  2.777e-02 -1.559e-01 -2.369e-01  8.921e-03  7.793e-02]\n",
      "    [ 1.185e-01  8.301e-02 -1.369e-01 -1.657e-01 -1.014e-01  3.616e-01  9.072e-02 -7.640e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-4.260e-01  2.376e-01  3.259e-01 -5.504e-02  2.070e-01  3.101e-01  6.235e-02  7.733e-02]\n",
      "    [ 1.042e-01  7.421e-02  3.729e-01  8.907e-02 -1.804e-01  3.334e-01 -1.888e-02 -8.148e-03]]\n",
      "\n",
      "   [[-9.311e-03  4.827e-02  1.813e-01  1.001e-01 -2.988e-02 -1.861e-01 -2.707e-01  1.510e-01]\n",
      "    [ 8.459e-02 -2.357e-02 -8.353e-02  4.609e-03  8.631e-02 -1.218e-01  6.100e-02  5.442e-01]\n",
      "    [-1.112e-01  8.651e-02  2.411e-01  1.222e-01  8.451e-03  1.154e-01  2.398e-01  1.084e-01]\n",
      "    [ 2.102e-01  1.173e-01  1.797e-01  5.981e-03 -8.761e-02  2.265e-01  7.890e-02 -6.849e-02]\n",
      "    [-4.260e-01  2.376e-01  3.259e-01 -5.504e-02  2.070e-01  3.101e-01  6.235e-02  7.733e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.939e-01  2.751e-02  9.883e-02  2.800e-01 -3.629e-01  3.124e-02  5.000e-02  1.407e-01]]\n",
      "\n",
      "   [[-1.692e-02 -1.715e-02 -6.067e-02  7.328e-02 -2.569e-01 -3.630e-01 -1.534e-01 -2.295e-01]\n",
      "    [-6.485e-02  2.254e-01 -2.258e-01  2.342e-02  1.638e-01 -1.326e-01 -2.633e-01 -6.923e-02]\n",
      "    [ 2.415e-01 -1.538e-01  1.265e-01 -1.176e-02 -6.074e-02 -1.656e-01  1.579e-01 -1.344e-01]\n",
      "    [-1.190e-01  3.051e-01 -1.589e-01  2.026e-01 -1.555e-01  1.753e-02 -1.099e-01  9.467e-02]\n",
      "    [ 1.042e-01  7.421e-02  3.729e-01  8.907e-02 -1.804e-01  3.334e-01 -1.888e-02 -8.148e-03]\n",
      "    [-1.939e-01  2.751e-02  9.883e-02  2.800e-01 -3.629e-01  3.124e-02  5.000e-02  1.407e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.833e-01  2.556e-01 -1.206e-01 -4.175e-02  8.999e-02 -3.027e-01 -1.388e-01 -2.018e-02]\n",
      "    [ 4.306e-02  1.441e-01 -5.779e-02  1.434e-01  2.959e-01 -4.443e-02 -2.106e-01 -1.555e-01]\n",
      "    [-2.119e-01 -2.128e-01  1.204e-01 -3.774e-02 -5.265e-02 -4.457e-02 -1.122e-01 -1.369e-01]\n",
      "    [-5.986e-02  8.029e-02 -2.703e-02  9.666e-02 -8.684e-02  1.236e-01  6.542e-02  1.716e-01]\n",
      "    [ 1.149e-01  5.471e-02  5.284e-02  1.346e-01  1.678e-01 -2.268e-02 -8.653e-02  3.039e-01]\n",
      "    [-6.559e-02  3.258e-01 -2.444e-02 -1.165e-01 -7.136e-02 -1.933e-01 -4.546e-02 -2.943e-01]]\n",
      "\n",
      "   [[-3.833e-01  2.556e-01 -1.206e-01 -4.175e-02  8.999e-02 -3.027e-01 -1.388e-01 -2.018e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.786e-01  2.915e-01 -3.683e-03 -1.697e-01  1.336e-01 -1.950e-01  1.509e-01 -1.910e-01]\n",
      "    [-1.601e-01 -1.302e-02 -5.214e-02  1.836e-01 -3.605e-02  5.758e-02 -2.060e-01  2.015e-01]\n",
      "    [-2.238e-01 -1.175e-01 -5.247e-02  6.021e-02  3.209e-02 -8.071e-02 -1.743e-01 -6.154e-02]\n",
      "    [-1.374e-01 -2.017e-01 -1.481e-01 -4.115e-01  2.638e-01 -4.816e-02 -2.848e-01 -2.711e-02]\n",
      "    [-2.277e-02 -5.077e-03  5.819e-01  2.760e-02 -1.314e-01 -9.018e-02 -8.930e-02  1.665e-02]]\n",
      "\n",
      "   [[ 4.306e-02  1.441e-01 -5.779e-02  1.434e-01  2.959e-01 -4.443e-02 -2.106e-01 -1.555e-01]\n",
      "    [-1.786e-01  2.915e-01 -3.683e-03 -1.697e-01  1.336e-01 -1.950e-01  1.509e-01 -1.910e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-8.008e-02 -1.709e-01 -1.393e-02 -5.133e-02 -2.855e-02 -1.819e-01  1.387e-01 -1.164e-01]\n",
      "    [ 8.423e-02 -1.140e-01 -1.537e-01  2.891e-01  2.896e-01 -7.297e-02 -1.380e-01  1.843e-01]\n",
      "    [-2.691e-01 -2.524e-01 -8.234e-02 -4.442e-02  6.124e-03 -2.006e-01 -3.402e-01  2.054e-01]\n",
      "    [-8.567e-02  1.244e-01  1.777e-01  8.419e-02 -9.956e-02  6.806e-02 -1.908e-01  1.206e-02]]\n",
      "\n",
      "   [[-2.119e-01 -2.128e-01  1.204e-01 -3.774e-02 -5.265e-02 -4.457e-02 -1.122e-01 -1.369e-01]\n",
      "    [-1.601e-01 -1.302e-02 -5.214e-02  1.836e-01 -3.605e-02  5.758e-02 -2.060e-01  2.015e-01]\n",
      "    [-8.008e-02 -1.709e-01 -1.393e-02 -5.133e-02 -2.855e-02 -1.819e-01  1.387e-01 -1.164e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 7.025e-02  2.406e-02  1.471e-01 -6.040e-02  1.616e-01 -1.239e-01  2.859e-01  6.651e-02]\n",
      "    [ 6.591e-02 -9.314e-02  1.578e-03 -3.173e-01 -6.725e-02 -6.994e-02 -7.534e-03  5.695e-02]\n",
      "    [-6.152e-02 -2.355e-01  8.210e-02  4.082e-02  1.009e-01 -2.452e-02 -6.479e-02  2.631e-01]]\n",
      "\n",
      "   [[-5.986e-02  8.029e-02 -2.703e-02  9.666e-02 -8.684e-02  1.236e-01  6.542e-02  1.716e-01]\n",
      "    [-2.238e-01 -1.175e-01 -5.247e-02  6.021e-02  3.209e-02 -8.071e-02 -1.743e-01 -6.154e-02]\n",
      "    [ 8.423e-02 -1.140e-01 -1.537e-01  2.891e-01  2.896e-01 -7.297e-02 -1.380e-01  1.843e-01]\n",
      "    [ 7.025e-02  2.406e-02  1.471e-01 -6.040e-02  1.616e-01 -1.239e-01  2.859e-01  6.651e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.339e-01  2.797e-01 -3.096e-03  5.929e-02 -9.273e-02  1.544e-01  1.662e-01  1.816e-02]\n",
      "    [ 8.079e-02  1.709e-01  4.490e-02  2.788e-01 -3.077e-02  2.665e-01  2.565e-01 -4.831e-03]]\n",
      "\n",
      "   [[ 1.149e-01  5.471e-02  5.284e-02  1.346e-01  1.678e-01 -2.268e-02 -8.653e-02  3.039e-01]\n",
      "    [-1.374e-01 -2.017e-01 -1.481e-01 -4.115e-01  2.638e-01 -4.816e-02 -2.848e-01 -2.711e-02]\n",
      "    [-2.691e-01 -2.524e-01 -8.234e-02 -4.442e-02  6.124e-03 -2.006e-01 -3.402e-01  2.054e-01]\n",
      "    [ 6.591e-02 -9.314e-02  1.578e-03 -3.173e-01 -6.725e-02 -6.994e-02 -7.534e-03  5.695e-02]\n",
      "    [-1.339e-01  2.797e-01 -3.096e-03  5.929e-02 -9.273e-02  1.544e-01  1.662e-01  1.816e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.865e-01  7.866e-02 -4.859e-02  2.069e-01  1.474e-01  1.574e-01 -3.406e-02  5.607e-02]]\n",
      "\n",
      "   [[-6.559e-02  3.258e-01 -2.444e-02 -1.165e-01 -7.136e-02 -1.933e-01 -4.546e-02 -2.943e-01]\n",
      "    [-2.277e-02 -5.077e-03  5.819e-01  2.760e-02 -1.314e-01 -9.018e-02 -8.930e-02  1.665e-02]\n",
      "    [-8.567e-02  1.244e-01  1.777e-01  8.419e-02 -9.956e-02  6.806e-02 -1.908e-01  1.206e-02]\n",
      "    [-6.152e-02 -2.355e-01  8.210e-02  4.082e-02  1.009e-01 -2.452e-02 -6.479e-02  2.631e-01]\n",
      "    [ 8.079e-02  1.709e-01  4.490e-02  2.788e-01 -3.077e-02  2.665e-01  2.565e-01 -4.831e-03]\n",
      "    [-1.865e-01  7.866e-02 -4.859e-02  2.069e-01  1.474e-01  1.574e-01 -3.406e-02  5.607e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.864e-01 -4.155e-02 -2.578e-01 -9.272e-03 -3.616e-01  4.548e-02  1.630e-01 -1.037e-02]\n",
      "    [ 8.138e-02  2.048e-01 -2.598e-01  1.405e-01 -9.402e-02  1.922e-02 -3.240e-02  1.879e-01]\n",
      "    [-4.890e-02 -5.037e-02  1.047e-01  1.618e-01  1.342e-01 -9.776e-02  9.874e-02 -1.455e-02]\n",
      "    [-1.324e-01  1.872e-02 -8.609e-02 -1.088e-01 -3.365e-01 -1.067e-02 -1.854e-01 -4.118e-02]\n",
      "    [ 1.741e-02 -6.952e-02 -1.246e-01  8.108e-02 -2.074e-01  6.453e-02 -7.328e-02 -1.656e-01]\n",
      "    [ 4.614e-02 -1.087e-01 -2.043e-01  3.006e-02 -8.246e-02 -2.183e-01 -9.932e-02  1.916e-01]]\n",
      "\n",
      "   [[-1.864e-01 -4.155e-02 -2.578e-01 -9.272e-03 -3.616e-01  4.548e-02  1.630e-01 -1.037e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.376e-01 -2.724e-02 -6.230e-02 -3.166e-02 -1.153e-01  5.163e-03  1.377e-02 -2.576e-02]\n",
      "    [ 2.547e-01  1.537e-02 -2.488e-04  9.567e-04 -1.979e-02  8.483e-02  2.578e-01  5.668e-02]\n",
      "    [-2.783e-01  3.654e-02 -1.589e-01 -6.541e-03  1.651e-01 -3.029e-02 -8.689e-03  2.333e-01]\n",
      "    [-2.410e-01  8.389e-02  1.938e-01 -6.451e-02 -1.829e-01 -4.460e-02  1.350e-01  1.691e-01]\n",
      "    [-6.826e-02 -1.094e-01 -2.505e-01 -1.251e-01  1.220e-01 -1.268e-01 -1.733e-01  4.860e-02]]\n",
      "\n",
      "   [[ 8.138e-02  2.048e-01 -2.598e-01  1.405e-01 -9.402e-02  1.922e-02 -3.240e-02  1.879e-01]\n",
      "    [ 1.376e-01 -2.724e-02 -6.230e-02 -3.166e-02 -1.153e-01  5.163e-03  1.377e-02 -2.576e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 4.138e-01 -1.071e-01  3.863e-02 -3.047e-01  1.304e-01  1.017e-01  1.045e-01 -3.860e-01]\n",
      "    [-2.318e-01 -1.076e-02  2.214e-01  1.013e-01 -9.438e-02 -1.053e-01 -1.437e-01  1.770e-01]\n",
      "    [-5.306e-02 -1.151e-01  3.074e-01  3.964e-01  2.736e-01  3.159e-01 -2.863e-02 -1.250e-01]\n",
      "    [ 1.025e-02  1.300e-01  2.587e-01  1.526e-01  5.218e-02  3.563e-01 -1.188e-01  2.769e-02]]\n",
      "\n",
      "   [[-4.890e-02 -5.037e-02  1.047e-01  1.618e-01  1.342e-01 -9.776e-02  9.874e-02 -1.455e-02]\n",
      "    [ 2.547e-01  1.537e-02 -2.488e-04  9.567e-04 -1.979e-02  8.483e-02  2.578e-01  5.668e-02]\n",
      "    [ 4.138e-01 -1.071e-01  3.863e-02 -3.047e-01  1.304e-01  1.017e-01  1.045e-01 -3.860e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.412e-01  2.294e-01 -1.912e-01 -4.777e-01 -9.321e-03 -1.970e-01  1.734e-01  7.455e-02]\n",
      "    [-2.711e-01 -2.643e-02  1.739e-01  1.710e-02 -6.889e-02  5.247e-02  6.268e-02  7.704e-02]\n",
      "    [-4.906e-02 -1.568e-02  9.579e-02  1.070e-01  6.481e-02  1.408e-01 -1.296e-01 -2.925e-01]]\n",
      "\n",
      "   [[-1.324e-01  1.872e-02 -8.609e-02 -1.088e-01 -3.365e-01 -1.067e-02 -1.854e-01 -4.118e-02]\n",
      "    [-2.783e-01  3.654e-02 -1.589e-01 -6.541e-03  1.651e-01 -3.029e-02 -8.689e-03  2.333e-01]\n",
      "    [-2.318e-01 -1.076e-02  2.214e-01  1.013e-01 -9.438e-02 -1.053e-01 -1.437e-01  1.770e-01]\n",
      "    [-2.412e-01  2.294e-01 -1.912e-01 -4.777e-01 -9.321e-03 -1.970e-01  1.734e-01  7.455e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 9.555e-02  2.218e-01  2.144e-01 -6.460e-02 -1.332e-01  2.597e-01  1.855e-01  8.850e-02]\n",
      "    [-1.245e-01  9.688e-02  2.419e-01 -4.643e-02 -4.951e-02  1.914e-01 -5.547e-02  2.011e-01]]\n",
      "\n",
      "   [[ 1.741e-02 -6.952e-02 -1.246e-01  8.108e-02 -2.074e-01  6.453e-02 -7.328e-02 -1.656e-01]\n",
      "    [-2.410e-01  8.389e-02  1.938e-01 -6.451e-02 -1.829e-01 -4.460e-02  1.350e-01  1.691e-01]\n",
      "    [-5.306e-02 -1.151e-01  3.074e-01  3.964e-01  2.736e-01  3.159e-01 -2.863e-02 -1.250e-01]\n",
      "    [-2.711e-01 -2.643e-02  1.739e-01  1.710e-02 -6.889e-02  5.247e-02  6.268e-02  7.704e-02]\n",
      "    [ 9.555e-02  2.218e-01  2.144e-01 -6.460e-02 -1.332e-01  2.597e-01  1.855e-01  8.850e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.037e-01  2.079e-01  5.862e-02 -1.038e-01 -9.238e-02  3.287e-01 -2.560e-01 -1.668e-02]]\n",
      "\n",
      "   [[ 4.614e-02 -1.087e-01 -2.043e-01  3.006e-02 -8.246e-02 -2.183e-01 -9.932e-02  1.916e-01]\n",
      "    [-6.826e-02 -1.094e-01 -2.505e-01 -1.251e-01  1.220e-01 -1.268e-01 -1.733e-01  4.860e-02]\n",
      "    [ 1.025e-02  1.300e-01  2.587e-01  1.526e-01  5.218e-02  3.563e-01 -1.188e-01  2.769e-02]\n",
      "    [-4.906e-02 -1.568e-02  9.579e-02  1.070e-01  6.481e-02  1.408e-01 -1.296e-01 -2.925e-01]\n",
      "    [-1.245e-01  9.688e-02  2.419e-01 -4.643e-02 -4.951e-02  1.914e-01 -5.547e-02  2.011e-01]\n",
      "    [ 1.037e-01  2.079e-01  5.862e-02 -1.038e-01 -9.238e-02  3.287e-01 -2.560e-01 -1.668e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.106e-02 -1.037e-01  2.451e-02  1.408e-01  1.857e-01  6.767e-02 -1.090e-01 -2.213e-01]\n",
      "    [-2.500e-02 -2.173e-01 -9.150e-02  1.393e-01  2.288e-01 -1.468e-02 -9.523e-02 -3.220e-01]\n",
      "    [-6.323e-02 -1.448e-01  1.885e-01  1.533e-01 -3.456e-02  9.406e-02  7.562e-02  1.538e-01]\n",
      "    [ 2.995e-02 -2.999e-02 -1.760e-01  2.144e-01  6.655e-02 -2.458e-01 -1.913e-01  1.247e-01]\n",
      "    [ 2.354e-02  1.045e-01 -3.693e-02 -7.979e-02 -1.946e-01  6.906e-02  2.410e-01  3.505e-02]\n",
      "    [-1.671e-01  1.113e-01  2.985e-01  1.401e-02  1.867e-01  1.128e-01 -1.932e-01  2.767e-02]]\n",
      "\n",
      "   [[-3.106e-02 -1.037e-01  2.451e-02  1.408e-01  1.857e-01  6.767e-02 -1.090e-01 -2.213e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-9.507e-02 -1.804e-01 -2.650e-02 -5.906e-02  3.727e-03  1.664e-01 -7.663e-02 -6.130e-02]\n",
      "    [ 2.454e-02 -2.763e-01 -8.181e-02  2.635e-01  1.159e-01 -9.436e-02 -1.201e-01 -3.418e-01]\n",
      "    [-2.317e-01  2.101e-01 -1.942e-01 -1.456e-01  1.529e-01  1.416e-01  1.019e-01 -6.160e-02]\n",
      "    [-2.082e-01  8.179e-02 -6.863e-02  1.431e-01 -1.392e-01 -1.567e-01  2.144e-01  7.808e-02]\n",
      "    [-3.712e-02 -8.282e-02  1.370e-01  6.717e-02 -3.597e-02 -1.482e-01  1.728e-01  4.237e-02]]\n",
      "\n",
      "   [[-2.500e-02 -2.173e-01 -9.150e-02  1.393e-01  2.288e-01 -1.468e-02 -9.523e-02 -3.220e-01]\n",
      "    [-9.507e-02 -1.804e-01 -2.650e-02 -5.906e-02  3.727e-03  1.664e-01 -7.663e-02 -6.130e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-7.073e-02  3.433e-01 -1.053e-01  1.611e-01  7.572e-02  3.897e-02  7.011e-02  1.212e-01]\n",
      "    [ 2.644e-01 -1.390e-01  2.762e-02 -2.597e-01  4.218e-02  2.032e-02  1.882e-01 -1.379e-01]\n",
      "    [-4.453e-02 -1.418e-01  5.761e-04 -1.431e-01 -1.872e-01  5.248e-02  2.010e-03 -1.975e-01]\n",
      "    [ 1.008e-01 -4.552e-02 -6.351e-02 -1.844e-01  3.621e-01 -8.148e-02  1.051e-01 -6.256e-02]]\n",
      "\n",
      "   [[-6.323e-02 -1.448e-01  1.885e-01  1.533e-01 -3.456e-02  9.406e-02  7.562e-02  1.538e-01]\n",
      "    [ 2.454e-02 -2.763e-01 -8.181e-02  2.635e-01  1.159e-01 -9.436e-02 -1.201e-01 -3.418e-01]\n",
      "    [-7.073e-02  3.433e-01 -1.053e-01  1.611e-01  7.572e-02  3.897e-02  7.011e-02  1.212e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 9.261e-03  1.704e-01 -1.896e-01 -3.040e-01 -1.840e-01  1.915e-02 -1.230e-01 -5.852e-02]\n",
      "    [ 3.214e-01 -4.633e-02  2.761e-01  3.734e-02  3.515e-03 -3.022e-01 -4.429e-02 -7.665e-02]\n",
      "    [ 1.415e-01 -2.777e-01 -3.203e-01  1.481e-02  5.852e-02 -1.620e-02 -2.631e-02 -1.071e-01]]\n",
      "\n",
      "   [[ 2.995e-02 -2.999e-02 -1.760e-01  2.144e-01  6.655e-02 -2.458e-01 -1.913e-01  1.247e-01]\n",
      "    [-2.317e-01  2.101e-01 -1.942e-01 -1.456e-01  1.529e-01  1.416e-01  1.019e-01 -6.160e-02]\n",
      "    [ 2.644e-01 -1.390e-01  2.762e-02 -2.597e-01  4.218e-02  2.032e-02  1.882e-01 -1.379e-01]\n",
      "    [ 9.261e-03  1.704e-01 -1.896e-01 -3.040e-01 -1.840e-01  1.915e-02 -1.230e-01 -5.852e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.643e-01 -1.278e-01  1.415e-01 -1.839e-01 -1.859e-01  1.570e-01 -9.506e-02 -1.272e-01]\n",
      "    [ 1.999e-01 -1.375e-01  1.499e-01  1.570e-01 -3.756e-02 -5.693e-02 -2.266e-01  4.389e-02]]\n",
      "\n",
      "   [[ 2.354e-02  1.045e-01 -3.693e-02 -7.979e-02 -1.946e-01  6.906e-02  2.410e-01  3.505e-02]\n",
      "    [-2.082e-01  8.179e-02 -6.863e-02  1.431e-01 -1.392e-01 -1.567e-01  2.144e-01  7.808e-02]\n",
      "    [-4.453e-02 -1.418e-01  5.761e-04 -1.431e-01 -1.872e-01  5.248e-02  2.010e-03 -1.975e-01]\n",
      "    [ 3.214e-01 -4.633e-02  2.761e-01  3.734e-02  3.515e-03 -3.022e-01 -4.429e-02 -7.665e-02]\n",
      "    [ 2.643e-01 -1.278e-01  1.415e-01 -1.839e-01 -1.859e-01  1.570e-01 -9.506e-02 -1.272e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 4.814e-01 -2.620e-02  1.332e-01  1.773e-02 -1.121e-01  1.677e-01  4.728e-02 -1.215e-02]]\n",
      "\n",
      "   [[-1.671e-01  1.113e-01  2.985e-01  1.401e-02  1.867e-01  1.128e-01 -1.932e-01  2.767e-02]\n",
      "    [-3.712e-02 -8.282e-02  1.370e-01  6.717e-02 -3.597e-02 -1.482e-01  1.728e-01  4.237e-02]\n",
      "    [ 1.008e-01 -4.552e-02 -6.351e-02 -1.844e-01  3.621e-01 -8.148e-02  1.051e-01 -6.256e-02]\n",
      "    [ 1.415e-01 -2.777e-01 -3.203e-01  1.481e-02  5.852e-02 -1.620e-02 -2.631e-02 -1.071e-01]\n",
      "    [ 1.999e-01 -1.375e-01  1.499e-01  1.570e-01 -3.756e-02 -5.693e-02 -2.266e-01  4.389e-02]\n",
      "    [ 4.814e-01 -2.620e-02  1.332e-01  1.773e-02 -1.121e-01  1.677e-01  4.728e-02 -1.215e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-9.918e-02 -1.339e-02  1.878e-01 -1.392e-01 -6.062e-02 -1.481e-01  7.079e-02  2.861e-01]\n",
      "    [ 1.926e-01 -1.545e-01  3.261e-01  3.437e-04  5.174e-02 -1.625e-01  1.253e-02  1.013e-01]\n",
      "    [-1.938e-02  1.784e-01  1.501e-01 -2.535e-01 -2.222e-02 -1.729e-02 -1.402e-03 -3.668e-01]\n",
      "    [ 4.497e-02 -1.022e-01  3.215e-01 -1.293e-01 -5.054e-03 -1.420e-01  1.710e-01 -6.956e-02]\n",
      "    [-3.241e-05  1.925e-01 -9.595e-02 -3.642e-02  1.332e-01 -9.403e-02 -3.070e-01  6.990e-02]\n",
      "    [-1.575e-01 -3.024e-01  8.336e-02 -3.435e-02 -7.503e-02  9.786e-03 -4.870e-02  5.106e-02]]\n",
      "\n",
      "   [[-9.918e-02 -1.339e-02  1.878e-01 -1.392e-01 -6.062e-02 -1.481e-01  7.079e-02  2.861e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.409e-02  1.551e-01  1.355e-01  7.593e-03 -2.866e-01  4.906e-01 -4.770e-02  6.298e-02]\n",
      "    [-1.513e-01  2.450e-02  1.291e-01  3.852e-01  2.158e-01  7.730e-04 -2.230e-01 -3.373e-01]\n",
      "    [-2.718e-01 -7.202e-03  1.140e-01 -6.846e-02  6.180e-02  7.982e-03 -2.530e-01  4.848e-02]\n",
      "    [-7.439e-02 -2.366e-02  3.720e-02 -1.418e-01  3.091e-02 -9.169e-02  5.506e-02  9.600e-02]\n",
      "    [ 2.051e-01  1.616e-01  8.757e-02 -6.786e-02 -4.381e-03 -1.394e-02 -1.729e-01 -3.019e-02]]\n",
      "\n",
      "   [[ 1.926e-01 -1.545e-01  3.261e-01  3.437e-04  5.174e-02 -1.625e-01  1.253e-02  1.013e-01]\n",
      "    [ 1.409e-02  1.551e-01  1.355e-01  7.593e-03 -2.866e-01  4.906e-01 -4.770e-02  6.298e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-5.424e-02 -1.762e-01  3.627e-01 -1.531e-01 -3.657e-01 -2.121e-01  9.924e-03  1.149e-02]\n",
      "    [-5.007e-02 -1.056e-01  1.258e-01 -1.078e-02 -3.819e-01  1.871e-01 -1.122e-01 -1.075e-01]\n",
      "    [ 2.571e-01 -1.651e-02 -2.179e-01  2.520e-01  3.691e-01 -3.804e-02 -1.604e-01  4.962e-02]\n",
      "    [-1.356e-02  2.014e-01 -1.229e-02  1.947e-01  3.053e-01  1.397e-02 -2.674e-01  6.408e-02]]\n",
      "\n",
      "   [[-1.938e-02  1.784e-01  1.501e-01 -2.535e-01 -2.222e-02 -1.729e-02 -1.402e-03 -3.668e-01]\n",
      "    [-1.513e-01  2.450e-02  1.291e-01  3.852e-01  2.158e-01  7.730e-04 -2.230e-01 -3.373e-01]\n",
      "    [-5.424e-02 -1.762e-01  3.627e-01 -1.531e-01 -3.657e-01 -2.121e-01  9.924e-03  1.149e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 7.455e-02  1.658e-02  8.412e-02 -5.726e-02  3.297e-01 -2.685e-01  2.956e-02  3.923e-02]\n",
      "    [-2.662e-01  6.668e-03 -2.626e-01 -5.177e-02  1.245e-01 -1.933e-01  1.636e-01  1.911e-01]\n",
      "    [-1.996e-01 -2.897e-01  8.547e-02 -9.875e-02  2.327e-02 -1.198e-01  1.677e-01  1.332e-01]]\n",
      "\n",
      "   [[ 4.497e-02 -1.022e-01  3.215e-01 -1.293e-01 -5.054e-03 -1.420e-01  1.710e-01 -6.956e-02]\n",
      "    [-2.718e-01 -7.202e-03  1.140e-01 -6.846e-02  6.180e-02  7.982e-03 -2.530e-01  4.848e-02]\n",
      "    [-5.007e-02 -1.056e-01  1.258e-01 -1.078e-02 -3.819e-01  1.871e-01 -1.122e-01 -1.075e-01]\n",
      "    [ 7.455e-02  1.658e-02  8.412e-02 -5.726e-02  3.297e-01 -2.685e-01  2.956e-02  3.923e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.496e-01  1.966e-01 -1.607e-01  1.564e-01 -2.067e-01  1.866e-02 -1.307e-01  1.889e-01]\n",
      "    [ 1.239e-01 -8.709e-02  9.787e-03 -1.741e-02  1.364e-01 -1.280e-02 -6.192e-02 -2.543e-01]]\n",
      "\n",
      "   [[-3.241e-05  1.925e-01 -9.595e-02 -3.642e-02  1.332e-01 -9.403e-02 -3.070e-01  6.990e-02]\n",
      "    [-7.439e-02 -2.366e-02  3.720e-02 -1.418e-01  3.091e-02 -9.169e-02  5.506e-02  9.600e-02]\n",
      "    [ 2.571e-01 -1.651e-02 -2.179e-01  2.520e-01  3.691e-01 -3.804e-02 -1.604e-01  4.962e-02]\n",
      "    [-2.662e-01  6.668e-03 -2.626e-01 -5.177e-02  1.245e-01 -1.933e-01  1.636e-01  1.911e-01]\n",
      "    [-1.496e-01  1.966e-01 -1.607e-01  1.564e-01 -2.067e-01  1.866e-02 -1.307e-01  1.889e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.764e-01  1.783e-01 -1.526e-02  3.837e-01  6.953e-02  5.557e-02 -1.163e-01 -1.166e-01]]\n",
      "\n",
      "   [[-1.575e-01 -3.024e-01  8.336e-02 -3.435e-02 -7.503e-02  9.786e-03 -4.870e-02  5.106e-02]\n",
      "    [ 2.051e-01  1.616e-01  8.757e-02 -6.786e-02 -4.381e-03 -1.394e-02 -1.729e-01 -3.019e-02]\n",
      "    [-1.356e-02  2.014e-01 -1.229e-02  1.947e-01  3.053e-01  1.397e-02 -2.674e-01  6.408e-02]\n",
      "    [-1.996e-01 -2.897e-01  8.547e-02 -9.875e-02  2.327e-02 -1.198e-01  1.677e-01  1.332e-01]\n",
      "    [ 1.239e-01 -8.709e-02  9.787e-03 -1.741e-02  1.364e-01 -1.280e-02 -6.192e-02 -2.543e-01]\n",
      "    [ 1.764e-01  1.783e-01 -1.526e-02  3.837e-01  6.953e-02  5.557e-02 -1.163e-01 -1.166e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 8.717e-02  3.523e-01 -5.135e-02  6.576e-03  3.554e-01 -4.033e-02 -1.428e-03 -2.781e-01]\n",
      "    [-2.336e-01  1.273e-01 -1.131e-01  2.281e-01 -3.334e-02 -1.346e-02 -4.037e-02 -1.765e-02]\n",
      "    [-1.439e-01 -2.061e-01 -2.968e-03 -1.217e-02 -1.881e-02  9.081e-02 -1.634e-01 -1.748e-01]\n",
      "    [ 2.910e-02  1.093e-01 -8.099e-02 -6.633e-02  4.216e-02  1.419e-01 -5.784e-02  1.613e-02]\n",
      "    [-1.113e-01  1.746e-01  4.296e-02 -2.518e-01 -2.443e-01  1.300e-02 -2.990e-01  2.014e-01]\n",
      "    [ 2.256e-01  1.309e-01 -2.125e-01 -4.238e-02  2.367e-01  5.661e-02  5.862e-02  6.803e-03]]\n",
      "\n",
      "   [[ 8.717e-02  3.523e-01 -5.135e-02  6.576e-03  3.554e-01 -4.033e-02 -1.428e-03 -2.781e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.106e-01 -1.870e-02 -1.197e-01 -2.839e-01 -2.030e-01  1.201e-01  9.817e-02 -1.786e-01]\n",
      "    [ 6.121e-02  8.011e-03  3.632e-02 -2.378e-01  1.735e-01  2.212e-02  5.195e-02  1.387e-01]\n",
      "    [-2.725e-01  1.102e-01 -8.945e-02 -9.922e-02  1.643e-02  8.463e-02  1.388e-02  1.091e-01]\n",
      "    [-5.613e-02 -6.607e-02  6.633e-02 -1.990e-01 -1.634e-01 -7.028e-02 -2.928e-02 -2.674e-02]\n",
      "    [-4.112e-02  1.527e-01  2.957e-01  1.969e-02  1.780e-01 -4.136e-02  1.285e-01 -3.018e-01]]\n",
      "\n",
      "   [[-2.336e-01  1.273e-01 -1.131e-01  2.281e-01 -3.334e-02 -1.346e-02 -4.037e-02 -1.765e-02]\n",
      "    [ 1.106e-01 -1.870e-02 -1.197e-01 -2.839e-01 -2.030e-01  1.201e-01  9.817e-02 -1.786e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.240e-02 -9.768e-02 -8.890e-02 -6.717e-02  8.161e-02 -1.550e-01 -5.430e-02  6.497e-02]\n",
      "    [-6.539e-02 -2.675e-02  3.276e-02  5.983e-02 -2.102e-01 -3.114e-01 -1.772e-01 -4.177e-01]\n",
      "    [ 1.124e-01 -9.658e-03 -4.973e-02  3.872e-02  1.704e-01 -2.330e-02  2.053e-02 -1.157e-01]\n",
      "    [-2.567e-01  2.427e-01  6.251e-02  4.921e-02 -6.362e-03  1.469e-02  3.491e-01 -1.427e-01]]\n",
      "\n",
      "   [[-1.439e-01 -2.061e-01 -2.968e-03 -1.217e-02 -1.881e-02  9.081e-02 -1.634e-01 -1.748e-01]\n",
      "    [ 6.121e-02  8.011e-03  3.632e-02 -2.378e-01  1.735e-01  2.212e-02  5.195e-02  1.387e-01]\n",
      "    [-2.240e-02 -9.768e-02 -8.890e-02 -6.717e-02  8.161e-02 -1.550e-01 -5.430e-02  6.497e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 9.657e-02 -2.907e-02  3.611e-01  6.921e-02  3.078e-01  9.123e-02 -1.513e-01 -4.529e-03]\n",
      "    [-7.646e-02 -2.002e-01  1.869e-01 -6.108e-02 -3.245e-02 -3.365e-01  4.489e-02 -3.839e-02]\n",
      "    [ 1.334e-01  2.336e-02 -1.699e-01 -1.082e-01 -1.910e-01  2.194e-01 -1.354e-01 -1.877e-01]]\n",
      "\n",
      "   [[ 2.910e-02  1.093e-01 -8.099e-02 -6.633e-02  4.216e-02  1.419e-01 -5.784e-02  1.613e-02]\n",
      "    [-2.725e-01  1.102e-01 -8.945e-02 -9.922e-02  1.643e-02  8.463e-02  1.388e-02  1.091e-01]\n",
      "    [-6.539e-02 -2.675e-02  3.276e-02  5.983e-02 -2.102e-01 -3.114e-01 -1.772e-01 -4.177e-01]\n",
      "    [ 9.657e-02 -2.907e-02  3.611e-01  6.921e-02  3.078e-01  9.123e-02 -1.513e-01 -4.529e-03]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-2.312e-01 -7.351e-03  1.375e-01  1.337e-01  1.949e-02 -4.432e-02 -4.599e-02  2.909e-01]\n",
      "    [ 3.462e-01 -1.549e-01 -5.370e-02 -1.579e-01  1.420e-01  1.652e-01  1.113e-01 -4.227e-02]]\n",
      "\n",
      "   [[-1.113e-01  1.746e-01  4.296e-02 -2.518e-01 -2.443e-01  1.300e-02 -2.990e-01  2.014e-01]\n",
      "    [-5.613e-02 -6.607e-02  6.633e-02 -1.990e-01 -1.634e-01 -7.028e-02 -2.928e-02 -2.674e-02]\n",
      "    [ 1.124e-01 -9.658e-03 -4.973e-02  3.872e-02  1.704e-01 -2.330e-02  2.053e-02 -1.157e-01]\n",
      "    [-7.646e-02 -2.002e-01  1.869e-01 -6.108e-02 -3.245e-02 -3.365e-01  4.489e-02 -3.839e-02]\n",
      "    [-2.312e-01 -7.351e-03  1.375e-01  1.337e-01  1.949e-02 -4.432e-02 -4.599e-02  2.909e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.468e-01  8.705e-02 -9.482e-04  3.537e-02 -2.019e-01 -1.183e-01 -6.370e-02  2.266e-02]]\n",
      "\n",
      "   [[ 2.256e-01  1.309e-01 -2.125e-01 -4.238e-02  2.367e-01  5.661e-02  5.862e-02  6.803e-03]\n",
      "    [-4.112e-02  1.527e-01  2.957e-01  1.969e-02  1.780e-01 -4.136e-02  1.285e-01 -3.018e-01]\n",
      "    [-2.567e-01  2.427e-01  6.251e-02  4.921e-02 -6.362e-03  1.469e-02  3.491e-01 -1.427e-01]\n",
      "    [ 1.334e-01  2.336e-02 -1.699e-01 -1.082e-01 -1.910e-01  2.194e-01 -1.354e-01 -1.877e-01]\n",
      "    [ 3.462e-01 -1.549e-01 -5.370e-02 -1.579e-01  1.420e-01  1.652e-01  1.113e-01 -4.227e-02]\n",
      "    [ 1.468e-01  8.705e-02 -9.482e-04  3.537e-02 -2.019e-01 -1.183e-01 -6.370e-02  2.266e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 2.092e-01  3.253e-01  1.206e-01  9.560e-03 -7.623e-02 -1.665e-01 -1.012e-01 -1.028e-01]\n",
      "    [ 2.985e-01  1.752e-01  5.359e-02 -5.868e-02  1.110e-01  1.814e-01  5.441e-02 -2.811e-01]\n",
      "    [-1.507e-02 -7.888e-02 -6.643e-02  6.558e-02 -1.251e-01 -1.605e-01  3.402e-02  5.293e-02]\n",
      "    [-6.732e-02  1.112e-01 -1.941e-01  2.490e-01  1.680e-03 -2.413e-02  1.064e-01 -3.691e-02]\n",
      "    [ 4.434e-02 -4.005e-02 -3.185e-02 -2.116e-01  1.747e-01 -1.567e-01  7.469e-02  1.097e-01]\n",
      "    [ 1.843e-02  5.573e-02 -1.584e-01 -3.716e-01 -1.251e-01  5.669e-02 -1.886e-02 -2.136e-02]]\n",
      "\n",
      "   [[ 2.092e-01  3.253e-01  1.206e-01  9.560e-03 -7.623e-02 -1.665e-01 -1.012e-01 -1.028e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-3.784e-03  1.160e-01 -5.408e-02  4.584e-02  4.137e-01  3.259e-02 -3.374e-01 -1.593e-02]\n",
      "    [ 1.438e-02 -5.509e-02 -7.728e-02  7.777e-02  8.509e-03 -8.377e-02  4.483e-02  1.324e-02]\n",
      "    [-3.633e-01 -2.650e-01  7.223e-02  8.169e-02  2.150e-01  1.629e-02  1.486e-01 -1.919e-01]\n",
      "    [ 9.080e-02  1.902e-01 -1.353e-01 -2.284e-01  2.072e-01 -1.785e-01  3.691e-02  2.718e-01]\n",
      "    [-2.137e-01 -4.116e-02 -1.149e-01 -5.886e-02  3.784e-01  1.884e-01 -1.179e-01  1.819e-01]]\n",
      "\n",
      "   [[ 2.985e-01  1.752e-01  5.359e-02 -5.868e-02  1.110e-01  1.814e-01  5.441e-02 -2.811e-01]\n",
      "    [-3.784e-03  1.160e-01 -5.408e-02  4.584e-02  4.137e-01  3.259e-02 -3.374e-01 -1.593e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.638e-02 -4.783e-03 -1.086e-01 -1.562e-01 -1.450e-01  3.095e-01 -9.462e-02 -4.026e-02]\n",
      "    [ 1.705e-02  1.109e-01 -7.243e-03 -5.174e-02 -1.190e-01 -1.443e-01  1.910e-01 -1.203e-01]\n",
      "    [ 1.345e-02  3.508e-02  3.146e-01  7.671e-02  2.585e-01  1.799e-04 -7.376e-02  4.205e-02]\n",
      "    [-1.484e-01 -3.229e-01  4.259e-02  4.447e-02  1.951e-01 -1.301e-02 -3.709e-02  7.767e-02]]\n",
      "\n",
      "   [[-1.507e-02 -7.888e-02 -6.643e-02  6.558e-02 -1.251e-01 -1.605e-01  3.402e-02  5.293e-02]\n",
      "    [ 1.438e-02 -5.509e-02 -7.728e-02  7.777e-02  8.509e-03 -8.377e-02  4.483e-02  1.324e-02]\n",
      "    [ 1.638e-02 -4.783e-03 -1.086e-01 -1.562e-01 -1.450e-01  3.095e-01 -9.462e-02 -4.026e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.391e-01  1.515e-01  1.128e-01 -7.292e-03  1.735e-01 -1.729e-01  6.206e-02  1.041e-01]\n",
      "    [ 1.156e-03  9.138e-02  1.879e-01 -2.895e-01 -8.667e-02  1.609e-02  2.449e-01  7.695e-02]\n",
      "    [-5.759e-02 -8.826e-02 -6.994e-02  2.233e-02 -3.353e-02 -2.304e-01  2.677e-01 -1.044e-02]]\n",
      "\n",
      "   [[-6.732e-02  1.112e-01 -1.941e-01  2.490e-01  1.680e-03 -2.413e-02  1.064e-01 -3.691e-02]\n",
      "    [-3.633e-01 -2.650e-01  7.223e-02  8.169e-02  2.150e-01  1.629e-02  1.486e-01 -1.919e-01]\n",
      "    [ 1.705e-02  1.109e-01 -7.243e-03 -5.174e-02 -1.190e-01 -1.443e-01  1.910e-01 -1.203e-01]\n",
      "    [-1.391e-01  1.515e-01  1.128e-01 -7.292e-03  1.735e-01 -1.729e-01  6.206e-02  1.041e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 7.218e-02  8.107e-02 -2.365e-01 -1.670e-01 -1.454e-01 -3.549e-01  4.835e-02 -3.283e-01]\n",
      "    [-7.225e-02  4.475e-02 -2.281e-01  1.067e-01 -7.238e-02  8.654e-02  4.123e-02 -2.189e-02]]\n",
      "\n",
      "   [[ 4.434e-02 -4.005e-02 -3.185e-02 -2.116e-01  1.747e-01 -1.567e-01  7.469e-02  1.097e-01]\n",
      "    [ 9.080e-02  1.902e-01 -1.353e-01 -2.284e-01  2.072e-01 -1.785e-01  3.691e-02  2.718e-01]\n",
      "    [ 1.345e-02  3.508e-02  3.146e-01  7.671e-02  2.585e-01  1.799e-04 -7.376e-02  4.205e-02]\n",
      "    [ 1.156e-03  9.138e-02  1.879e-01 -2.895e-01 -8.667e-02  1.609e-02  2.449e-01  7.695e-02]\n",
      "    [ 7.218e-02  8.107e-02 -2.365e-01 -1.670e-01 -1.454e-01 -3.549e-01  4.835e-02 -3.283e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 9.709e-02  1.620e-01  7.873e-02  1.597e-01 -1.025e-01 -1.710e-01  2.251e-01 -6.047e-02]]\n",
      "\n",
      "   [[ 1.843e-02  5.573e-02 -1.584e-01 -3.716e-01 -1.251e-01  5.669e-02 -1.886e-02 -2.136e-02]\n",
      "    [-2.137e-01 -4.116e-02 -1.149e-01 -5.886e-02  3.784e-01  1.884e-01 -1.179e-01  1.819e-01]\n",
      "    [-1.484e-01 -3.229e-01  4.259e-02  4.447e-02  1.951e-01 -1.301e-02 -3.709e-02  7.767e-02]\n",
      "    [-5.759e-02 -8.826e-02 -6.994e-02  2.233e-02 -3.353e-02 -2.304e-01  2.677e-01 -1.044e-02]\n",
      "    [-7.225e-02  4.475e-02 -2.281e-01  1.067e-01 -7.238e-02  8.654e-02  4.123e-02 -2.189e-02]\n",
      "    [ 9.709e-02  1.620e-01  7.873e-02  1.597e-01 -1.025e-01 -1.710e-01  2.251e-01 -6.047e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]\n",
      "\n",
      "\n",
      "  [[[ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.988e-01  1.037e-01 -5.886e-04 -1.134e-01  8.367e-02  6.138e-02 -9.670e-02  8.827e-02]\n",
      "    [ 1.502e-01  2.536e-01  1.076e-01  1.511e-01 -1.214e-01 -3.826e-02  4.575e-03  7.719e-02]\n",
      "    [-2.688e-02  1.459e-02  1.081e-01 -5.378e-03  5.852e-02 -1.831e-01  3.847e-02 -5.433e-02]\n",
      "    [-1.854e-01  1.643e-01  2.074e-01  1.664e-01 -3.108e-01  2.647e-01 -4.051e-04  5.297e-02]\n",
      "    [-5.171e-02 -1.047e-01  1.947e-01 -8.255e-02 -5.801e-02 -1.041e-01 -2.606e-01  1.818e-01]\n",
      "    [-2.829e-01 -9.537e-02  2.681e-02  1.366e-01 -3.435e-01 -1.190e-01 -1.463e-02  2.101e-01]]\n",
      "\n",
      "   [[-1.988e-01  1.037e-01 -5.886e-04 -1.134e-01  8.367e-02  6.138e-02 -9.670e-02  8.827e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-4.218e-02  1.130e-01  1.012e-01 -4.335e-02 -1.281e-01  1.309e-01  8.724e-02  1.429e-01]\n",
      "    [-5.109e-02 -8.883e-02  1.229e-01  2.920e-01 -1.160e-01  1.863e-01 -1.462e-01 -2.370e-02]\n",
      "    [-1.510e-01  1.465e-01 -3.877e-01  1.600e-01 -5.569e-02 -1.308e-01 -6.262e-02 -4.287e-01]\n",
      "    [-1.877e-01  1.658e-01  2.883e-02  3.027e-02  1.315e-01  3.025e-02  2.156e-01  3.858e-02]\n",
      "    [-9.416e-02 -8.216e-02  2.057e-01  2.402e-01 -1.176e-01  1.897e-01  1.168e-01  2.518e-01]]\n",
      "\n",
      "   [[ 1.502e-01  2.536e-01  1.076e-01  1.511e-01 -1.214e-01 -3.826e-02  4.575e-03  7.719e-02]\n",
      "    [-4.218e-02  1.130e-01  1.012e-01 -4.335e-02 -1.281e-01  1.309e-01  8.724e-02  1.429e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.938e-02 -1.891e-01 -6.901e-02  1.052e-01 -4.457e-02  4.270e-02  8.488e-02 -2.287e-01]\n",
      "    [-6.216e-02  6.503e-02 -9.805e-02  1.048e-01  8.059e-02  2.075e-01  1.585e-01  1.821e-01]\n",
      "    [ 1.046e-02 -4.754e-02 -3.984e-02 -1.102e-02  1.207e-02 -1.381e-01 -1.024e-01  2.943e-01]\n",
      "    [ 6.250e-03 -1.723e-01 -9.909e-02 -3.083e-02  3.985e-02  1.869e-01 -9.521e-02  1.142e-01]]\n",
      "\n",
      "   [[-2.688e-02  1.459e-02  1.081e-01 -5.378e-03  5.852e-02 -1.831e-01  3.847e-02 -5.433e-02]\n",
      "    [-5.109e-02 -8.883e-02  1.229e-01  2.920e-01 -1.160e-01  1.863e-01 -1.462e-01 -2.370e-02]\n",
      "    [-1.938e-02 -1.891e-01 -6.901e-02  1.052e-01 -4.457e-02  4.270e-02  8.488e-02 -2.287e-01]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 3.971e-02  1.544e-02 -3.683e-01  2.845e-01  1.793e-02 -8.531e-02 -7.982e-02  5.074e-02]\n",
      "    [-3.886e-02 -5.704e-02  2.327e-01  5.620e-03  1.523e-01 -5.511e-03 -1.070e-01 -3.593e-02]\n",
      "    [ 9.976e-02  1.629e-02 -1.388e-01  1.093e-01  1.527e-02  5.687e-02  2.739e-01  7.373e-02]]\n",
      "\n",
      "   [[-1.854e-01  1.643e-01  2.074e-01  1.664e-01 -3.108e-01  2.647e-01 -4.051e-04  5.297e-02]\n",
      "    [-1.510e-01  1.465e-01 -3.877e-01  1.600e-01 -5.569e-02 -1.308e-01 -6.262e-02 -4.287e-01]\n",
      "    [-6.216e-02  6.503e-02 -9.805e-02  1.048e-01  8.059e-02  2.075e-01  1.585e-01  1.821e-01]\n",
      "    [ 3.971e-02  1.544e-02 -3.683e-01  2.845e-01  1.793e-02 -8.531e-02 -7.982e-02  5.074e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [ 1.382e-01  7.365e-02  3.502e-02  3.271e-01  6.701e-03 -4.112e-02 -9.215e-02 -5.241e-02]\n",
      "    [-7.892e-03 -8.293e-02 -1.134e-01  1.386e-01  6.625e-02 -4.077e-02  3.264e-02 -4.621e-02]]\n",
      "\n",
      "   [[-5.171e-02 -1.047e-01  1.947e-01 -8.255e-02 -5.801e-02 -1.041e-01 -2.606e-01  1.818e-01]\n",
      "    [-1.877e-01  1.658e-01  2.883e-02  3.027e-02  1.315e-01  3.025e-02  2.156e-01  3.858e-02]\n",
      "    [ 1.046e-02 -4.754e-02 -3.984e-02 -1.102e-02  1.207e-02 -1.381e-01 -1.024e-01  2.943e-01]\n",
      "    [-3.886e-02 -5.704e-02  2.327e-01  5.620e-03  1.523e-01 -5.511e-03 -1.070e-01 -3.593e-02]\n",
      "    [ 1.382e-01  7.365e-02  3.502e-02  3.271e-01  6.701e-03 -4.112e-02 -9.215e-02 -5.241e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]\n",
      "    [-1.036e-01  3.887e-01 -2.894e-01  4.930e-02 -3.338e-02 -2.068e-01  8.892e-02  5.960e-02]]\n",
      "\n",
      "   [[-2.829e-01 -9.537e-02  2.681e-02  1.366e-01 -3.435e-01 -1.190e-01 -1.463e-02  2.101e-01]\n",
      "    [-9.416e-02 -8.216e-02  2.057e-01  2.402e-01 -1.176e-01  1.897e-01  1.168e-01  2.518e-01]\n",
      "    [ 6.250e-03 -1.723e-01 -9.909e-02 -3.083e-02  3.985e-02  1.869e-01 -9.521e-02  1.142e-01]\n",
      "    [ 9.976e-02  1.629e-02 -1.388e-01  1.093e-01  1.527e-02  5.687e-02  2.739e-01  7.373e-02]\n",
      "    [-7.892e-03 -8.293e-02 -1.134e-01  1.386e-01  6.625e-02 -4.077e-02  3.264e-02 -4.621e-02]\n",
      "    [-1.036e-01  3.887e-01 -2.894e-01  4.930e-02 -3.338e-02 -2.068e-01  8.892e-02  5.960e-02]\n",
      "    [ 1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00  1.000e+00]]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def self_outer_product_eq(num_dims, axis):\n",
    "    letters = string.ascii_lowercase\n",
    "    base_letters = letters[:-2]\n",
    "    base = base_letters[:num_dims]\n",
    "    f1 = base[:axis] + letters[-2] + base[axis+1:]\n",
    "    f2 = base[:axis] + letters[-1] + base[axis+1:]\n",
    "    prod = base[:axis] + letters[-2:] + base[axis+1:]\n",
    "    return f1 + ',' + f2 + '->' + prod\n",
    "\n",
    "\n",
    "def self_outer_product(tensor, axis):\n",
    "    with tf.name_scope('self_outer_product'):\n",
    "        num_dims = len(tensor.get_shape().as_list())\n",
    "        eq = self_outer_product_eq(num_dims, axis)\n",
    "        return tf.einsum(eq, tensor, tensor)\n",
    "\n",
    "\n",
    "def covariance(tensor, reduced_axes, cov_axis):\n",
    "    with tf.name_scope('covariance'):\n",
    "        mean = tf.reduce_mean(tensor, axis=reduced_axes, keepdims=True)\n",
    "        devs = tensor - mean\n",
    "        dev_prods = self_outer_product(devs, cov_axis)\n",
    "        return tf.reduce_mean(dev_prods, axis=reduced_axes)\n",
    "\n",
    "\n",
    "def correlation(tensor, reduced_axes, cor_axis, epsilon=1e-12):\n",
    "    with tf.name_scope('correlation'):\n",
    "        cov = covariance(tensor, reduced_axes, cor_axis)\n",
    "        _, variance = tf.nn.moments(tensor, axes=reduced_axes, keep_dims=True)\n",
    "        var_cross_mul = self_outer_product(variance, cor_axis)\n",
    "        var_cross_mul = tf.reduce_sum(var_cross_mul, axis=reduced_axes)\n",
    "        return cov / tf.sqrt(var_cross_mul + epsilon)\n",
    "    \n",
    "a = tf.constant([[1, -2, 3, -4, 5, -6, 7], [-1, 2, -3, 4, -5, 6, -7], [0]*7], dtype=tf.float32)\n",
    "b = tf.random_uniform(shape=[2, 3, 4, 5, 6, 7, 8])\n",
    "cor = correlation(b, [0, 2, 3], 5)\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(cor)\n",
    "    np.set_printoptions(precision=3, linewidth=300, threshold=np.nan)\n",
    "    print(res.shape)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.08096984 0.0975479  0.26694262 0.5545396 ]\n",
      "1000 [0.0533044  0.19900034 0.5111163  0.23657893]\n",
      "2000 [0.04506009 0.2585933  0.5747717  0.12157496]\n",
      "3000 [0.0462773  0.28025383 0.5934374  0.08003151]\n",
      "4000 [0.04730603 0.2972135  0.59320414 0.06227635]\n",
      "5000 [0.04869702 0.29630738 0.6007808  0.05421491]\n",
      "6000 [0.04989836 0.302922   0.5937062  0.05347345]\n",
      "7000 [0.04912981 0.30450043 0.59776264 0.04860713]\n",
      "8000 [0.05085437 0.301653   0.5983184  0.04917423]\n",
      "9000 [0.04980492 0.30537108 0.59524184 0.0495821 ]\n",
      "10000 [0.04901305 0.29486674 0.60645235 0.0496678 ]\n",
      "11000 [0.05039519 0.30151966 0.5997605  0.04832472]\n",
      "12000 [0.05130767 0.2991871  0.6008251  0.04868015]\n",
      "13000 [0.04810471 0.30305338 0.59956044 0.04928147]\n",
      "14000 [0.05046886 0.3014141  0.59800047 0.05011658]\n",
      "15000 [0.05116741 0.2969777  0.6018445  0.0500104 ]\n",
      "16000 [0.05030151 0.30790877 0.5929822  0.04880754]\n",
      "17000 [0.05044535 0.30435082 0.59567946 0.04952439]\n",
      "18000 [0.05145176 0.30772248 0.59086555 0.04996015]\n",
      "19000 [0.04869069 0.29502562 0.6079232  0.04836055]\n",
      "20000 [0.05054011 0.2997276  0.60078275 0.04894949]\n",
      "21000 [0.0499399  0.29681426 0.6044737  0.04877222]\n",
      "22000 [0.04995796 0.29944372 0.6013185  0.04927984]\n",
      "23000 [0.0506405  0.30111867 0.5986086  0.04963226]\n",
      "24000 [0.05093496 0.30018    0.597552   0.05133304]\n",
      "25000 [0.04989674 0.2978597  0.601153   0.05109052]\n",
      "26000 [0.05170452 0.2944559  0.6041289  0.04971063]\n",
      "27000 [0.05421989 0.29624635 0.5989833  0.05055047]\n",
      "28000 [0.05115524 0.30012408 0.600018   0.04870263]\n",
      "29000 [0.04835065 0.29969594 0.6011171  0.05083638]\n",
      "30000 [0.05016481 0.30092555 0.5978995  0.05101006]\n",
      "31000 [0.04891286 0.3030634  0.5987462  0.04927757]\n",
      "32000 [0.05196333 0.29684785 0.60149217 0.04969669]\n",
      "33000 [0.04924804 0.30571905 0.595665   0.04936797]\n",
      "34000 [0.05164746 0.30069527 0.5978199  0.0498373 ]\n",
      "35000 [0.0513721  0.29977235 0.5982852  0.05057042]\n",
      "36000 [0.04845599 0.2979999  0.6040262  0.04951799]\n",
      "37000 [0.04834603 0.30176088 0.5996025  0.05029061]\n",
      "38000 [0.04900131 0.2980474  0.60372746 0.04922383]\n",
      "39000 [0.05099601 0.29944015 0.6010774  0.04848645]\n",
      "40000 [0.05072872 0.2941191  0.6056601  0.04949213]\n",
      "41000 [0.05025207 0.30092472 0.59772885 0.05109432]\n",
      "42000 [0.04909933 0.29501805 0.60587883 0.05000375]\n",
      "43000 [0.05082985 0.29563934 0.60114515 0.05238574]\n",
      "44000 [0.05145663 0.29666933 0.6027223  0.04915173]\n",
      "45000 [0.05079317 0.29818144 0.6009019  0.05012346]\n",
      "46000 [0.05368599 0.3014779  0.5950613  0.04977484]\n",
      "47000 [0.04991604 0.29936203 0.6020362  0.04868572]\n",
      "48000 [0.04855623 0.30378383 0.59776324 0.04989668]\n",
      "49000 [0.0493275  0.29554284 0.6068535  0.04827616]\n",
      "50000 [0.05090529 0.29867187 0.60062927 0.04979357]\n",
      "51000 [0.0511696  0.2996637  0.59975696 0.04940976]\n",
      "52000 [0.05048654 0.29671186 0.6046492  0.0481524 ]\n",
      "53000 [0.0509831  0.30238923 0.5967039  0.04992382]\n",
      "54000 [0.05317304 0.29541644 0.6020789  0.04933161]\n",
      "55000 [0.04990523 0.30157566 0.5986632  0.04985591]\n",
      "56000 [0.05110686 0.30029267 0.5990843  0.04951617]\n",
      "57000 [0.04967197 0.2942415  0.60705084 0.04903567]\n",
      "58000 [0.05058382 0.3092297  0.5893407  0.05084575]\n",
      "59000 [0.05062233 0.2918072  0.606366   0.05120453]\n",
      "60000 [0.05022667 0.29692897 0.6030814  0.04976299]\n",
      "61000 [0.05134851 0.30378544 0.59574544 0.04912057]\n",
      "62000 [0.05106631 0.3052011  0.5940408  0.0496918 ]\n",
      "63000 [0.04802716 0.3066559  0.5967995  0.04851738]\n",
      "64000 [0.04926005 0.29218233 0.6085578  0.04999982]\n",
      "65000 [0.04884528 0.29757679 0.6029061  0.05067179]\n",
      "66000 [0.05026316 0.29399705 0.6073656  0.04837425]\n",
      "67000 [0.0526369  0.29606944 0.60169435 0.04959929]\n",
      "68000 [0.05082848 0.29251698 0.6062179  0.05043659]\n",
      "69000 [0.04992136 0.29590487 0.60175    0.05242375]\n",
      "70000 [0.04970565 0.29807296 0.6007158  0.05150557]\n",
      "71000 [0.04969887 0.29990885 0.5991264  0.05126585]\n",
      "72000 [0.0501684  0.3045173  0.59361976 0.05169454]\n",
      "73000 [0.05009573 0.30219218 0.5984387  0.04927335]\n",
      "74000 [0.0482243  0.30518076 0.59790546 0.0486894 ]\n",
      "75000 [0.04878746 0.3022386  0.59905577 0.04991814]\n",
      "76000 [0.04978348 0.29609746 0.6045171  0.04960196]\n",
      "77000 [0.048989   0.29876143 0.60221744 0.05003214]\n",
      "78000 [0.04994263 0.3037171  0.5968464  0.0494938 ]\n",
      "79000 [0.04941226 0.30650234 0.59286493 0.0512205 ]\n",
      "80000 [0.05128021 0.30328512 0.5935858  0.05184886]\n",
      "81000 [0.04886547 0.2988489  0.6017666  0.05051908]\n",
      "82000 [0.04958993 0.30075893 0.5998152  0.04983596]\n",
      "83000 [0.04960028 0.30025843 0.59812146 0.05201983]\n",
      "84000 [0.04954771 0.29948315 0.6015822  0.04938693]\n",
      "85000 [0.04886223 0.29590014 0.6049672  0.05027046]\n",
      "86000 [0.04961788 0.30070236 0.59881026 0.05086951]\n",
      "87000 [0.0512479  0.29600587 0.60326403 0.04948216]\n",
      "88000 [0.0503039  0.30096057 0.5988691  0.04986642]\n",
      "89000 [0.04995573 0.29954332 0.5999751  0.05052583]\n",
      "90000 [0.04902667 0.3045624  0.5987576  0.04765333]\n",
      "91000 [0.05009542 0.29786226 0.6017889  0.05025347]\n",
      "92000 [0.05071543 0.2998775  0.59992707 0.04948004]\n",
      "93000 [0.0509348  0.3038702  0.5951314  0.05006361]\n",
      "94000 [0.04880513 0.30722764 0.592068   0.05189927]\n",
      "95000 [0.05163822 0.29674324 0.60144526 0.05017327]\n",
      "96000 [0.05084784 0.30485427 0.5941563  0.05014158]\n",
      "97000 [0.04945128 0.2880891  0.6124611  0.04999853]\n",
      "98000 [0.04955704 0.3028433  0.5983879  0.04921177]\n",
      "99000 [0.04980431 0.29899228 0.6014033  0.04980011]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100000):\n",
    "        _, pr = sess.run([train_op, probs])\n",
    "#         print(cd)\n",
    "#         print(u)\n",
    "#         print(c)\n",
    "        if i % 1000 == 0:\n",
    "            print(i, pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3], [0.5477225575051661, 0.5477225575051661, 0.5477225575051661, 0.18257418583505544])\n",
      "([3, 4, 5, 6], [0.36514837167011066, 0.5477225575051661, 0.5477225575051661, 0.3651483716701109])\n",
      "([6, 7, 8, 9], [0.1825741858350552, 0.5477225575051661, 0.5477225575051661, 0.5477225575051661])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def indices_and_weights_for_squeezing_of_1_neuron(i, N, M):\n",
    "    weights = []\n",
    "    indices = []\n",
    "    q = N / M\n",
    "    left, right = i * q, (i + 1) * q\n",
    "    if int(left) == left:\n",
    "        start_of_ones = int(left)\n",
    "    else:\n",
    "        weights.append(np.ceil(left) - left)\n",
    "        indices.append(int(left))\n",
    "        start_of_ones = int(left) + 1\n",
    "    \n",
    "    end_of_ones = int(right)\n",
    "    weights += [1.] * (end_of_ones - start_of_ones)\n",
    "    indices.extend(range(start_of_ones, end_of_ones))\n",
    "    \n",
    "    if int(right) != right:\n",
    "        weights.append(right - int(right))\n",
    "        indices.append(indices[-1] + 1)\n",
    "        \n",
    "    factor = q ** -0.5\n",
    "    weights = [w * factor for w in weights]\n",
    "    return indices, weights\n",
    "\n",
    "N = 10\n",
    "M = 3\n",
    "for i in range(M):\n",
    "    print(indices_and_weights_for_squeezing_of_1_neuron(i, N, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (4, 1), (5, 1), (6, 1), (6, 2), (7, 2), (8, 2), (9, 2)], [0.5477225575051661, 0.5477225575051661, 0.5477225575051661, 0.18257418583505544, 0.36514837167011066, 0.5477225575051661, 0.5477225575051661, 0.3651483716701109, 0.1825741858350552, 0.5477225575051661, 0.5477225575051661, 0.5477225575051661])\n"
     ]
    }
   ],
   "source": [
    "def squeezing_sparse_matrix(N, M):\n",
    "    init_indices, init_weights = [], []\n",
    "    for i in range(M):\n",
    "        indices, weights = indices_and_weights_for_squeezing_of_1_neuron(i, N, M)\n",
    "        init_indices.extend(zip(indices, [i] * len(indices)))\n",
    "        init_weights += weights\n",
    "    return init_indices, init_weights\n",
    "\n",
    "print(init_of_squeezing_sparse_matrix(N, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2  3]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[10 11]\n",
      "  [14 15]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def sample_tensor_slices(tensor, n, axis):\n",
    "    if isinstance(n, int):\n",
    "        n = tf.constant(n, dtype=tf.int32)\n",
    "    indices = tf.slice(tf.random_shuffle(tf.range(0, n, dtype=tf.int32)), [0], tf.reshape(n, [1]))\n",
    "    return tf.gather(tensor, indices, axis=axis)\n",
    "\n",
    "\n",
    "def average_k(tensor, k, axis, random_sampling=False):\n",
    "    with tf.name_scope('average_k'):\n",
    "        tensor_shape = tf.shape(tensor)\n",
    "        dim = tf.shape(tensor)[axis]\n",
    "        quotient = dim // k\n",
    "        num_sampled = k * quotient\n",
    "        num_dims = len(tensor.get_shape().as_list())\n",
    "        if random_sampling:\n",
    "            for_averaging = sample_tensor_slices(tensor, num_sampled, axis)\n",
    "        else:\n",
    "            for_averaging = tf.slice(\n",
    "                tensor, [0]*num_dims, \n",
    "                tf.concat(\n",
    "                    [tensor_shape[:axis], tf.reshape(num_sampled, [1]), tensor_shape[axis+1:]],\n",
    "                    0\n",
    "                )\n",
    "            )\n",
    "        sh = tf.shape(for_averaging)\n",
    "        k = tf.constant([k]) if isinstance(k, int) else tf.reshape(k, shape=[1])\n",
    "        new_shape = tf.concat(\n",
    "            [\n",
    "                sh[:axis],\n",
    "                tf.reshape(quotient, [1]),\n",
    "                k,\n",
    "                sh[axis+1:]\n",
    "            ],\n",
    "            0\n",
    "        )\n",
    "        for_averaging = tf.reshape(for_averaging, shape=new_shape)\n",
    "        return tf.reduce_mean(for_averaging, axis=axis+1, keepdims=False)\n",
    "    \n",
    "\n",
    "a = np.array([[[1, 2], [3, 4], [5, 6], [7, 8]], [[9, 10], [11, 12], [13, 14], [15, 16]]])\n",
    "\n",
    "a = tf.constant(a)\n",
    "res = average_k(a, 2, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-01 15:29:52.751 INFO in 'pymorphy2.opencorpora_dict.wrapper'['wrapper'] at line 16: Loading dictionaries from /home/anton/dpenv/lib/python3.6/site-packages/pymorphy2_dicts/data\n",
      "2018-08-01 15:29:52.805 INFO in 'pymorphy2.opencorpora_dict.wrapper'['wrapper'] at line 20: format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['abc'], ['def']]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.models.tokenizers.ru_tokenizer import RussianTokenizer\n",
    "\n",
    "tokenizer = RussianTokenizer(ngram_range=[1, 1])\n",
    "batch = ['abc', 'def']\n",
    "print(tokenizer(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(<class 'tuple'>,)\n",
      "()\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "d = collections.OrderedDict(a=1, b=2)\n",
    "print(type(d) == collections.OrderedDict)\n",
    "\n",
    "tuple_type = collections.namedtuple('mytuple', [])\n",
    "\n",
    "t = tuple_type()\n",
    "print(tuple_type.__bases__)\n",
    "print(getattr(tuple_type, '_fields'))\n",
    "print(all([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, rnn1/transpose/_3, rnn1/concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, rnn2/transpose/_9, rnn2/transpose_1/_11, rnn2/concat_5/_13, rnn2/concat_11/_15)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-2f993b27c650>\", line 11, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 278, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 194, in save_op\n    tensors)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1687, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, rnn1/transpose/_3, rnn1/concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, rnn2/transpose/_9, rnn2/transpose_1/_11, rnn2/concat_5/_13, rnn2/concat_11/_15)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, rnn1/transpose/_3, rnn1/concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, rnn2/transpose/_9, rnn2/transpose_1/_11, rnn2/concat_5/_13, rnn2/concat_11/_15)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2f993b27c650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1651\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, rnn1/transpose/_3, rnn1/concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, rnn2/transpose/_9, rnn2/transpose_1/_11, rnn2/concat_5/_13, rnn2/concat_11/_15)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-2f993b27c650>\", line 11, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 278, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 194, in save_op\n    tensors)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1687, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, rnn1/transpose/_3, rnn1/concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, rnn2/transpose/_9, rnn2/transpose_1/_11, rnn2/concat_5/_13, rnn2/concat_11/_15)]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.cudnn_rnn import CudnnLSTM as CudnnLSTM\n",
    "inp = tf.zeros([10, 32, 100])\n",
    "lstm1 = CudnnLSTM(1, 128)\n",
    "lstm2 = CudnnLSTM(2, 256)\n",
    "with tf.name_scope('rnn1'):\n",
    "    lstm1.build(inp.shape)\n",
    "with tf.name_scope('rnn2'):\n",
    "    lstm2.build(inp.shape)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    save_path = os.path.join('test_cudnn_lstm_save', '1')\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(os.path.join(save_path))\n",
    "    saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 2, 3, 4) (0, 0, 0, 1, 1, 1)\n",
      "[[0.66666667 0.        ]\n",
      " [0.66666667 0.        ]\n",
      " [0.33333333 0.33333333]\n",
      " [0.         0.66666667]\n",
      " [0.         0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def indices_and_weights_for_squeezing_of_1_neuron(i, N, M):\n",
    "    weights = []\n",
    "    indices = []\n",
    "    q = N / M\n",
    "    left, right = i * q, (i + 1) * q\n",
    "    if N >= M:\n",
    "        if int(left) == left:\n",
    "            start_of_ones = int(left)\n",
    "        else:\n",
    "            weights.append(np.ceil(left) - left)\n",
    "            indices.append(int(left))\n",
    "            start_of_ones = int(left) + 1\n",
    "\n",
    "        end_of_ones = int(right)\n",
    "        weights += [1.] * (end_of_ones - start_of_ones)\n",
    "        indices.extend(range(start_of_ones, end_of_ones))\n",
    "\n",
    "        if int(right) != right:\n",
    "            weights.append(right - int(right))\n",
    "            indices.append(indices[-1] + 1)\n",
    "    else:\n",
    "        left_floor, right_floor = int(left), int(right)\n",
    "        if left_floor == right_floor or right == right_floor:\n",
    "            weights.append(right - left)\n",
    "            indices.append(left_floor)\n",
    "        else:\n",
    "            weights += [right_floor - left, right - right_floor]\n",
    "            indices += [left_floor, right_floor]\n",
    "\n",
    "    factor = sum([w**2 for w in weights]) ** -0.5\n",
    "    weights = [w * factor for w in weights]\n",
    "    return indices, weights\n",
    "\n",
    "def squeezing_sparse_matrix(N, M):\n",
    "    init_indices, init_weights = [], []\n",
    "    for i in range(M):\n",
    "        # print(\"(util.tensor.squeezing_sparse_matrix)N, M:\", N, M)\n",
    "        indices, weights = indices_and_weights_for_squeezing_of_1_neuron(i, N, M)\n",
    "        init_indices.extend(zip(indices, [i] * len(indices)))\n",
    "        init_weights += weights\n",
    "    return init_indices, init_weights\n",
    "\n",
    "N, M = 5, 2\n",
    "indices, weights = squeezing_sparse_matrix(N, M)\n",
    "row_ids, col_ids = zip(*indices)\n",
    "print(row_ids, col_ids)\n",
    "sp_matrix = coo_matrix((weights, (row_ids, col_ids)), shape=(N, M))\n",
    "print(sp_matrix.todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you need the answer? (y/n): y\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'EssentialAnswers' has no attribute 'the_answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-22c1a5774edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEssentialAnswers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthe_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPhilosopher1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthe_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPhilosopher2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetaclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEssentialAnswers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'EssentialAnswers' has no attribute 'the_answer'"
     ]
    }
   ],
   "source": [
    "x = input(\"Do you need the answer? (y/n): \")\n",
    "if x.lower() == \"y\":\n",
    "    required = True\n",
    "else:\n",
    "    required = False\n",
    "    \n",
    "def the_answer(self, *args):              \n",
    "        return 42\n",
    "    \n",
    "class EssentialAnswers(type):\n",
    "    \n",
    "    def __init__(cls, clsname, superclasses, attributedict):\n",
    "        if required:\n",
    "            cls.the_answer = the_answer\n",
    "                           \n",
    "    \n",
    "class Philosopher1(metaclass=EssentialAnswers): \n",
    "    pass\n",
    "\n",
    "\n",
    "print(Philosopher1.the_answer)\n",
    "class Philosopher2(metaclass=EssentialAnswers): \n",
    "    pass\n",
    "class Philosopher3(metaclass=EssentialAnswers): \n",
    "    pass\n",
    "    \n",
    "    \n",
    "plato = Philosopher1()\n",
    "print(plato.the_answer())\n",
    "kant = Philosopher2()\n",
    "# let's see what Kant has to say :-)\n",
    "print(kant.the_answer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-03 15:36:34.385 INFO in 'char_lm_vocab'['char_lm_vocab'] at line 70: [loading vocabulary from /home/anton/DeepPavlov/download/vocab.dict]\n",
      "2018-08-03 15:36:34.400 INFO in 'char_lm_vocab'['char_lm_vocab'] at line 70: [loading vocabulary from /home/anton/DeepPavlov/download/vocab.dict]\n",
      "2018-08-03 15:36:34.412 INFO in 'char_lm_vocab'['char_lm_vocab'] at line 59: [saving vocabulary to /home/anton/DeepPavlov/download/vocab.dict]\n"
     ]
    }
   ],
   "source": [
    "from char_lm_vocab import CharLMVocabulary\n",
    "vocab = CharLMVocabulary(\n",
    "    save_path='./vocab.dict',\n",
    "    load_path='./vocab.dict',\n",
    ")\n",
    "text = 'DeepPavlov is an open-source conversational AI library built on TensorFlow and Keras.'\n",
    "vocab.fit(text)\n",
    "vocab.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "letters = string.ascii_lowercase\n",
    "print(letters.replace('', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-99608877cb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCudnnLSTM\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Bring in subpackages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeneratorEnqueuer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedEnqueuer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProgbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, tp)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Invokes __set__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_import_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36m_import_module\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_import_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;34m\"\"\"Import module, returning the module after the last dot.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.cudnn_rnn import CudnnLSTM as LSTM\n",
    "import numpy as np\n",
    "\n",
    "num_units = 100\n",
    "voc_size = 20\n",
    "inps = tf.placeholder(tf.int32, shape=[None, None])\n",
    "lbls = tf.placeholder(tf.int32, shape=[None, None])\n",
    "prep_inps = tf.one_hot(inps, voc_size)\n",
    "prep_lbls = tf.one_hot(lbls, voc_size)\n",
    "\n",
    "out_w = tf.Variable(\n",
    "    tf.truncated_normal([num_units, voc_size])\n",
    ")\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    lstm = LSTM(\n",
    "        2,\n",
    "        num_units,\n",
    "        input_mode='skip_input',\n",
    "    )\n",
    "\n",
    "bs = tf.shape(inps)[1:-1]\n",
    "state_shape = tf.concat([[2], bs, [num_units]], 0)\n",
    "with tf.device('/gpu:0'):\n",
    "    lstm_res, state = lstm(\n",
    "        prep_inps\n",
    "    )\n",
    "    print(lstm_res)\n",
    "    logits = tf.matmul(tf.reshape(lstm_res, [-1, num_units]), out_w)\n",
    "    predictions = tf.nn.softmax(logits)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=logits,\n",
    "        labels=tf.reshape(prep_lbls, [-1, voc_size])\n",
    "    ))\n",
    "    opt = tf.train.GradientDescentOptimizer(1.)\n",
    "    train_op = opt.minimize(loss)\n",
    "    \n",
    "nu = 10\n",
    "bs = 32\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(100):\n",
    "        inputs = np.random.randint(0, voc_size, size=(nu, bs))\n",
    "        labels = np.random.randint(0, voc_size, size=(nu, bs))\n",
    "        _, preds = sess.run([train_op, preds], feed_dict={inps: inputs, lbls: labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def create_distribute_map(num_distributed, result_length):\n",
    "    quotient = result_length / num_distributed\n",
    "    num_filled = 0\n",
    "    if num_distributed < result_length:\n",
    "        num_repeats = list()\n",
    "        for i in range(1, num_distributed):\n",
    "            filled_space = quotient * i\n",
    "            print(filled_space)\n",
    "            truncated = int(filled_space)\n",
    "            num_repeats.append(truncated - num_filled)\n",
    "            num_filled = truncated\n",
    "        num_repeats.append(result_length - num_filled)\n",
    "    else:\n",
    "        num_repeats = [1] * result_length\n",
    "    map_ = list(itertools.chain(*[[i] * n_rep for i, n_rep in enumerate(num_repeats)]))\n",
    "    return map_\n",
    "\n",
    "print(create_distribute_map(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function f at 0x7ff2b407ac80>\n",
      "<function <lambda> at 0x7ff2b407ad90>\n",
      "<function <lambda> at 0x7ff2b407a9d8>\n",
      "<function f at 0x7ff2b407ac80>\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    pass\n",
    "h = f\n",
    "g = lambda x: x\n",
    "i = lambda x: x\n",
    "print(h)\n",
    "print(g)\n",
    "print(i)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^Mama и ^Папа\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Mama и Папа\"\n",
    "text = re.sub(\"([A-ZА-Я])\", r\"^\\1\", text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^a component of ^tool's song repertoire relies on the use of unusual time signatures. ^for instance, ^chancellor describes the time signature employed on the first single from ^lateralus, \"^schism\", as \"six\" and \"six-and-a-half\" and that it later \"goes into all kinds of other times\".[115] ^further examples include the album's title track, which also displays shifting rhythms,[115] as do 10,000 ^days: \"^wings for ^marie (^pt 1)\" and \"10,000 ^days (^wings ^pt 2)\".[116]\n",
      "\n",
      "A component of Tool's song repertoire relies on the use of unusual time signatures. For instance, Chancellor describes the time signature employed on the first single from Lateralus, \"Schism\", as \"six\" and \"six-and-a-half\" and that it later \"goes into all kinds of other times\".[115] Further examples include the album's title track, which also displays shifting rhythms,[115] as do 10,000 Days: \"Wings for Marie (Pt 1)\" and \"10,000 Days (Wings Pt 2)\".[116]\n"
     ]
    }
   ],
   "source": [
    "from helmo.util.text import preprocessing, postprocessing\n",
    "text = \"A component of Tool's song repertoire relies on the use of unusual time signatures. For instance, Chancellor describes the time signature employed on the first single from Lateralus, \\\"Schism\\\", as \\\"six\\\" and \\\"six-and-a-half\\\" and that it later \\\"goes into all kinds of other times\\\".[115] Further examples include the album's title track, which also displays shifting rhythms,[115] as do 10,000 Days: \\\"Wings for Marie (Pt 1)\\\" and \\\"10,000 Days (Wings Pt 2)\\\".[116]\"\n",
    "text = preprocessing.hat_uppercase(text)\n",
    "print(text)\n",
    "print()\n",
    "text = postprocessing.hat_uppercase(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'loss': 0.8077297808527947, 'bpc': 1.2, 'perplexity': 4.011995053052902, 'accuracy': 0.7565445318222046}], [], ['0'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_tt_results(result_dir, required_metric_names):\n",
    "    folders = filter(lambda x: x.isdigit(), os.listdir(result_dir))\n",
    "    metrics = list()\n",
    "    launches_for_testing = list()\n",
    "    trained_launches = list()\n",
    "    for folder in folders:\n",
    "        one_launch_metrics = dict()\n",
    "        path_to_metrics = os.path.join(result_dir, folder, 'testing/results')\n",
    "        if os.path.exists(path_to_metrics):\n",
    "            for metric_file in os.listdir(path_to_metrics):\n",
    "                metric_name = metric_file.split('_')[0]\n",
    "                with open(os.path.join(path_to_metrics, metric_file), 'r') as f:\n",
    "                    one_launch_metrics[metric_name] = float(f.read())\n",
    "        if set(required_metric_names) == set(one_launch_metrics.keys()):\n",
    "            metrics.append(one_launch_metrics)\n",
    "            trained_launches.append(folder)\n",
    "        elif len(one_launch_metrics) > 0:\n",
    "            launches_for_testing.append(folder)\n",
    "            trained_launches.append(folder)\n",
    "    return metrics, launches_for_testing, trained_launches\n",
    "\n",
    "\n",
    "required_metric_names = ['accuracy', 'bpc', 'perplexity', 'loss']\n",
    "result_dir = 'expres/resrnn/char/tt/first'\n",
    "print(load_tt_results(result_dir, required_metric_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: [1, 2, 3, 4]\n",
      "\n",
      "L2: [10, 11, 12]\n",
      "L1 after 'L1[:2] = L2': [10, 11, 12, 3, 4]\n",
      "\n",
      "L3: [-3, -4]\n",
      "L1 after 'L1[1:2] = L3': [10, -3, -4, 12, 3, 4]\n",
      "\n",
      "L4: [5, 6, 7, 8]\n",
      "L1 after 'L1[3:3] = L4': [10, -3, -4, 5, 6, 7, 8, 12, 3, 4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to assign sequence of size 2 to extended slice of size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-84da205e65ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L1 after 'L1[3:3] = L4':\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mL5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mL1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nL5:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L1 after 'L1[:-2:-1] = L5':\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to assign sequence of size 2 to extended slice of size 1"
     ]
    }
   ],
   "source": [
    "L1 = [1, 2, 3, 4]\n",
    "print(\"L1:\", L1)\n",
    "L2 = [10, 11, 12]\n",
    "L1[:2] = L2\n",
    "print(\"\\nL2:\", L2)\n",
    "print(\"L1 after 'L1[:2] = L2':\", L1)\n",
    "L3 = [-3, -4]\n",
    "L1[1:2] = L3\n",
    "print(\"\\nL3:\", L3)\n",
    "print(\"L1 after 'L1[1:2] = L3':\", L1)\n",
    "L4 = [5, 6, 7, 8]\n",
    "L1[3:3] = L4\n",
    "print(\"\\nL4:\", L4)\n",
    "print(\"L1 after 'L1[3:3] = L4':\", L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "from useful_functions import all_combs\n",
    "\n",
    "def create_even_distribution(num_unique_items, num_slots):\n",
    "    \"\"\"Returns a list with number of slots taken by each item. If num_slots < num_unique_items not all items\n",
    "    will be distributed\"\"\"\n",
    "    items_per_slot_float = num_slots / num_unique_items\n",
    "    total_slots_filled_saved = 0\n",
    "    if num_unique_items < num_slots:\n",
    "        item_distribution = list()\n",
    "        for i in range(1, num_unique_items):\n",
    "            total_slots_float = items_per_slot_float * i\n",
    "            total_slots_filled = int(total_slots_float)\n",
    "            item_distribution.append(total_slots_filled - total_slots_filled_saved)\n",
    "            total_slots_filled_saved = total_slots_filled\n",
    "        item_distribution.append(num_slots - total_slots_filled_saved)\n",
    "    else:\n",
    "        item_distribution = [1] * num_slots\n",
    "    return item_distribution\n",
    "\n",
    "\n",
    "def create_distribute_map(num_unique_items, num_slots):\n",
    "    item_distribution = create_even_distribution(num_unique_items, num_slots)\n",
    "    map_ = list(itertools.chain(*[[i] * n_rep for i, n_rep in enumerate(item_distribution)]))\n",
    "    return map_\n",
    "\n",
    "\n",
    "def approx_mem_consumption(config):\n",
    "    # in MB for sequence_length=100, batch_size=128, num_layers=2, num_units=2000\n",
    "    # working for all lstm variants\n",
    "    base_consumption = 4500\n",
    "    consumption = base_consumption * \\\n",
    "        (config['num_units'] / 2000)**2 * \\\n",
    "        (config['num_layers'] / 2) * \\\n",
    "        (config['batch_size'] / 128) * \\\n",
    "        (config['sequence_length'] / 100)\n",
    "    return consumption\n",
    "\n",
    "\n",
    "def num_consequent_repeats(list_, idx):\n",
    "    current = list_[idx]\n",
    "    i = 1\n",
    "    while list_[idx+i] == current:\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def ceil(a):\n",
    "    if int(a) != a:\n",
    "        return int(a) + 1\n",
    "    return int(a)\n",
    "\n",
    "\n",
    "def split_experiment_config_into_separate_measurement_configs(config):\n",
    "    seq_lens = make_list(config['sequence_length'])\n",
    "    batch_sizes = make_list(config['batch_size'])\n",
    "    num_layers = make_list(config['num_layers'])\n",
    "    num_units = make_list(config['num_units'])\n",
    "    combs = all_combs([seq_lens, batch_sizes, num_layers, num_units])\n",
    "    configs = list()\n",
    "    for comb in combs:\n",
    "        conf = copy.deepcopy(config)\n",
    "        conf['sequence_length'] = comb[0]\n",
    "        conf['batch_size'] = comb[1]\n",
    "        conf['num_layers'] = comb[2]\n",
    "        conf['num_units'] = comb[3]\n",
    "        configs.append(conf)\n",
    "    if config['num_repeats'] == 1:\n",
    "        return configs\n",
    "    else:\n",
    "        confs = list()\n",
    "        for conf in configs:\n",
    "            confs.extend([conf]*config['num_repeats'])\n",
    "        return confs\n",
    "\n",
    "\n",
    "def get_configs_run_in_parallel(configs, counter):\n",
    "    current_config = configs[counter]\n",
    "    max_num_in_parallel = current_config['memory_per_experiment'] / approx_mem_consumption(current_config)\n",
    "    num_repeats = num_consequent_repeats(configs, counter)\n",
    "    configs_to_process = configs[counter:counter+num_repeats]\n",
    "    num_launches_required = ceil(num_repeats / max_num_in_parallel)\n",
    "    distribution = create_even_distribution(num_launches_required, num_repeats)\n",
    "    list_of_launches = list()\n",
    "    pointer = 0\n",
    "    for num_proc in distribution:\n",
    "        list_of_launches.append(configs_to_process[pointer:pointer+num_proc])\n",
    "        pointer += num_proc\n",
    "    return list_of_launches, num_repeats\n",
    "\n",
    "\n",
    "def make_list(candidate):\n",
    "    if isinstance(candidate, list):\n",
    "        l = candidate\n",
    "    else:\n",
    "        l = [candidate]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"num_layers\": [3, 4],\n",
    "  \"num_units\": [1000, 2000],\n",
    "  \"sequence_length\": [50, 100],\n",
    "  \"batch_size\": [128],\n",
    "  \"save_path\": \"results/lstm_test\",\n",
    "  \"lstm_type\": \"cudnn_stacked\",\n",
    "  \"mode\": \"train\",\n",
    "  \"num_steps\": 500,\n",
    "  \"num_proc_in_pool\": 5,\n",
    "  \"num_repeats\": 10,\n",
    "  \"memory_per_experiment\": 7500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "\n",
      "\n",
      "1\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "{'num_units': 1000, 'num_steps': 500, 'num_layers': 3, 'memory_per_experiment': 7500, 'mode': 'train', 'sequence_length': 50, 'save_path': 'results/lstm_test', 'batch_size': 128, 'num_proc_in_pool': 5, 'lstm_type': 'cudnn_stacked', 'num_repeats': 10}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = split_experiment_config_into_separate_measurement_configs(config)\n",
    "launches = get_configs_run_in_parallel(configs, 0)\n",
    "for idx, launch in enumerate(launches[0]):\n",
    "    print(idx)\n",
    "    for conf in launch:\n",
    "        print(conf)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843.75\n"
     ]
    }
   ],
   "source": [
    "print(approx_mem_consumption(configs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "14\n",
      "58\n",
      "242\n",
      "994\n",
      "4034\n",
      "16258\n",
      "65282\n",
      "261634\n",
      "1047554\n",
      "4192258\n",
      "16773122\n",
      "67100674\n",
      "268419074\n",
      "1073709058\n",
      "4294901762\n",
      "17179738114\n",
      "68719214594\n",
      "274877382658\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(2**(2*i) - 2**i + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "4\n",
      "8\n",
      "14\n",
      "22\n",
      "32\n",
      "44\n",
      "58\n",
      "74\n",
      "92\n",
      "112\n",
      "134\n",
      "158\n",
      "184\n",
      "212\n",
      "242\n",
      "274\n",
      "308\n",
      "344\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i**2 - i + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_1/LSTMCellZeroState/zeros:0' shape=(10, 100) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_1/LSTMCellZeroState/zeros_1:0' shape=(10, 100) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_1/LSTMCellZeroState_1/zeros:0' shape=(10, 200) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_1/LSTMCellZeroState_1/zeros_1:0' shape=(10, 200) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_1/LSTMCellZeroState_2/zeros:0' shape=(10, 300) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_1/LSTMCellZeroState_2/zeros_1:0' shape=(10, 300) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.nn.rnn_cell import LSTMCell as LSTMCell\n",
    "lstms = [LSTMCell(num_units, dtype=tf.float32) for num_units in [100, 200, 300]]\n",
    "multilayer_lstm = tf.contrib.rnn.MultiRNNCell(lstms)\n",
    "print(multilayer_lstm.zero_state(10, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.Variable(0, trainable=False, validate_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "b = ([1], [2], [3])\n",
    "for k in zip(*b):\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_zip(objects, depth, passable_types=(list, tuple, dict)):\n",
    "    if depth != 0 and isinstance(objects[0], passable_types):\n",
    "        if isinstance(objects[0], (list, tuple)):\n",
    "            zipped = list()\n",
    "            for comb in zip(*objects):\n",
    "                zipped.append(\n",
    "                    deep_zip(comb, depth-1, passable_types=passable_types)\n",
    "                )\n",
    "            if isinstance(objects[0], tuple):\n",
    "                zipped = tuple(zipped)\n",
    "            return zipped\n",
    "        elif isinstance(objects[0], dict):\n",
    "            zipped = dict()\n",
    "            for key in objects[0].keys():\n",
    "                values = [obj[key] for obj in objects]\n",
    "                zipped[key] = deep_zip(values, depth-1, passable_types=passable_types)\n",
    "            return zipped\n",
    "    return tuple(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1, 5), (2, 6)), ([(3, 7), (9, 10)], (4, 8)), ({'a': 4}, {'a': 5})]\n"
     ]
    }
   ],
   "source": [
    "objects = [\n",
    "    [(1, 2), ([3, 9], 4), {'a': 4}],\n",
    "    [(5, 6), ([7, 10], 8), {'a': 5}],\n",
    "]\n",
    "depth = 10\n",
    "print(deep_zip(objects, depth, passable_types=(list, tuple)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_func_on_depth(obj, func, depth, passable_types=(list, tuple, dict)):\n",
    "    if depth != 0 and isinstance(obj, passable_types):\n",
    "        if isinstance(obj, (list, tuple)):\n",
    "            processed = list()\n",
    "            for elem in obj:\n",
    "                processed.append(apply_func_on_depth(elem, func, depth-1, passable_types=passable_types))\n",
    "            if isinstance(obj, tuple):\n",
    "                processed = tuple(processed)\n",
    "            return processed\n",
    "        elif isinstance(obj, dict):\n",
    "            processed = dict()\n",
    "            for key, value in obj.items():\n",
    "                processed[key] = apply_func_on_depth(value, func, depth-1, passable_types=passable_types)\n",
    "            return processed\n",
    "    return func(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1, 4), ([9, 81], 16), {'a': 16}], [(25, 36), ([49, 100], 64), {'a': 25}]]\n"
     ]
    }
   ],
   "source": [
    "obj = [\n",
    "    [(1, 2), ([3, 9], 4), {'a': 4}],\n",
    "    [(5, 6), ([7, 10], 8), {'a': 5}],\n",
    "]\n",
    "\n",
    "func = lambda x: x**2\n",
    "depth = 4\n",
    "print(apply_func_on_depth(obj, func, depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.Variable(0)\n",
    "ndim_tensor = tf.shape(tf.shape(a))\n",
    "is_scalar = tf.equal(tf.shape(tf.shape(a))[0], 0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(is_scalar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "f = lambda: 1\n",
    "print(f())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('a', 1), ('b', 2), ('c', 3))\n"
     ]
    }
   ],
   "source": [
    "a = {'a': 1, 'b': 2, 'c': 3}\n",
    "def f(*args):\n",
    "    print(args)\n",
    "\n",
    "f(*a.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f() got multiple values for argument 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-672cbc5cc0b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: f() got multiple values for argument 'a'"
     ]
    }
   ],
   "source": [
    "def f(a=1):\n",
    "    print(a)\n",
    "    \n",
    "kwargs = {'a': 2}\n",
    "\n",
    "f(4, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7d0be93e607d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "d = {([1, 2], [3, 4]): 1, ([5, 6], [7, 8]): 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(not 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f1aa3bad00e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "print(a['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "\n",
      "True\n",
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "\n",
    "# no exception\n",
    "sv = SimpleVocabulary(\n",
    "    load_path=\"file_which_does_not_exists\",\n",
    "    save_path=\"file_which_does_not_exists\"\n",
    ")\n",
    "print(sv.load_path.is_file())\n",
    "sv.load()\n",
    "print(len(sv))\n",
    "\n",
    "print()\n",
    "# exception\n",
    "sv = SimpleVocabulary(\n",
    "    load_path=\"no_such_dir/file_which_does_not_exists\",\n",
    "    save_path=\"no_such_dir/file_which_does_not_exists\"\n",
    ")\n",
    "print(sv.load_path.parent.is_dir())\n",
    "print(sv.load_path.is_file())\n",
    "sv.load()\n",
    "print(len(sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    user_paths = os.environ['PYTHONPATH'].split(os.pathsep)\n",
    "except KeyError:\n",
    "    user_paths = []\n",
    "print(user_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 3), (2, 2), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "l = [1, 2, 3, 2, 1, 1]\n",
    "freqs = Counter(chain(l))\n",
    "print(list(freqs.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'abc\\ndef'\n",
      "abc\n",
      "def\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s0 = 'abc\\ndef'\n",
    "s1 = repr(s0)\n",
    "print(s1)\n",
    "s2 = bytes(s, \"utf-8\").decode(\"unicode_escape\")\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a: int) -> int:\n",
    "    print(a)\n",
    "    return [3]\n",
    "    \n",
    "f([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccaccbaaba\n",
      "str32\n",
      "str\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5311f1a67660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab = ['a', 'b', 'c']\n",
    "a = np.random.rand(10, 3)\n",
    "def f(vec):\n",
    "    return vocab[np.argmax(vec)]\n",
    "b = np.apply_along_axis(f, -1, a)\n",
    "print(''.join(b))\n",
    "print(b.dtype.name)\n",
    "print(np.dtype(str).name)\n",
    "print(np.dtype(np.array(['a', 'b'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'filter' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6c742d016971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'filter' has no len()"
     ]
    }
   ],
   "source": [
    "print(len(filter(abs, [1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "a\n",
      "b\n",
      "('a', 'a')\n",
      "('b', 'b')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.nn.rnn_cell import LSTMStateTuple as LSTMStateTuple\n",
    "t1 = LSTMStateTuple(h='b', c='a')\n",
    "t2 = LSTMStateTuple(c='a', h='b')\n",
    "print(isinstance(t1, tuple))\n",
    "for e in t1:\n",
    "    print(e)\n",
    "for e in zip(t1, t2):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-13 15:26:54.204 WARNING in 'tensorflow'['tf_logging'] at line 120: <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f8bfc62b940>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "var and delta do not have the same shape[10,20] []\n\t [[Node: GradientDescent/update_state/ApplyGradientDescent = ApplyGradientDescent[T=DT_FLOAT, use_locking=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](state, GradientDescent/learning_rate, gradients/cond/Reshape/Switch_grad/cond_grad)]]\n\nCaused by op 'GradientDescent/update_state/ApplyGradientDescent', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-21777d4be57d>\", line 76, in <module>\n    train_op = opt.apply_gradients(grads_and_vars)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 605, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 114, in update_op\n    update_op = optimizer._apply_dense(g, self._v)  # pylint: disable=protected-access\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/gradient_descent.py\", line 60, in _apply_dense\n    use_locking=self._use_locking).op\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/gen_training_ops.py\", line 576, in apply_gradient_descent\n    use_locking=use_locking, name=name)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): var and delta do not have the same shape[10,20] []\n\t [[Node: GradientDescent/update_state/ApplyGradientDescent = ApplyGradientDescent[T=DT_FLOAT, use_locking=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](state, GradientDescent/learning_rate, gradients/cond/Reshape/Switch_grad/cond_grad)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: var and delta do not have the same shape[10,20] []\n\t [[Node: GradientDescent/update_state/ApplyGradientDescent = ApplyGradientDescent[T=DT_FLOAT, use_locking=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](state, GradientDescent/learning_rate, gradients/cond/Reshape/Switch_grad/cond_grad)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-21777d4be57d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: var and delta do not have the same shape[10,20] []\n\t [[Node: GradientDescent/update_state/ApplyGradientDescent = ApplyGradientDescent[T=DT_FLOAT, use_locking=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](state, GradientDescent/learning_rate, gradients/cond/Reshape/Switch_grad/cond_grad)]]\n\nCaused by op 'GradientDescent/update_state/ApplyGradientDescent', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-21777d4be57d>\", line 76, in <module>\n    train_op = opt.apply_gradients(grads_and_vars)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 605, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 114, in update_op\n    update_op = optimizer._apply_dense(g, self._v)  # pylint: disable=protected-access\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/gradient_descent.py\", line 60, in _apply_dense\n    use_locking=self._use_locking).op\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/gen_training_ops.py\", line 576, in apply_gradient_descent\n    use_locking=use_locking, name=name)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): var and delta do not have the same shape[10,20] []\n\t [[Node: GradientDescent/update_state/ApplyGradientDescent = ApplyGradientDescent[T=DT_FLOAT, use_locking=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](state, GradientDescent/learning_rate, gradients/cond/Reshape/Switch_grad/cond_grad)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def is_scalar_tensor(t):\n",
    "    return tf.equal(tf.shape(tf.shape(t))[0], 0)\n",
    "\n",
    "\n",
    "def replace_empty_saved_state(saved_and_zero_state):\n",
    "    return tf.cond(\n",
    "        is_scalar_tensor(saved_and_zero_state[0]),\n",
    "        true_fn=lambda: saved_and_zero_state[1],\n",
    "        false_fn=lambda: tf.reshape(saved_and_zero_state[0], tf.shape(saved_and_zero_state[1])),\n",
    "    )\n",
    "\n",
    "def synchronous_flatten(*nested):\n",
    "    if not isinstance(nested[0], (tuple, list, dict)):\n",
    "        return [[n] for n in nested]\n",
    "    output = [list() for _ in nested]\n",
    "    if isinstance(nested[0], dict):\n",
    "        for k in nested[0].keys():\n",
    "            flattened = synchronous_flatten(*[n[k] for n in nested])\n",
    "            for o, f in zip(output, flattened):\n",
    "                o.extend(f)\n",
    "    else:\n",
    "        try:\n",
    "            for inner_nested in zip(*nested):\n",
    "                flattened = synchronous_flatten(*inner_nested)\n",
    "                for o, f in zip(output, flattened):\n",
    "                    o.extend(f)\n",
    "        except TypeError:\n",
    "            print('(synchronous_flatten)nested:', nested)\n",
    "            raise\n",
    "    return output\n",
    "\n",
    "def compose_save_list(*pairs, name_scope='save_list'):\n",
    "    with tf.name_scope(name_scope):\n",
    "        save_list = list()\n",
    "        for pair in pairs:\n",
    "            # print('pair:', pair)\n",
    "            [variables, new_values] = synchronous_flatten(pair[0], pair[1])\n",
    "            # print(\"(useful_functions.compose_save_list)variables:\", variables)\n",
    "            # variables = flatten(pair[0])\n",
    "            # # print(variables)\n",
    "            # new_values = flatten(pair[1])\n",
    "            for variable, value in zip(variables, new_values):\n",
    "                save_list.append(tf.assign(variable, value, validate_shape=False))\n",
    "        return save_list\n",
    "\n",
    "# saved_state = (\n",
    "#     tf.Variable(0., validate_shape=False, trainable=False, name='state'),\n",
    "#     tf.Variable(0., validate_shape=False, trainable=False, name='state')\n",
    "# )\n",
    "saved_state = tf.Variable(0., validate_shape=False, trainable=False, name='state')\n",
    "\n",
    "lstm = tf.nn.rnn_cell.LSTMCell(10, state_is_tuple=False)\n",
    "\n",
    "inp = tf.zeros([100, 10, 13])\n",
    "zero_state = lstm.zero_state(tf.shape(inp)[1], tf.float32)\n",
    "\n",
    "# state = [\n",
    "#     replace_empty_saved_state([s, z]) for s, z in zip(saved_state, zero_state)\n",
    "# ]\n",
    "state = replace_empty_saved_state([saved_state, zero_state])\n",
    "output, new_state = tf.nn.dynamic_rnn(\n",
    "    lstm, inp, initial_state=state, parallel_iterations=1024, time_major=True\n",
    ")\n",
    "\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(1.)\n",
    "\n",
    "save_list = compose_save_list((saved_state, new_state))\n",
    "with tf.control_dependencies(save_list):\n",
    "    loss = tf.reduce_sum(output)\n",
    "    grads_and_vars = opt.compute_gradients(loss, var_list=tf.global_variables())\n",
    "    grads_and_vars = [(grad, var) for grad, var in grads_and_vars if grad is not None]\n",
    "    train_op = opt.apply_gradients(grads_and_vars)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        sess.run(train_op)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "object\n",
      "object\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "indices_batch = np.array([None, None])\n",
    "print(indices_batch[0] is None)\n",
    "a = np.array([1, 2])\n",
    "for i in np.nditer(indices_batch, flags=['refs_ok']):\n",
    "    print(i.dtype.name)\n",
    "for i in np.nditer(a, flags=['refs_ok']):\n",
    "    print(i.dtype.name)\n",
    "if any([i is None for i in np.nditer(indices_batch, flags=['refs_ok'])]):\n",
    "    print('!')\n",
    "    g = np.vectorize(lambda x: x is None)\n",
    "    mask = g(indices_batch)\n",
    "    print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n"
     ]
    }
   ],
   "source": [
    "print(repr('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]] [[1 4]\n",
      " [2 5]\n",
      " [3 6]] \n",
      "\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]] [[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]] \n",
      "\n",
      "[[2 2]\n",
      " [2 2]\n",
      " [2 2]] \n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[[1, 4], [2, 5], [3, 6]], [[7, 8], [9, 10], [11, 12]]])\n",
    "b = np.reshape(a, (-1, a.shape[-1]))\n",
    "correct = sum([y1 == y2 for y1, y2 in zip(a, a)])\n",
    "for y1, y2 in zip(a, a):\n",
    "    print(y1, y2, '\\n')\n",
    "print(correct, '\\n')\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from deeppavlov.core.common.log import get_logger\n",
    "\n",
    "\n",
    "def prepare_for_accuracy_computation(y_true, y_predicted):\n",
    "    log = get_logger(__name__)\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        y_true = np.array(y_true)\n",
    "    if not isinstance(y_predicted, np.ndarray):\n",
    "        y_predicted = np.array(y_predicted)\n",
    "    num_examples = y_true.size\n",
    "    if y_true.size != y_predicted.size:\n",
    "        num_examples = min(y_true.size, y_predicted.size)\n",
    "        log.warning(\n",
    "            \"Number of elements in y_true and in y_predicted are not equal\\n\"\n",
    "            \"y_true.size = {}, y_predicted.size = {}\\n\"\n",
    "            \"Using first {} elements of y_true and y_predicted\".format(\n",
    "                y_true.size, y_predicted.size, num_examples,\n",
    "            )\n",
    "        )\n",
    "        y_true, y_predicted = np.reshape(y_true, (-1)), np.reshape(y_predicted, (-1))\n",
    "        y_true, y_predicted = y_true[:num_examples], y_predicted[:num_examples]\n",
    "    if y_true.shape != y_predicted.shape:\n",
    "        log.warning(\n",
    "            \"y_true and y_predicted have different shapes\\ny_true.shape = {}, y_predicted.shape = {}\\n\"\n",
    "            \"Reshaping y_true to y_predicted.shape\".format(y_true.shape, y_predicted.shape)\n",
    "        )\n",
    "        y_true = np.reshape(y_true, y_predicted.shape)\n",
    "    return y_true, y_predicted, num_examples\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    Calculate accuracy in terms of absolute coincidence\n",
    "\n",
    "    Args:\n",
    "        y_true: array of true values\n",
    "        y_predicted: array of predicted values\n",
    "\n",
    "    Returns:\n",
    "        portion of absolutely coincidental samples\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true, y_predicted, num_examples = prepare_for_accuracy_computation(y_true, y_predicted)\n",
    "    correct = np.sum(y_true == y_predicted)\n",
    "    return correct / num_examples if num_examples else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-13 14:25:53.122 WARNING in '__main__'['<ipython-input-35-9e32c49161a5>'] at line 22: Number of elements in y_true and in y_predicted are not equal\n",
      "y_true.size = 3, y_predicted.size = 0\n",
      "Using first 0 elements of y_true and y_predicted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[1, 2, 4]])\n",
    "y_predicted = []\n",
    "print(accuracy(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/dpenv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/anton/dpenv/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.array([])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "l = []\n",
    "l += list(a)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "a\n",
      "<class 'numpy.ndarray'>\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array(['a', 'b'])\n",
    "for e in np.nditer(a):\n",
    "    print(type(e))\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    global tf\n",
    "    import tensorflow as tf\n",
    "f()   \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cudnn_lstm_1/CudnnRNN:0\", shape=(?, ?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.cudnn_rnn import CudnnLSTM as CudnnLSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm = CudnnLSTM(1, 100)\n",
    "inp = tf.placeholder(shape=[None, None, 31], dtype=tf.float32)\n",
    "output, state = lstm(inp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'split:0' shape=(100, 50) dtype=float32>, <tf.Tensor 'split:1' shape=(0, 50) dtype=float32>]\n",
      "Tensor(\"MatMul_2:0\", shape=(0, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.zeros([0, 100])\n",
    "b = tf.ones([100, 50])\n",
    "d = tf.split(b, [100, 0], axis=0)\n",
    "print(d)\n",
    "c = tf.matmul(a, b)\n",
    "print(c)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import turtle\n",
    "turtle.shape('turtle')\n",
    "a = 50\n",
    "for i in range(360):\n",
    "    t = i * math.pi/180\n",
    "    x = 2*a*math.cos(t) - a*math.cos(2*t) - a\n",
    "    y = 2*a*math.sin(t) - a*math.sin(2*t)\n",
    "    turtle.goto(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid reduction dimension 4 for input with 3 dimensions. for 'Mean_2' (op: 'Mean') with input shapes: [100,100,100], [] and with computed input tensors: input[1] = <4>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1588\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension 4 for input with 3 dimensions. for 'Mean_2' (op: 'Mean') with input shapes: [100,100,100], [] and with computed input tensors: input[1] = <4>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-26f2e4bc7d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 instructions)\n\u001b[0;32m--> 432\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    434\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name, reduction_indices, keep_dims)\u001b[0m\n\u001b[1;32m   1451\u001b[0m                                                   reduction_indices),\n\u001b[1;32m   1452\u001b[0m                                    \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                    name=name))\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   4494\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4495\u001b[0m         \u001b[0;34m\"Mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4496\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4497\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4498\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3414\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1756\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1757\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid reduction dimension 4 for input with 3 dimensions. for 'Mean_2' (op: 'Mean') with input shapes: [100,100,100], [] and with computed input tensors: input[1] = <4>."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.zeros([100, 100, 100])\n",
    "b = tf.reduce_mean(a, axis=tf.constant([1, 2]))\n",
    "c = tf.reduce_mean(a, axis=4)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import turtle\n",
    "turtle.shape('turtle')\n",
    "turtle.forward(50)\n",
    "turtle.left(90)\n",
    "turtle.forward(50)\n",
    "turtle.left(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.left(90)\n",
    "turtle.forward(50)\n",
    "turtle.left(90)\n",
    "turtle.forward(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "turtle.shape('turtle')\n",
    "turtle.forward(50)\n",
    "turtle.left(90)\n",
    "turtle.forward(50)\n",
    "turtle.left(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.right(90)\n",
    "turtle.forward(50)\n",
    "turtle.left(90)\n",
    "turtle.forward(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import turtle\n",
    "x = 0\n",
    "y = 0\n",
    "a = 100\n",
    "turtle.reset\n",
    "turtle.down\n",
    "for i in range(0, 360):\n",
    "    x = 2*a*math.cos(math.radians(i))-a*math.cos(2*math.radians(i))\n",
    "    y = 2*a*math.sin(math.radians(i))-a*math.sin(2*math.radians(i))\n",
    "    turtle.goto(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import turtle\n",
    "x = 0\n",
    "y = 0\n",
    "a = 100\n",
    "turtle.reset\n",
    "turtle.down\n",
    "for i in range(0, 360):\n",
    "    x = 2*a*math.cos(math.radians(i))-a*math.cos(2*math.radians(i))\n",
    "    y = 2*a*math.sin(math.radians(i))-a*math.sin(2*math.radians(i))\n",
    "    turtle.goto(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "введите число 0=exit : 100\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "[1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f=True\n",
    "\n",
    "while f:\n",
    "    n=int(input('введите число 0=exit : '))\n",
    "    if n==0: break\n",
    "    a= [i for i in range(n+1)]\n",
    "    b=[]\n",
    "    print (a)\n",
    "\n",
    "    for i in range(2,n):\n",
    "        if (i**2<=n) and (a[i]!=0):\n",
    "            for j in range(i**2,n+1,i):\n",
    "                a[j]=0\n",
    "            #print(a)    \n",
    "    for i in range(n+1):\n",
    "        if a[i]!=0:\n",
    "            b.append(a[i])              \n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'ArgMax': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT64]\n\n\t [[Node: ArgMax = ArgMax[T=DT_INT32, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/device:GPU:0\"](Placeholder, ArgMax/dimension)]]\n\nCaused by op 'ArgMax', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-565a258acdcc>\", line 5, in <module>\n    b = tf.argmax(a, axis=-1)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 88, in argmax\n    return gen_math_ops.arg_max(input, axis, name=name, output_type=output_type)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 783, in arg_max\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'ArgMax': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT64]\n\n\t [[Node: ArgMax = ArgMax[T=DT_INT32, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/device:GPU:0\"](Placeholder, ArgMax/dimension)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'ArgMax': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT64]\n\n\t [[Node: ArgMax = ArgMax[T=DT_INT32, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/device:GPU:0\"](Placeholder, ArgMax/dimension)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-565a258acdcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'ArgMax': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT64]\n\n\t [[Node: ArgMax = ArgMax[T=DT_INT32, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/device:GPU:0\"](Placeholder, ArgMax/dimension)]]\n\nCaused by op 'ArgMax', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-565a258acdcc>\", line 5, in <module>\n    b = tf.argmax(a, axis=-1)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 88, in argmax\n    return gen_math_ops.arg_max(input, axis, name=name, output_type=output_type)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 783, in arg_max\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'ArgMax': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nRegistered kernels:\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_FLOAT]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT32]; Tidx in [DT_INT32]\n  device='GPU'; T in [DT_HALF]; output_type in [DT_INT64]; Tidx in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_DOUBLE]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_FLOAT]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_BFLOAT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_HALF]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT8]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_UINT16]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT32]; output_type in [DT_INT64]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT32]\n  device='CPU'; T in [DT_INT64]; output_type in [DT_INT64]\n\n\t [[Node: ArgMax = ArgMax[T=DT_INT32, Tidx=DT_INT32, output_type=DT_INT64, _device=\"/device:GPU:0\"](Placeholder, ArgMax/dimension)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.placeholder(tf.int32)\n",
    "    b = tf.argmax(a, axis=-1)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(b, feed_dict={a: np.zeros(shape=(10, 20, 100), dtype=np.int32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [], 'b': []}\n"
     ]
    }
   ],
   "source": [
    "d = {k: list() for k in {'a': 1, 'b': 2}.keys()}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value recall_1/true_positives/count\n\t [[Node: recall_1/true_positives/count/read = Identity[T=DT_FLOAT, _class=[\"loc:@recall_1/true_positives/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](recall_1/true_positives/count)]]\n\t [[Node: recall_1/value/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_58_recall_1/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'recall_1/true_positives/count/read', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9fd5e458e749>\", line 5, in <module>\n    recall=tf.metrics.recall(b,a)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 2106, in recall\n    name=None)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 1807, in true_positives\n    updates_collections)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 1407, in _count_condition\n    count = metric_variable([], dtypes.float32, name='count')\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 51, in metric_variable\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2234, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2224, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2207, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 422, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 79, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3263, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value recall_1/true_positives/count\n\t [[Node: recall_1/true_positives/count/read = Identity[T=DT_FLOAT, _class=[\"loc:@recall_1/true_positives/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](recall_1/true_positives/count)]]\n\t [[Node: recall_1/value/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_58_recall_1/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value recall_1/true_positives/count\n\t [[Node: recall_1/true_positives/count/read = Identity[T=DT_FLOAT, _class=[\"loc:@recall_1/true_positives/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](recall_1/true_positives/count)]]\n\t [[Node: recall_1/value/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_58_recall_1/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9fd5e458e749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minit_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value recall_1/true_positives/count\n\t [[Node: recall_1/true_positives/count/read = Identity[T=DT_FLOAT, _class=[\"loc:@recall_1/true_positives/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](recall_1/true_positives/count)]]\n\t [[Node: recall_1/value/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_58_recall_1/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'recall_1/true_positives/count/read', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9fd5e458e749>\", line 5, in <module>\n    recall=tf.metrics.recall(b,a)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 2106, in recall\n    name=None)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 1807, in true_positives\n    updates_collections)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 1407, in _count_condition\n    count = metric_variable([], dtypes.float32, name='count')\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 51, in metric_variable\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2234, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2224, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2207, in default_variable_creator\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 422, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 79, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3263, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value recall_1/true_positives/count\n\t [[Node: recall_1/true_positives/count/read = Identity[T=DT_FLOAT, _class=[\"loc:@recall_1/true_positives/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](recall_1/true_positives/count)]]\n\t [[Node: recall_1/value/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_58_recall_1/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a=tf.Variable(tf.constant([0.,1.,2.]))\n",
    "b=tf.Variable(tf.constant([1.,1.,1.]))\n",
    "recall=tf.metrics.recall(b,a)\n",
    "\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run([init_g])\n",
    "    rec=sess.run(recall)\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "d = {'a': 1}\n",
    "print(hasattr(d, '__setitem__'))\n",
    "l = []\n",
    "print(hasattr(l, 'append'))\n",
    "print(hasattr(l, '__getitem__'))\n",
    "print(hasattr(l, '__setitem__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "d = OrderedDict([('a', 1)])\n",
    "print(isinstance(d, dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parent directory of test_cudnn_lstm_save doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/transpose/_1, cudnn_lstm/concat_5/_3, cudnn_lstm_1/transpose/_5, cudnn_lstm_1/concat_5/_7)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1651\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/transpose/_1, cudnn_lstm/concat_5/_3, cudnn_lstm_1/transpose/_5, cudnn_lstm_1/concat_5/_7)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-acc1ee31cbc9>\", line 10, in <module>\n    [lstm1.saveable, lstm2.saveable]\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1296, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1333, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 278, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 194, in save_op\n    tensors)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1687, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/transpose/_1, cudnn_lstm/concat_5/_3, cudnn_lstm_1/transpose/_5, cudnn_lstm_1/concat_5/_7)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-acc1ee31cbc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1668\u001b[0m                   save_path))\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of test_cudnn_lstm_save doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.cudnn_rnn import CudnnLSTM as CudnnLSTM\n",
    "inp = tf.zeros([10, 32, 100])\n",
    "lstm1 = CudnnLSTM(1, 128)\n",
    "lstm2 = CudnnLSTM(1, 256)\n",
    "_, _ = lstm1(inp)\n",
    "_, _ = lstm2(inp)\n",
    "saver = tf.train.Saver(\n",
    "    [lstm1.saveable, lstm2.saveable]\n",
    ")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    save_path = 'test_cudnn_lstm_save'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print([1, 2] == (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400000\n"
     ]
    }
   ],
   "source": [
    "print(int(6.4e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/h-elmo/helmo/experiments/test.py\n",
      "/home/anton/h-elmo/abc/def\n"
     ]
    }
   ],
   "source": [
    "import helmo.experiments.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "l = [1, 2]\n",
    "print(l and True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/', '')\n",
      "('/', 'home')\n",
      "/home\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.split('/'))\n",
    "print(os.path.split('/home'))\n",
    "print(os.path.join('/', 'home'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/', 'home', 'peganov']\n",
      "['home', 'peganov']\n",
      "['~', 'peganov']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def full_path_split(path):\n",
    "    splitted_path = list()\n",
    "    head, tail = os.path.split(path)\n",
    "    while len(head) > 0 and len(tail) > 0:\n",
    "        splitted_path = [tail] + splitted_path\n",
    "        head, tail = os.path.split(head)\n",
    "    splitted_path = [head] + splitted_path if len(head) > 0 else [tail] + splitted_path\n",
    "    return splitted_path\n",
    "\n",
    "print(full_path_split('/home/peganov'))\n",
    "print(full_path_split('home/peganov'))\n",
    "print(full_path_split('~/peganov'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = False\n",
    "b = ''\n",
    "print(a is False)\n",
    "print(b is False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "s = {'c', 'a', 'b'}\n",
    "print(sorted(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn_lstm_1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.cudnn_rnn import CudnnLSTM as CudnnLSTM\n",
    "lstm = CudnnLSTM(1, 100)\n",
    "print(lstm.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Determinant(M):                                                 # список из списков-строк\n",
    "    if len(M[0]) == 1:\n",
    "        return(M[0])\n",
    "    elif len(M[0]) == 2:\n",
    "        return M[0][0] * M[1][1] - M[0][1]*M[1][0]    \n",
    "    else:                                                          # раскладываем по первой строке\n",
    "        \n",
    "        MatrixLength = len(M)\n",
    "        det = 0\n",
    "        for ind, el in enumerate(M[0]):                            # итерируемся по минорам\n",
    "            Minor = []\n",
    "            for i in range (1, MatrixLength):                       # итерируемся по строкам\n",
    "                MatrixString = []\n",
    "                for j in range(MatrixLength):\n",
    "                    if not (j == ind):\n",
    "                        MatrixString.append(M[i][j])  \n",
    "                Minor.append(MatrixString) \n",
    "            det += (-1)**ind * el * Determinant(Minor)\n",
    "        return (det)\n",
    "            \n",
    "print(Determinant([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(Determinant([[2, 2, 2], [1, 1, 1], [1, 2, 3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def Determinant(M):                                                 # список из списков-строк\n",
    "    if len(M[0]) == 1:\n",
    "        return(M[0])\n",
    "    elif len(M[0]) == 2:\n",
    "        return M[0][0] * M[1][1] - M[0][1]*M[1][0]    \n",
    "    else:                                                          # раскладываем по первой строке\n",
    "        \n",
    "        num_rows = len(M)\n",
    "        det = 0\n",
    "        for c_i, el in enumerate(M[0]):                            # итерируемся по минорам\n",
    "            submatrix = []\n",
    "            for r_i in range (1, num_rows):                       # итерируемся по строкам\n",
    "                submatrix.append(M[r_i][:c_i] + M[r_i][c_i+1:])\n",
    "            det += (-1)**c_i * el * Determinant(submatrix)\n",
    "        return (det)\n",
    "    \n",
    "print(Determinant([[2, 2, 2], [1, 1, 1], [1, 2, 3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5 5 5 5 5 5 5 2\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "a[i]  5\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 2] 10\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = [int(e) for e in input().split()]\n",
    "b = []\n",
    "for i in range(len(a)-1):\n",
    "    if a[i] > 2 or (a[i] == 2 and a[i+1] == 2):\n",
    "        print('a[i] ', a[i])\n",
    "        b.append(a[i])\n",
    "       \n",
    "print(a,len(a))\n",
    "print((sum(b)+a[len(a)-1])//(len(b)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
