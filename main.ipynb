{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_relevant_activations(data, markup_for_tag):\n",
    "    result = []\n",
    "    for i, tag in enumerate(markup_for_tag):\n",
    "        if tag != 0:\n",
    "            result.append(data[i])\n",
    "    return np.stack(result)\n",
    "\n",
    "\n",
    "def get_matches(activations, markup):\n",
    "    markup = np.array(markup)\n",
    "    markup_devs = markup - np.mean(markup)\n",
    "    activation_devs = activations - np.mean(activations, 0, keepdims=True)\n",
    "    activation_stddevs = np.std(activations, 0, ddof=1, keepdims=True)\n",
    "    markup_stddev = np.std(markup, ddof=1)\n",
    "    activation_dev_fractions = activation_devs / (activation_stddevs + 1e-20)\n",
    "    markup_dev_fractions = markup_devs / (markup_stddev + 1e-20)\n",
    "    return activation_dev_fractions * np.reshape(markup_dev_fractions, [-1, 1])\n",
    "\n",
    "\n",
    "def compute_stats(data, markup_for_tag):\n",
    "    markup_for_tag = np.array(markup_for_tag)\n",
    "    stats = {}\n",
    "    stats['markup'] = markup_for_tag\n",
    "    stats['relevant_markup'] = list(filter(lambda x: x != 0, markup_for_tag))\n",
    "    stats['relevant_activations'] = get_relevant_activations(data, markup_for_tag)\n",
    "    stats['matches'] = get_matches(stats['relevant_activations'], stats['relevant_markup'])\n",
    "    stats['correlations'] = np.mean(stats['matches'], 0)\n",
    "    assert stats['correlations'].ndim == 1\n",
    "    stats['match_stddevs'] = np.std(stats['matches'], 0)\n",
    "    stats['mean_square_correlation'] = np.sqrt(np.mean(stats['correlations']**2))\n",
    "    stats['meta'] = {\n",
    "        \"positive\": np.count_nonzero(markup_for_tag == 1),\n",
    "        \"negative\": np.count_nonzero(markup_for_tag == -1),\n",
    "        \"total\": len(stats['markup']),\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "os.makedirs('test', exist_ok=True)\n",
    "\n",
    "with open(\"test/test.pickle\", 'wb') as f:\n",
    "    pickle.dump(np.array([[4]*10]*50), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "итого 8\r\n",
      "-rw-rw-r-- 1 anton anton 4160 июн  7 11:29 test.pickle\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_axis_quarters(tensor):\n",
    "    last_dim = tf.shape(tensor, out_type=tf.float32)[-1]\n",
    "    exponents = tf.range(0., last_dim, 1., dtype=tf.float32)\n",
    "    powers = tf.math.pow(2., exponents)\n",
    "    binary_format = tf.cast(tensor > 0, tf.float32)\n",
    "    linear_combination = powers * binary_format\n",
    "    numbers = tf.reduce_sum(linear_combination, axis=-1)\n",
    "    return tf.cast(numbers, tf.int32)\n",
    "\n",
    "tensor = tf.constant(\n",
    "    [[1, -1, 1],\n",
    "     [-1, -1, -1]]\n",
    ")\n",
    "\n",
    "axis_quarters = get_axis_quarters(tensor)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(axis_quarters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "prefix = '/media/anton/DATA/results/h-elmo/expres/resrnn/poscorr/4/9/corr/level1_1/NNS'\n",
    "\n",
    "tmpl = os.path.join(prefix, '{}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = tmpl.format('correlations')\n",
    "with open(file_name, 'rb') as f:\n",
    "    corr = pickle.load(f)\n",
    "    \n",
    "print(max(corr))\n",
    "print(np.argmax(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1, 2: 1, 3: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "\n",
    "c = Counter(a)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08246549  0.02131961  0.08308583 ... -0.55830922  0.02906624\n",
      "  0.02100856]\n",
      "18.750923953380248\n",
      "50567\n",
      "-13.644160917601068\n",
      "52351\n"
     ]
    }
   ],
   "source": [
    "matches = tmpl.format('matches')\n",
    "with open(matches, 'rb') as f:\n",
    "    m = pickle.load(f)\n",
    "\n",
    "m62 = m[:, 62]\n",
    "print(m62)\n",
    "print(max(m62))\n",
    "print(np.argmax(m62))\n",
    "print(min(m62))\n",
    "print(np.argmin(m62))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.387342495802599\n"
     ]
    }
   ],
   "source": [
    "print(np.std(m62))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0\n",
    "f1 = m62[m62 > threshold]\n",
    "f2 = m62[m62 <= -threshold]\n",
    "filtered = np.concatenate([f1, f2])\n",
    "plt.hist(filtered, bins=100, density=True)\n",
    "plt.grid()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('matches')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = tmpl.format('relevant_activations')\n",
    "with open(act, 'rb') as f:\n",
    "    act = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup = tmpl.format('relevant_markup')\n",
    "with open(markup, 'rb') as f:\n",
    "    markup = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "act62 = act[:, 62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(act62, bins=100, density=True)\n",
    "plt.grid()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('activations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm62' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-934192da9a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdensity_plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdensity_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm62\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm62' is not defined"
     ]
    }
   ],
   "source": [
    "from helmo.util.plot.plot_helpers import density_plot\n",
    "\n",
    "density_plot(m62, 0.001, None, 'blue')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('matches')\n",
    "plt.ylabel('density')\n",
    "plt.grid()\n",
    "plt.savefig(\n",
    "    '/media/anton/DATA/results/h-elmo/expres/resrnn/poscorr/4/9/corr/level1_1/NNS/plots/matches.png',\n",
    "    dpi=900\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helmo.util.plot.plot_helpers import density_plot\n",
    "\n",
    "density_plot(act62, 0.0001, None, 'blue')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('activations')\n",
    "plt.ylabel('density')\n",
    "plt.grid()\n",
    "plt.savefig(\n",
    "    '/media/anton/DATA/results/h-elmo/expres/resrnn/poscorr/4/9/corr/level1_1/NNS/plots/activations.png',\n",
    "    dpi=900\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helmo.util.plot.plot_helpers import density_plot\n",
    "\n",
    "selected_indices = np.array(np.array(markup) + 1, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nns_act62 = act62[selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7996,)\n",
      "[ 0.03987525  0.24359564  0.13936374  0.01275242  0.33905667  0.23092057\n",
      "  0.49802893  0.7179312   0.6440741   0.72047305  0.68238884  0.27751622\n",
      "  0.7226443   0.66829014  0.6769268   0.35996893  0.62734854  0.4216515\n",
      "  0.53920376 -0.07121509  0.5742651   0.7341397   0.23616292  0.7350702\n",
      "  0.13083465  0.35654765  0.5455406   0.41869763  0.5783358   0.61539644\n",
      "  0.6135536   0.62634987  0.23542795  0.21027555  0.6333601   0.036227\n",
      "  0.43719196  0.35494202  0.13239472  0.6450477   0.7428283   0.7066073\n",
      "  0.6975089   0.28573078  0.42003262  0.20334533  0.45254168  0.40931424\n",
      "  0.15804431  0.5475083   0.12762508  0.30116114  0.46461856  0.6587762\n",
      "  0.34424582  0.47947675  0.7382973   0.43743163  0.48655224  0.3983338\n",
      "  0.6633929   0.5986025   0.6500519   0.72113675  0.61620504  0.70613456\n",
      "  0.02858962  0.5844811   0.5168905   0.2948563   0.41682157  0.40695137\n",
      "  0.5016543   0.3709565   0.7006538   0.62645507 -0.00999689  0.631873\n",
      "  0.37047824  0.10538723 -0.12101641  0.3286183   0.73879755  0.419461\n",
      " -0.18268616  0.48435506  0.57082313  0.4695439   0.66903937  0.2646437\n",
      "  0.5649067   0.57630575  0.02788873  0.572275    0.13611141  0.40970537\n",
      "  0.40464735  0.66551423  0.59703594  0.6573207 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(nns_act62.shape)\n",
    "print(nns_act62[:100])\n",
    "min_ = np.min(act62)\n",
    "max_ = np.max(act62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "density_plot(act62, 0.0001, 'all activations', 'blue')\n",
    "density_plot(nns_act62, 0.0001, 'NNS activations', 'red', [min_, max_])\n",
    "plt.yscale('log')\n",
    "plt.xlabel('activations')\n",
    "plt.ylabel('density')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\n",
    "    os.path.join(prefix, 'plots/activations_and_nns_activations.png'),\n",
    "    dpi=900\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [0.01*i for i in range(-200, 200)]\n",
    "y = [1 / np.log(abs(xx-1.)) for xx in x]\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! export PYTHONPATH=\"~/h-elmo:~/learning-to-learn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "! echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = m[m > 1.]\n",
    "f2 = m[m < -1.]\n",
    "filtered = np.concatenate([f1, f2])\n",
    "plt.hist(filtered, bins=1000, density=True)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmpl = '/media/anton/DATA/results/h-elmo/expres/resrnn/poscorr/4/9/corr/level0_0/NNS/{}.pickle'\n",
    "matches = tmpl.format('matches')\n",
    "with open(matches, 'rb') as f:\n",
    "    m = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "act = tmpl.format('activations')\n",
    "with open(act, 'rb') as f:\n",
    "    a = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stddevs = tmpl.format('match_stddevs')\n",
    "with open(stddevs, 'rb') as f:\n",
    "    std = pickle.load(f)\n",
    "\n",
    "print(std)\n",
    "print(max(std))\n",
    "print(np.argmax(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "[[[[[1 2]]\n",
      "\n",
      "   [[3 4]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[5 6]]\n",
      "\n",
      "   [[7 8]]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_all_values_except_specified(tensor, excluded):\n",
    "    with tf.name_scope('get_all_values_except_specified'):\n",
    "        tensor = tf.reshape(tensor, [-1])\n",
    "        excluded = tf.reshape(excluded, [-1])\n",
    "        excluded_shape = tf.shape(excluded)\n",
    "        tensor_expanded = tf.reshape(tensor, [-1, 1])\n",
    "        multiples = tf.concat([[1], excluded_shape], 0)\n",
    "        tensor_expanded = tf.tile(tensor_expanded, multiples)\n",
    "        masks = tf.cast(tf.equal(tf.cast(tensor_expanded, tf.int32), tf.cast(excluded, tf.int32)), tf.int32)\n",
    "        mask = tf.reduce_sum(masks, [1])\n",
    "        mask = tf.cast(tf.cast(mask, dtype=tf.bool), dtype=tf.int32) - 1\n",
    "        return tf.boolean_mask(tensor, mask)\n",
    "    \n",
    "\n",
    "tensor, num_dims, axes, output = (\n",
    "                    [[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n",
    "\n",
    "                    5,\n",
    "\n",
    "                    [0, 2, 4],\n",
    "\n",
    "                    [[[[[1, 2]], [[3, 4]]], [[[5, 6]], [[7, 8]]]]],\n",
    "                )\n",
    "\n",
    "if not tf.contrib.framework.is_tensor(tensor):\n",
    "    tensor = tf.constant(tensor)\n",
    "if not tf.contrib.framework.is_tensor(axes):\n",
    "    axes = tf.constant(axes, dtype=tf.int32)\n",
    "sh = tf.shape(tensor, out_type=tf.int32)\n",
    "nd = tf.shape(sh, out_type=tf.int32)[0]\n",
    "assert_axes_smaller_than_num_dims = tf.assert_less(\n",
    "    axes, num_dims, message='`axes` has to be less than `num_dims`')\n",
    "check_num_dims = tf.assert_greater_equal(\n",
    "    num_dims, nd,\n",
    "    message='`num_dims` has to be greater or equal to number of dimensions in `tensor`'\n",
    ")\n",
    "ass_axes_bigger_or_equal_than_num_dims = tf.assert_greater_equal(axes, -num_dims)\n",
    "\n",
    "negative_axes_mask = tf.cast(axes < 0, tf.int32)\n",
    "axes += negative_axes_mask * num_dims\n",
    "\n",
    "ones_for_expansion = tf.ones(tf.reshape(num_dims - nd, [1]), dtype=tf.int32)\n",
    "shape_for_expansion = tf.concat([sh, ones_for_expansion], 0)\n",
    "\n",
    "tensor = tf.reshape(tensor, shape_for_expansion)\n",
    "\n",
    "# remained_axes = get_all_values_except_specified(tf.range(num_dims, dtype=tf.int32), axes)\n",
    "# perm = tf.concat([axes, remained_axes], 0)\n",
    "updates = tf.range(0, num_dims, 1, dtype=tf.int32)\n",
    "remained_positions = get_all_values_except_specified(tf.range(num_dims, dtype=tf.int32), axes)\n",
    "indices = tf.concat([axes, remained_positions], 0)\n",
    "indices = tf.reshape(indices, [-1, 1])\n",
    "perm_shape = tf.reshape(num_dims, [1])\n",
    "perm = tf.scatter_nd(indices, updates, perm_shape)\n",
    "\n",
    "with tf.control_dependencies([check_num_dims, assert_axes_smaller_than_num_dims, ass_axes_bigger_or_equal_than_num_dims]):\n",
    "    tensor = tf.transpose(tensor, perm=perm)\n",
    "    \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1 -1]\n",
      " [ 1  1  1  1]\n",
      " [ 0  0  0  0]\n",
      " [-1 -1 -1 -1]\n",
      " [ 1  1  1  1]\n",
      " [-1 -1 -1 -1]\n",
      " [ 1  1  1  1]\n",
      " [-1 -1 -1 -1]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [-1 -1 -1 -1]\n",
      " [ 0  0  0  0]\n",
      " [ 1  1  1  1]\n",
      " [ 0  0  0  0]\n",
      " [ 1  1  1  1]\n",
      " [ 0  0  0  0]\n",
      " [ 1  1  1  1]]\n",
      "{'markup': array([-1,  1,  0, -1,  1, -1,  1, -1,  0,  0, -1, -1, -1, -1,  0,  1,  0,\n",
      "        1,  0,  1]), 'relevant_markup': [-1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, 1, 1], 'relevant_activations': array([[-1, -1, -1, -1],\n",
      "       [ 1,  1,  1,  1],\n",
      "       [-1, -1, -1, -1],\n",
      "       [ 1,  1,  1,  1],\n",
      "       [-1, -1, -1, -1],\n",
      "       [ 1,  1,  1,  1],\n",
      "       [-1, -1, -1, -1],\n",
      "       [-1, -1, -1, -1],\n",
      "       [-1, -1, -1, -1],\n",
      "       [-1, -1, -1, -1],\n",
      "       [-1, -1, -1, -1],\n",
      "       [ 1,  1,  1,  1],\n",
      "       [ 1,  1,  1,  1],\n",
      "       [ 1,  1,  1,  1]]), 'matches': array([[0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [1.33333333, 1.33333333, 1.33333333, 1.33333333],\n",
      "       [0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [1.33333333, 1.33333333, 1.33333333, 1.33333333],\n",
      "       [0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [1.33333333, 1.33333333, 1.33333333, 1.33333333],\n",
      "       [0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [0.75      , 0.75      , 0.75      , 0.75      ],\n",
      "       [1.33333333, 1.33333333, 1.33333333, 1.33333333],\n",
      "       [1.33333333, 1.33333333, 1.33333333, 1.33333333],\n",
      "       [1.33333333, 1.33333333, 1.33333333, 1.33333333]]), 'correlations': array([1., 1., 1., 1.]), 'match_stddevs': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'mean_square_correlation': 1.0000000000000002, 'meta': {'positive': 6, 'negative': 8, 'total': 20}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from helmo.util.scripts.text_neuron_correlation import compute_stats\n",
    "\n",
    "num_unrollings = 20\n",
    "num_units = 4\n",
    "\n",
    "# a = np.random.rand(num_units, num_unrollings)\n",
    "\n",
    "m = np.random.choice([-1, 1, 0], num_unrollings)\n",
    "a = np.stack([m]*num_units, 1)\n",
    "print(a)\n",
    "\n",
    "stats = compute_stats(a, m)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 None\n",
      "0.01 -2\n",
      "0.02 -2\n",
      "0.03 -2\n",
      "0.04 -2\n",
      "0.05 -2\n",
      "0.06 -2\n",
      "0.07 -2\n",
      "0.08 -2\n",
      "0.09 -1\n",
      "0.1 -1\n",
      "0.11 -1\n",
      "0.12 -1\n",
      "0.13 -2\n",
      "0.14 -2\n",
      "0.15 -2\n",
      "0.16 -2\n",
      "0.17 -1\n",
      "0.18 -1\n",
      "0.19 -1\n",
      "0.2 -1\n",
      "0.21 -1\n",
      "0.22 -1\n",
      "0.23 -1\n",
      "0.24 -1\n",
      "0.25 -1\n",
      "0.26 -1\n",
      "0.27 -1\n",
      "0.28 -1\n",
      "0.29 -1\n",
      "0.3 -1\n",
      "0.31 -1\n",
      "0.32 -1\n",
      "0.33 -1\n",
      "0.34 -1\n",
      "0.35000000000000003 -1\n",
      "0.36 -1\n",
      "0.37 -1\n",
      "0.38 -1\n",
      "0.39 -1\n",
      "0.4 -1\n",
      "0.41000000000000003 -1\n",
      "0.42 -1\n",
      "0.43 -1\n",
      "0.44 -1\n",
      "0.45 -1\n",
      "0.46 -1\n",
      "0.47000000000000003 -1\n",
      "0.48 -1\n",
      "0.49 -1\n",
      "0.5 -1\n",
      "0.51 -1\n",
      "0.52 -1\n",
      "0.53 -1\n",
      "0.54 -1\n",
      "0.55 -1\n",
      "0.56 -1\n",
      "0.5700000000000001 -1\n",
      "0.58 -1\n",
      "0.59 -1\n",
      "0.6 -1\n",
      "0.61 -1\n",
      "0.62 -1\n",
      "0.63 -1\n",
      "0.64 -1\n",
      "0.65 -1\n",
      "0.66 -1\n",
      "0.67 -1\n",
      "0.68 -1\n",
      "0.6900000000000001 -1\n",
      "0.7000000000000001 -1\n",
      "0.71 -1\n",
      "0.72 -1\n",
      "0.73 -1\n",
      "0.74 -1\n",
      "0.75 -1\n",
      "0.76 -1\n",
      "0.77 -1\n",
      "0.78 -1\n",
      "0.79 -1\n",
      "0.8 -1\n",
      "0.81 -1\n",
      "0.8200000000000001 -1\n",
      "0.8300000000000001 -1\n",
      "0.84 0\n",
      "0.85 0\n",
      "0.86 0\n",
      "0.87 0\n",
      "0.88 0\n",
      "0.89 0\n",
      "0.9 0\n",
      "0.91 0\n",
      "0.92 0\n",
      "0.93 0\n",
      "0.9400000000000001 0\n",
      "0.9500000000000001 0\n",
      "0.96 0\n",
      "0.97 0\n",
      "0.98 0\n",
      "0.99 0\n",
      "1.0 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_int_part(n):\n",
    "    return str(int(n // 1))\n",
    "\n",
    "\n",
    "def get_frac_part(n):\n",
    "    removed = int(get_int_part(n))\n",
    "    frac_part = ''\n",
    "    while n % 1:\n",
    "        n *= 10\n",
    "        removed *= 10\n",
    "        frac_part += str(int(n // 1) - removed)\n",
    "        removed = int(n // 1)\n",
    "    return frac_part\n",
    "\n",
    "\n",
    "def get_kth_digit(number, k, default='0'):\n",
    "    \"\"\"Returns k-th digit. For example, in number 123.45 1 \n",
    "    is 2nd digit, 3 is zeroth and 5 is -2nd. \n",
    "    If the number does not have such a digit default is returned.\n",
    "    Args:\n",
    "        number: float or str convertable to float\n",
    "        k: integer\n",
    "    Returns:\n",
    "        str\"\"\"\n",
    "    if isinstance(number, str):\n",
    "        number = float(number)\n",
    "    int_part = get_int_part(number)\n",
    "    frac_part = get_frac_part(number)\n",
    "    number = int_part + frac_part\n",
    "    k = len(int_part) - k - 1\n",
    "    if 0 <= k < len(number):\n",
    "        return number[k]\n",
    "    else:\n",
    "        return default\n",
    "    \n",
    "    \n",
    "def get_first_nonzero_digit_pos(n):\n",
    "    if n == 0:\n",
    "        return None\n",
    "    int_part = get_int_part(n)\n",
    "    frac_part = get_frac_part(n)\n",
    "    if int(int_part):\n",
    "        return len(int_part) - 1\n",
    "    i = 0\n",
    "    while i < len(frac_part) and not int(frac_part[i]):\n",
    "        i += 1\n",
    "    assert frac_part[i] != '0'\n",
    "    return -i - 1\n",
    "\n",
    "\n",
    "def get_acc_num_digits(std, acc):\n",
    "    if std == 0:\n",
    "        return None\n",
    "    \n",
    "    std_err = std * acc\n",
    "    \n",
    "    nz_err = get_first_nonzero_digit_pos(std_err)\n",
    "    \n",
    "    digit_1_pos_higher = get_kth_digit(std, nz_err+1)\n",
    "    \n",
    "    higher_digit_change = get_kth_digit(std + std_err, nz_err+1) != digit_1_pos_higher or \\\n",
    "        get_kth_digit(std - std_err, nz_err+1) != digit_1_pos_higher\n",
    "\n",
    "    if higher_digit_change:\n",
    "        nz_err += 1\n",
    "    return nz_err\n",
    "\n",
    "for std in np.linspace(0, 1, 101):\n",
    "    last_digit = get_acc_num_digits(std, 0.2)\n",
    "    print(std, last_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_kth_digit(123.45678, -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_first_nonzero_digit_pos_for_std(std, acc):\n",
    "    if std == 0:\n",
    "        return None\n",
    "    std_fraction = std * acc\n",
    "    int_part = get_int_part(std_fraction)\n",
    "    frac_part = get_frac_part(std_fraction)\n",
    "    if int(int_part):\n",
    "        return len(int_part) - 1\n",
    "    i = 0\n",
    "    while i < len(frac_part) and not int(frac_part[i]):\n",
    "        i += 1\n",
    "    assert frac_part[i] != '0'\n",
    "    return -i - 1\n",
    "\n",
    "\n",
    "get_first_nonzero_digit_pos_for_std(0.0123456, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_int_part(n):\n",
    "    return str(int(n // 1))\n",
    "\n",
    "\n",
    "def get_frac_part(n):\n",
    "    removed = int(get_int_part(n))\n",
    "    frac_part = ''\n",
    "    while n % 1:\n",
    "        n *= 10\n",
    "        removed *= 10\n",
    "        frac_part += str(int(n // 1) - removed)\n",
    "        removed = int(n // 1)\n",
    "    return frac_part\n",
    "\n",
    "len(get_frac_part(2.2250738585072014e-308))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_probabilities_from_histograms(histograms, axis):\n",
    "    with tf.name_scope('probabilities_from_histograms'):\n",
    "        n = tf.reduce_sum(histograms, axis=axis, keepdims=True)\n",
    "        probabilities = tf.cast(histograms, tf.float32) / tf.cast(n, tf.float32)\n",
    "        return probabilities\n",
    "    \n",
    "    \n",
    "def entropy_MLE_from_prob(probabilities, axis, keepdims=False):\n",
    "    with tf.name_scope('entropy_MLE_from_prob'):\n",
    "        log_prob = tf.log(probabilities) / tf.log(2.)\n",
    "        log_prob = tf.where(\n",
    "            tf.logical_or(tf.is_nan(log_prob), tf.is_inf(log_prob)),\n",
    "            x=tf.zeros(tf.shape(log_prob)),\n",
    "            y=log_prob\n",
    "        )\n",
    "        products = probabilities * log_prob\n",
    "        return -tf.reduce_sum(products, axis=axis, keepdims=keepdims)\n",
    "\n",
    "\n",
    "def entropy_MLE_from_hist(histograms, axis, keepdims=False):\n",
    "    with tf.name_scope('entropy_MLE_from_hist'):\n",
    "        probabilities = get_probabilities_from_histograms(histograms, axis)\n",
    "        return entropy_MLE_from_prob(probabilities, axis, keepdims=keepdims)\n",
    "    \n",
    "    \n",
    "def get_sample_size_and_support_from_hist(\n",
    "        histograms,\n",
    "        axis,\n",
    "        keepdims=False,\n",
    "        dtype=tf.float32\n",
    "):\n",
    "    with tf.name_scope('get_sample_size_and_support_from_hist'):\n",
    "        n = tf.reduce_sum(histograms, axis=axis, keepdims=True)\n",
    "        m = tf.count_nonzero(histograms, axis=axis, keepdims=True)\n",
    "        n = tf.cast(n, dtype)\n",
    "        m = tf.cast(m, dtype)\n",
    "    return n, m\n",
    "\n",
    "\n",
    "def entropy_MM_from_hist(histograms, axis, keepdims=False):\n",
    "    with tf.name_scope('entropy_MM_from_hist'):\n",
    "        n, m = get_sample_size_and_support_from_hist(\n",
    "            histograms, axis, keepdims=True)\n",
    "        entropy = entropy_MLE_from_hist(histograms, axis, keepdims=True) + (m - 1.) / (2. * n)\n",
    "        if keepdims:\n",
    "            return entropy\n",
    "        return tf.squeeze(entropy, axis=axis)\n",
    "        \n",
    "\n",
    "def entropy_MM_from_prob(probabilities, n, m, axis, keepdims=False):\n",
    "    with tf.name_scope('entropy_MM_from_prob'):\n",
    "        n = tf.cast(n, tf.float32)\n",
    "        m = tf.cast(m, tf.float32)\n",
    "        entropy = entropy_MLE_from_prob(probabilities, axis, keepdims=True) + (m - 1.) / (2. * n)\n",
    "        if keepdims:\n",
    "            return entropy\n",
    "        return tf.squeeze(entropy, axis=axis)\n",
    "    \n",
    "    \n",
    "def sort_2_tf_values(value_1, value_2):\n",
    "    with tf.name_scope('sort_2_tf_values'):\n",
    "        first_value, second_value = tf.cond(\n",
    "            tf.greater(value_1, value_2),\n",
    "            true_fn=lambda: [value_2, value_1],\n",
    "            false_fn=lambda: [value_1, value_2],\n",
    "        )\n",
    "        return first_value, second_value\n",
    "    \n",
    "    \n",
    "def permute_two_axes(tensor, axis_1, axis_2):\n",
    "    with tf.name_scope('permute_two_axes'):\n",
    "        num_dims = tf.shape(tf.shape(tensor))[0]\n",
    "        axis_1 %= num_dims\n",
    "        axis_2 %= num_dims\n",
    "        first_axis, second_axis = sort_2_tf_values(axis_1, axis_2)\n",
    "        range_ = tf.range(num_dims)\n",
    "        false_value = tf.concat(\n",
    "            [\n",
    "                range_[:first_axis],\n",
    "                tf.reshape(second_axis, [1]),\n",
    "                range_[first_axis + 1:second_axis],\n",
    "                tf.reshape(first_axis, [1]),\n",
    "                range_[second_axis + 1:]\n",
    "            ],\n",
    "            0\n",
    "        )\n",
    "        permutation = tf.cond(\n",
    "            tf.equal(axis_1, axis_2),\n",
    "            true_fn=lambda: range_,\n",
    "            false_fn=lambda: false_value,\n",
    "        )\n",
    "        return tf.transpose(tensor, perm=permutation)\n",
    "\n",
    "\n",
    "class PermuteTwoAxes:\n",
    "    def __init__(self, tensor, axis_1, axis_2=-1):\n",
    "        self.tensor = tensor\n",
    "        self._axis_1 = axis_1\n",
    "        self._axis_2 = axis_2\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.tensor = permute_two_axes(self.tensor, self._axis_1, self._axis_2)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        self.tensor = permute_two_axes(self.tensor, self._axis_1, self._axis_2)\n",
    "        \n",
    "        \n",
    "def shift_axis(tensor, axis, position):\n",
    "    with tf.name_scope('shift_axis'):\n",
    "        num_dims = tf.shape(tf.shape(tensor))[0]\n",
    "        range_ = tf.range(num_dims)\n",
    "        axis %= num_dims\n",
    "        position %= num_dims\n",
    "        first_axis, second_axis = sort_2_tf_values(axis, position)\n",
    "        moved_dims = tf.reshape(axis, [1])\n",
    "        fill_dims = tf.zeros([0], dtype=tf.int32)\n",
    "        one = tf.constant(1)\n",
    "        zero = tf.constant(0)\n",
    "        first_dims, second_dims, before_2nd, after_1st, after_2nd = tf.cond(\n",
    "            tf.greater(axis, position),\n",
    "            true_fn=lambda: [moved_dims, fill_dims, zero, zero, one],\n",
    "            false_fn=lambda: [fill_dims, moved_dims, one, one, one],\n",
    "        )\n",
    "        false_value = tf.concat(\n",
    "            [\n",
    "                range_[:first_axis],\n",
    "                first_dims,\n",
    "                range_[first_axis+after_1st:second_axis+before_2nd],\n",
    "                second_dims,\n",
    "                range_[second_axis+after_2nd:]\n",
    "            ],\n",
    "            0\n",
    "        )\n",
    "        permutation = tf.cond(\n",
    "            tf.equal(axis, position),\n",
    "            true_fn=lambda: range_,\n",
    "            false_fn=lambda: false_value,\n",
    "        )\n",
    "        return tf.transpose(tensor, perm=permutation)\n",
    "\n",
    "\n",
    "class TensorToMatrix:\n",
    "    def __init__(self, tensor):\n",
    "        self.tensor = tensor\n",
    "        self._old_shape = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._old_shape = tf.shape(self.tensor)\n",
    "        self.tensor = tf.reshape(self.tensor, tf.stack([-1, self._old_shape[-1]]))\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        self.tensor = tf.reshape(self.tensor, tf.concat([self._old_shape[:-1], [-1]], 0))\n",
    "        \n",
    "        \n",
    "def get_slice_specs(shape, axis, idx, sample_size):\n",
    "    with tf.name_scope('get_slice_specs'):\n",
    "        shape = tf.identity(shape)\n",
    "        num_dims = tf.shape(shape)[0]\n",
    "        axis %= num_dims\n",
    "        n = shape[axis]\n",
    "        zeros = tf.zeros(tf.reshape(num_dims, [1]), dtype=tf.int32)\n",
    "        start = tf.concat(\n",
    "            [zeros[:axis], tf.reshape(idx, [1]), zeros[axis+1:]],\n",
    "            0\n",
    "        )\n",
    "        size = tf.concat(\n",
    "            [\n",
    "                shape[:axis],\n",
    "                tf.reshape(tf.minimum(sample_size, n - 1 - idx), [1]),\n",
    "                shape[axis+1:]\n",
    "            ],\n",
    "            0\n",
    "        )\n",
    "        return start, size\n",
    "        \n",
    "        \n",
    "def hist_1d_loop(values, num_bins, range_, axis, max_sample_size_per_iteration):\n",
    "    with tf.name_scope('hist_1d_loop'):\n",
    "        shape = tf.shape(values)\n",
    "        output_shape = get_output_shape_for_hist_1d(values, axis, num_bins)\n",
    "        n = shape[axis]\n",
    "        i0 = tf.constant(0)\n",
    "        hist = tf.zeros(output_shape, dtype=tf.int32)\n",
    "        \n",
    "        def body(idx, hist):\n",
    "            start, size = get_slice_specs(tf.shape(values), axis, idx, max_sample_size_per_iteration)\n",
    "            tensor = tf.slice(values, start, size)\n",
    "            hist += hist_1d(tensor, num_bins, range_, axis)\n",
    "            return idx + max_sample_size_per_iteration, hist\n",
    "        \n",
    "        _, hist = tf.while_loop(\n",
    "            lambda x, y: tf.less(x, n),\n",
    "            body,\n",
    "            [i0, hist],\n",
    "            shape_invariants=[tf.TensorShape([]), tf.TensorShape(None)],\n",
    "            parallel_iterations=1,\n",
    "        )\n",
    "        return tf.reshape(hist, output_shape)\n",
    "\n",
    "\n",
    "def hist_1d(values, num_bins, range_, axis):\n",
    "    with tf.name_scope('hist_1d'):\n",
    "        discrete = tf.histogram_fixed_width_bins(values, range_, num_bins)\n",
    "        return hist_from_nonnegative_ints(discrete, axis, num_bins)\n",
    "\n",
    "\n",
    "def compute_probabilities(activations, num_bins, range_, axis):\n",
    "    with tf.name_scope('compute_probabilities'):\n",
    "        n = tf.shape(activations)[axis]\n",
    "        histograms = hist_1d(activations, num_bins, range_, axis)\n",
    "        probabilities = tf.cast(histograms, tf.float32) / tf.cast(n, tf.float32)\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "def mean_neuron_entropy(activations, axis, num_bins, range_):\n",
    "    with tf.name_scope('mean_neuron_entropy'):\n",
    "        histograms = hist_1d(activations, num_bins, range_, axis)\n",
    "        return tf.reduce_mean(entropy_MM_from_hist(histograms, axis))\n",
    "    \n",
    "    \n",
    "def self_cross_sum(tensor, axis):\n",
    "    with tf.name_scope('self_cross_sum'):\n",
    "        num_dims = tf.shape(tf.shape(tensor))[0]\n",
    "        axis %= num_dims\n",
    "        t1 = tf.expand_dims(tensor, axis=axis)\n",
    "        t2 = tf.expand_dims(tensor, axis=axis+1)\n",
    "        return t1 + t2\n",
    "\n",
    "\n",
    "def self_cross_sum_with_factors(tensor, axis, f1, f2):\n",
    "    with tf.name_scope('self_cross_sum_with_factors'):\n",
    "        num_dims = tf.shape(tf.shape(tensor))[0]\n",
    "        axis %= num_dims\n",
    "        t1 = tf.expand_dims(tensor, axis=axis)\n",
    "        t2 = tf.expand_dims(tensor, axis=axis+1)\n",
    "        return f1*t1 + f2*t2\n",
    "    \n",
    "    \n",
    "def get_output_shape_for_hist_1d(tensor, axis, num_bins):\n",
    "    with tf.name_scope('get_output_shape_for_hist_1d'):\n",
    "        shape = tf.shape(tensor)\n",
    "        axis %= tf.shape(shape)[0]\n",
    "        return tf.concat(\n",
    "            [shape[:axis], tf.reshape(num_bins, [1]), shape[axis+1:]],\n",
    "            0\n",
    "        )\n",
    "    \n",
    "    \n",
    "def memory_efficient_bincount(values, num_bins):\n",
    "    with tf.name_scope('memory_efficient_bincount'):\n",
    "        data = tf.ones(tf.shape(values), dtype=tf.int32)\n",
    "        return tf.unsorted_segment_sum(data, values, num_bins)\n",
    "\n",
    "\n",
    "def hist_from_nonnegative_ints(tensor, axis, num_bins):\n",
    "    output_shape = get_output_shape_for_hist_1d(tensor, axis, num_bins)\n",
    "    with tf.name_scope('hist_from_nonnegative_ints'):\n",
    "        with PermuteTwoAxes(tensor, axis) as permute_ctx:\n",
    "            with TensorToMatrix(permute_ctx.tensor) as matrix_ctx:\n",
    "                shape = tf.shape(matrix_ctx.tensor)\n",
    "                n = shape[0]\n",
    "                shifts = tf.reshape(num_bins * tf.range(n), [-1, 1])\n",
    "                prepared_values = shifts + matrix_ctx.tensor\n",
    "                nb = num_bins * n\n",
    "                bc = memory_efficient_bincount(prepared_values, nb)\n",
    "                backward_shape = tf.concat([shape[:1], [-1]], 0)\n",
    "                matrix_ctx.tensor = tf.reshape(bc, backward_shape)\n",
    "            permute_ctx.tensor = matrix_ctx.tensor\n",
    "        return tf.reshape(permute_ctx.tensor, output_shape)\n",
    "\n",
    "\n",
    "def cross_hist_from_tensor(tensor, num_bins, range_):\n",
    "    with tf.name_scope('cross_hist_from_tensor'):\n",
    "        bins = tf.histogram_fixed_width_bins(\n",
    "            tensor,\n",
    "            range_,\n",
    "            nbins=num_bins,\n",
    "        )\n",
    "        bins_2d = self_cross_sum_with_factors(bins, -2, 1, num_bins)\n",
    "        returned_value = hist_from_nonnegative_ints(bins_2d, -1, num_bins**2)\n",
    "        return returned_value\n",
    "\n",
    "\n",
    "def add_cross_hist_1_slice_independent(\n",
    "    idx, \n",
    "    histograms, \n",
    "    activations, \n",
    "    num_bins,\n",
    "    range_,\n",
    "    max_sample_size_per_iteration\n",
    "):\n",
    "    with tf.name_scope('add_cross_hist_1_slice_independent'):\n",
    "        msspi = max_sample_size_per_iteration\n",
    "        tensor = activations[..., idx:idx+msspi]\n",
    "        histograms += cross_hist_from_tensor(tensor, num_bins, range_)\n",
    "        return idx+msspi, histograms\n",
    "\n",
    "\n",
    "def get_init_shape_of_cross_histograms(\n",
    "        activations,\n",
    "        num_bins\n",
    "):\n",
    "    shape = tf.shape(activations)\n",
    "    cross_dim = tf.reshape(shape[-2], [1])\n",
    "    return tf.concat(\n",
    "        [\n",
    "            shape[:-2],\n",
    "            cross_dim,\n",
    "            cross_dim,\n",
    "            tf.reshape(num_bins**2, [1])\n",
    "        ],\n",
    "        0\n",
    "    )\n",
    "            \n",
    "\n",
    "def sum_self_cross_histograms(\n",
    "        activations,\n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration,\n",
    "):\n",
    "    with tf.name_scope('sum_self_cross_histograms'):\n",
    "        def add_cross_hist_1_slice(idx, hists):\n",
    "            return add_cross_hist_1_slice_independent(\n",
    "                idx, \n",
    "                hists, \n",
    "                activations, \n",
    "                num_bins,\n",
    "                range_,\n",
    "                max_sample_size_per_iteration\n",
    "            )\n",
    "        i0 = tf.constant(0)\n",
    "        n = tf.shape(activations)[-1]\n",
    "        histograms = tf.zeros(\n",
    "            get_init_shape_of_cross_histograms(\n",
    "                activations, num_bins),\n",
    "            dtype=tf.int32\n",
    "        )\n",
    "        _, histograms = tf.while_loop(\n",
    "            lambda x, y: x < n,\n",
    "            add_cross_hist_1_slice,\n",
    "            [i0, histograms],\n",
    "            shape_invariants=[\n",
    "                tf.TensorShape([]),\n",
    "                histograms.get_shape()\n",
    "            ],\n",
    "            back_prop=False,\n",
    "            parallel_iterations=1,\n",
    "        )\n",
    "        return histograms\n",
    "    \n",
    "    \n",
    "def get_cross_histograms_permutation(\n",
    "        num_dims,\n",
    "        value_axis,\n",
    "        cross_axis, \n",
    "):\n",
    "    value_axis %= num_dims\n",
    "    cross_axis %= num_dims\n",
    "    dims = tf.range(num_dims+1)\n",
    "    first_dims, second_dims, first_axis, second_axis = tf.cond(\n",
    "        tf.greater(value_axis, cross_axis),\n",
    "        true_fn=lambda: [dims[-3:-1], dims[-1:], cross_axis, value_axis],\n",
    "        false_fn=lambda: [dims[-1:], dims[-3:-1], value_axis, cross_axis]\n",
    "    )\n",
    "    return tf.concat(\n",
    "        [\n",
    "            dims[:first_axis],\n",
    "            first_dims,\n",
    "            dims[first_axis:second_axis-1],\n",
    "            second_dims,\n",
    "            dims[second_axis-1:-3]\n",
    "        ],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "\n",
    "def get_self_cross_histograms(\n",
    "        activations,\n",
    "        value_axis,\n",
    "        cross_axis,\n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration=None,\n",
    "):\n",
    "    with tf.name_scope('get_self_cross_histograms'):\n",
    "        if max_sample_size_per_iteration is None:\n",
    "            max_sample_size_per_iteration = int(2.5e8) // num_bins\n",
    "        num_dims = tf.shape(tf.shape(activations))[0]\n",
    "        value_axis %= num_dims\n",
    "        cross_axis %= num_dims\n",
    "        output_permutation = get_cross_histograms_permutation(\n",
    "            num_dims,\n",
    "            value_axis,\n",
    "            cross_axis,\n",
    "        )\n",
    "        activations = shift_axis(activations, cross_axis, -1)\n",
    "        new_value_axis = value_axis - tf.cast(value_axis > cross_axis, tf.int32)\n",
    "        activations = shift_axis(activations, new_value_axis, -1)\n",
    "        histograms = sum_self_cross_histograms(\n",
    "            activations,\n",
    "            num_bins,\n",
    "            range_,\n",
    "            max_sample_size_per_iteration,  \n",
    "        )\n",
    "        return tf.transpose(histograms, perm=output_permutation)\n",
    "    \n",
    "    \n",
    "def get_min_nonzero(tensor):\n",
    "    with tf.name_scope('get_min_nonzero'):\n",
    "        tensor = tf.reshape(tensor, [-1])\n",
    "        unique, _ = tf.unique(tensor)\n",
    "        top2, _ = tf.math.top_k(-unique, 2)\n",
    "        top1, idx = tf.math.top_k(top2, 1)\n",
    "        return tf.where(tf.equal(top1[0], 0), x=-top2[idx[0]-1], y=-top1[0])\n",
    "\n",
    "    \n",
    "def squeeze_tf(tensor, axis):\n",
    "    with tf.name_scope('squeeze_tf'):\n",
    "        shape = tf.shape(tensor)\n",
    "        num_dims = tf.shape(shape)[0]\n",
    "        new_shape = tf.concat([shape[:axis], shape[axis+1:]], 0)\n",
    "        return tf.reshape(tensor, new_shape)\n",
    "    \n",
    "\n",
    "\n",
    "def mutual_information_and_min_nonzero_count(\n",
    "        activations,\n",
    "        value_axis, \n",
    "        cross_axis, \n",
    "        num_bins, \n",
    "        range_, \n",
    "        keepdims=False,\n",
    "        max_sample_size_per_iteration=2*10**4,\n",
    "):\n",
    "    with tf.name_scope('mutual_information_and_min_nonzero_count'):\n",
    "        num_dims = tf.shape(tf.shape(activations))[0]\n",
    "        value_axis %= num_dims\n",
    "        cross_axis %= num_dims\n",
    "        histograms = hist_1d_loop(activations, num_bins, range_, value_axis, 10**6)\n",
    "        entropy = entropy_MM_from_hist(histograms, value_axis, keepdims=True)\n",
    "        entropy_sum = self_cross_sum(entropy, cross_axis)\n",
    "        cross_histograms = get_self_cross_histograms(\n",
    "            activations, \n",
    "            value_axis, \n",
    "            cross_axis, \n",
    "            num_bins, \n",
    "            range_,\n",
    "            max_sample_size_per_iteration=max_sample_size_per_iteration,\n",
    "        )\n",
    "        value_axis = tf.cast(value_axis > cross_axis, tf.int32) + value_axis\n",
    "        joint_entropy = entropy_MM_from_hist(cross_histograms, value_axis, keepdims=True)\n",
    "        mutual_info = entropy_sum - joint_entropy\n",
    "        min_nonzero = get_min_nonzero(cross_histograms)\n",
    "        if keepdims:\n",
    "            return mutual_info, min_nonzero\n",
    "        else:\n",
    "            return squeeze_tf(mutual_info, value_axis), min_nonzero\n",
    "\n",
    "\n",
    "def mean_mutual_information_and_min_nonzero_count(\n",
    "        activations,\n",
    "        value_axis,\n",
    "        cross_axis,\n",
    "        num_bins,\n",
    "        range_,\n",
    "        keepdims=False,\n",
    "        max_sample_size_per_iteration=2 * 10 ** 4,\n",
    "):\n",
    "    with tf.name_scope('mean_mutual_information_and_min_nonzero_count'):\n",
    "        num_dims = tf.shape(tf.shape(activations))[0]\n",
    "        value_axis %= num_dims\n",
    "        cross_axis %= num_dims\n",
    "        mutual_info, min_nonzero = mutual_information_and_min_nonzero_count(\n",
    "            activations,\n",
    "            value_axis,\n",
    "            cross_axis,\n",
    "            num_bins,\n",
    "            range_,\n",
    "            keepdims=True,\n",
    "            max_sample_size_per_iteration=max_sample_size_per_iteration,\n",
    "        )\n",
    "        value_axis = value_axis + tf.cast(tf.greater(value_axis, cross_axis), tf.int32)\n",
    "        if not keepdims:\n",
    "            mutual_info = squeeze_tf(mutual_info, value_axis)\n",
    "        mutual_info_reshaped = shift_axis(mutual_info, cross_axis + 1, -1)\n",
    "        mutual_info_reshaped = shift_axis(mutual_info_reshaped, cross_axis, -1)\n",
    "        diag = tf.linalg.diag_part(mutual_info_reshaped)\n",
    "        N = tf.reduce_prod(tf.shape(mutual_info_reshaped))\n",
    "        n = tf.reduce_prod(tf.shape(diag))\n",
    "        s = tf.reduce_sum(mutual_info_reshaped) - tf.reduce_sum(diag)\n",
    "        return mutual_info, s / tf.cast(N - n, tf.float32), min_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]]\n",
      "\n",
      "********************\n",
      "get_output_shape_for_hist_1d\n",
      "[ 2  3  4  5  6 10]\n",
      "\n",
      "********************\n",
      "self_cross_sum_with_factors\n",
      "[[[11 22 33]\n",
      "  [41 52 63]]\n",
      "\n",
      " [[14 25 36]\n",
      "  [44 55 66]]]\n",
      "\n",
      "********************\n",
      "hist_from_nonnegative_ints\n",
      "19\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    2    1    0    1    0    0    0    0]\n",
      " [  16   13   15   14   11   17   13   17   13   17]\n",
      " [ 203  192  228  226  220  242  205  211  205  222]\n",
      " [1330 1357 1294 1337 1394 1356 1385 1355 1432 1389]\n",
      " [3392 3373 3409 3443 3453 3402 3448 3375 3380 3370]\n",
      " [3462 3518 3453 3395 3386 3414 3399 3456 3359 3419]\n",
      " [1362 1304 1386 1344 1305 1380 1339 1374 1382 1358]\n",
      " [ 218  227  199  231  215  180  199  201  217  211]\n",
      " [  17   16   13    8   16    8   11   11   10   12]\n",
      " [   0    0    1    1    0    0    1    0    2    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "********************\n",
      "cross_hist_from_tensor\n",
      "[[[ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0 20\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0\n",
      "    0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0]]\n",
      "\n",
      " [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0 20  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0]\n",
      "  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0 20  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0  0  0  0  0  0  0]]]\n",
      "\n",
      "********************\n",
      "add_cross_hist_1_slice_independent\n",
      "[13, array([[[[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]]], dtype=int32)]\n",
      "[23, array([[[[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 17,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 17,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]]], dtype=int32)]\n",
      "[33, array([[[[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 17,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0, 13,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 17,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0, 13,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 13,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 13,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]]], dtype=int32)]\n",
      "\n",
      "********************\n",
      "get_init_shape_of_cross_histograms\n",
      "[  5   6   7   7 100]\n",
      "\n",
      "********************\n",
      "sum_self_cross_histograms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  0  0  0  0  0  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0  0\n",
      "    20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "   [ 0  0  0  0  0  0  0  0  0  0  0  0  0 30 10  0  0  0  0  0  0  0\n",
      "     0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "  [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0 30  0  0  0  0  0  0  0  0  0 10 20  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "   [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0  0  0  0  0  0  0\n",
      "    30  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "     0  0  0  0  0  0  0  0  0  0  0  0]]]]\n",
      "\n",
      "********************\n",
      "get_cross_histograms_permutation\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "\n",
      "********************\n",
      "get_self_cross_histograms\n",
      "[1, 2, 60]\n",
      "(2, 2, 25)\n",
      "[[[ 0  0  0  0  0  0 40  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0\n",
      "    0  0]\n",
      "  [ 0  0  0  0  0  0  0  0 30 10  0  0  0  0 20  0  0  0  0  0  0  0  0\n",
      "    0  0]]\n",
      "\n",
      " [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0 10 20\n",
      "    0  0]\n",
      "  [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0\n",
      "    0 30]]]\n",
      "\n",
      "********************\n",
      "test_get_min_nonzero\n",
      "[1.0]\n",
      "\n",
      "********************\n",
      "test_mean_mutual_information_and_min_nonzero_count\n",
      "entropy:\n",
      " [6.4574785 6.457088  6.4573655 6.4579034 6.456763  6.457706  6.456841\n",
      " 6.456577  6.457474  6.4577403]\n",
      "\n",
      "mutual_info:\n",
      " [[6.4574790e+00 1.2569427e-03 1.4333725e-03 1.4362335e-03 1.3666153e-03\n",
      "  1.4095306e-03 1.4696121e-03 1.3971329e-03 1.3694763e-03 1.3380051e-03]\n",
      " [1.2569427e-03 6.4570885e+00 1.3999939e-03 1.3046265e-03 1.4266968e-03\n",
      "  1.3542175e-03 1.2836456e-03 1.3980865e-03 1.3933182e-03 1.3265610e-03]\n",
      " [1.4343262e-03 1.4009476e-03 6.4573650e+00 1.3017654e-03 1.4657974e-03\n",
      "  1.4276505e-03 1.4019012e-03 1.5039444e-03 1.5363693e-03 1.4591217e-03]\n",
      " [1.4352798e-03 1.3027191e-03 1.3008118e-03 6.4579034e+00 1.4743805e-03\n",
      "  1.4343262e-03 1.3341904e-03 1.3885498e-03 1.3074875e-03 1.3484955e-03]\n",
      " [1.3675690e-03 1.4266968e-03 1.4657974e-03 1.4753342e-03 6.4567628e+00\n",
      "  1.3885498e-03 1.3446808e-03 1.4266968e-03 1.2788773e-03 1.2989044e-03]\n",
      " [1.4095306e-03 1.3542175e-03 1.4286041e-03 1.4343262e-03 1.3885498e-03\n",
      "  6.4577060e+00 1.3608932e-03 1.3217926e-03 1.3847351e-03 1.2950897e-03]\n",
      " [1.4696121e-03 1.2836456e-03 1.4009476e-03 1.3351440e-03 1.3437271e-03\n",
      "  1.3618469e-03 6.4568419e+00 1.2941360e-03 1.3246536e-03 1.3847351e-03]\n",
      " [1.3961792e-03 1.3980865e-03 1.5039444e-03 1.3875961e-03 1.4266968e-03\n",
      "  1.3198853e-03 1.2941360e-03 6.4565768e+00 1.3341904e-03 1.3227463e-03]\n",
      " [1.3704300e-03 1.3923645e-03 1.5373230e-03 1.3084412e-03 1.2788773e-03\n",
      "  1.3856888e-03 1.3246536e-03 1.3351440e-03 6.4574752e+00 1.3046265e-03]\n",
      " [1.3370514e-03 1.3265610e-03 1.4581680e-03 1.3484955e-03 1.2989044e-03\n",
      "  1.2950897e-03 1.3847351e-03 1.3208389e-03 1.3055801e-03 6.4577413e+00]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.0013736301\n",
      "\n",
      "min_num_events:\n",
      " 2\n",
      "\n",
      "********************\n",
      "test_mutual_information_and_min_nonzero_count\n",
      "entropy:\n",
      " [6.457257  6.4571114 6.4572825 6.45739   6.4573393 6.4572387 6.4570637\n",
      " 6.4571834 6.4574175 6.4572473]\n",
      "\n",
      "mutual_info:\n",
      " [[6.4572568e+00 1.3542175e-04 1.2207031e-04 1.2874603e-04 1.2397766e-04\n",
      "  1.3542175e-04 1.3256073e-04 1.2397766e-04 1.2588501e-04 1.3732910e-04]\n",
      " [1.3542175e-04 6.4571114e+00 1.3923645e-04 1.5068054e-04 1.3256073e-04\n",
      "  1.4305115e-04 1.3542175e-04 1.3160706e-04 1.2683868e-04 1.2874603e-04]\n",
      " [1.2302399e-04 1.3923645e-04 6.4572830e+00 1.2683868e-04 1.3637543e-04\n",
      "  1.2111664e-04 1.3732910e-04 1.4686584e-04 1.4305115e-04 1.3351440e-04]\n",
      " [1.2969971e-04 1.5163422e-04 1.2779236e-04 6.4573894e+00 1.3732910e-04\n",
      "  1.2969971e-04 1.4114380e-04 1.3923645e-04 1.3828278e-04 1.3732910e-04]\n",
      " [1.2493134e-04 1.3256073e-04 1.3637543e-04 1.3828278e-04 6.4573393e+00\n",
      "  1.2969971e-04 1.2874603e-04 1.3256073e-04 1.3637543e-04 1.4114380e-04]\n",
      " [1.3351440e-04 1.4305115e-04 1.2302399e-04 1.2969971e-04 1.2874603e-04\n",
      "  6.4572387e+00 1.3732910e-04 1.3160706e-04 1.2588501e-04 1.2493134e-04]\n",
      " [1.3160706e-04 1.3637543e-04 1.3732910e-04 1.4019012e-04 1.2969971e-04\n",
      "  1.3637543e-04 6.4570637e+00 1.4114380e-04 1.2779236e-04 1.3351440e-04]\n",
      " [1.2397766e-04 1.3160706e-04 1.4686584e-04 1.3923645e-04 1.3351440e-04\n",
      "  1.3160706e-04 1.4114380e-04 6.4571834e+00 1.3351440e-04 1.2779236e-04]\n",
      " [1.2779236e-04 1.2683868e-04 1.4400482e-04 1.3828278e-04 1.3542175e-04\n",
      "  1.2493134e-04 1.2779236e-04 1.3351440e-04 6.4574189e+00 1.3160706e-04]\n",
      " [1.3828278e-04 1.2969971e-04 1.3351440e-04 1.3637543e-04 1.4114380e-04\n",
      "  1.2397766e-04 1.3351440e-04 1.2779236e-04 1.3160706e-04 6.4572473e+00]]\n",
      "\n",
      "min_num_events:\n",
      " 65\n",
      "5.112154223956168\n",
      "\n",
      "********************\n",
      "test_get_slice_specs\n",
      "[array([0, 0, 0, 2], dtype=int32), array([3, 4, 5, 3], dtype=int32)]\n",
      "\n",
      "********************\n",
      "test_hist_1d_loop\n",
      "[[[  2   6   1]\n",
      "  [  3   6   3]\n",
      "  [  8  11  11]\n",
      "  [ 17  19  17]\n",
      "  [ 39  27  31]\n",
      "  [ 43  57  51]\n",
      "  [ 52  70  66]\n",
      "  [ 93  86  80]\n",
      "  [115 106 113]\n",
      "  [118 120 124]\n",
      "  [125 119 129]\n",
      "  [ 98 102 105]\n",
      "  [ 84  82  97]\n",
      "  [ 90  75  57]\n",
      "  [ 41  44  53]\n",
      "  [ 34  42  29]\n",
      "  [ 17   9  20]\n",
      "  [ 10  11  10]\n",
      "  [  7   3   1]\n",
      "  [  3   4   1]]\n",
      "\n",
      " [[  1   4   4]\n",
      "  [  3   6   7]\n",
      "  [  8   1  12]\n",
      "  [ 14  11  23]\n",
      "  [ 30  26  30]\n",
      "  [ 60  48  46]\n",
      "  [ 75  79  67]\n",
      "  [ 99 100  80]\n",
      "  [ 97 112 101]\n",
      "  [120 104 116]\n",
      "  [120 117 132]\n",
      "  [116 103 106]\n",
      "  [ 83  86  94]\n",
      "  [ 62  73  60]\n",
      "  [ 41  57  55]\n",
      "  [ 25  39  36]\n",
      "  [ 26  14  16]\n",
      "  [  8   8   5]\n",
      "  [  8   8   4]\n",
      "  [  3   3   5]]\n",
      "\n",
      " [[  5   5   5]\n",
      "  [  8   7   5]\n",
      "  [ 13  11  11]\n",
      "  [ 16  18  27]\n",
      "  [ 28  24  33]\n",
      "  [ 48  56  48]\n",
      "  [ 63  72  63]\n",
      "  [ 84  98  73]\n",
      "  [111 119 111]\n",
      "  [124 103  99]\n",
      "  [118 113 115]\n",
      "  [ 93 113 122]\n",
      "  [ 85  76  94]\n",
      "  [ 80  57  66]\n",
      "  [ 58  47  65]\n",
      "  [ 29  44  31]\n",
      "  [ 20  21  19]\n",
      "  [  7  10   8]\n",
      "  [  6   3   3]\n",
      "  [  3   2   1]]\n",
      "\n",
      " [[  1   1   3]\n",
      "  [  2   3   5]\n",
      "  [ 11   4  14]\n",
      "  [ 14  19  22]\n",
      "  [ 32  34  29]\n",
      "  [ 57  49  53]\n",
      "  [ 66  61  67]\n",
      "  [ 87 103  79]\n",
      "  [115 103 103]\n",
      "  [114 112 128]\n",
      "  [108 118 121]\n",
      "  [115 114 114]\n",
      "  [ 91  86  92]\n",
      "  [ 69  80  65]\n",
      "  [ 44  45  53]\n",
      "  [ 39  32  24]\n",
      "  [ 15  19  17]\n",
      "  [ 10   6   5]\n",
      "  [  4   8   2]\n",
      "  [  5   2   3]]\n",
      "\n",
      " [[  3   1   2]\n",
      "  [  9   5   5]\n",
      "  [  7   8  11]\n",
      "  [ 19  14  23]\n",
      "  [ 32  28  45]\n",
      "  [ 57  53  48]\n",
      "  [ 70  63  65]\n",
      "  [ 88  87  81]\n",
      "  [105 109 106]\n",
      "  [102 123 121]\n",
      "  [107 128 127]\n",
      "  [118  99  91]\n",
      "  [ 95 111  93]\n",
      "  [ 68  61  80]\n",
      "  [ 48  45  47]\n",
      "  [ 31  34  28]\n",
      "  [ 19  20  14]\n",
      "  [ 12   6   5]\n",
      "  [  5   3   3]\n",
      "  [  4   1   4]]\n",
      "\n",
      " [[  3   3   2]\n",
      "  [  7   4   6]\n",
      "  [ 14   8  14]\n",
      "  [ 18  22  14]\n",
      "  [ 31  23  38]\n",
      "  [ 35  41  54]\n",
      "  [ 65  62  72]\n",
      "  [ 97  95  96]\n",
      "  [101 106  98]\n",
      "  [142 126 116]\n",
      "  [107 132 122]\n",
      "  [113  99 110]\n",
      "  [101  92  85]\n",
      "  [ 65  76  64]\n",
      "  [ 42  49  54]\n",
      "  [ 29  34  18]\n",
      "  [ 15  14  22]\n",
      "  [  4   8  10]\n",
      "  [  6   3   1]\n",
      "  [  4   2   3]]\n",
      "\n",
      " [[  2   5   6]\n",
      "  [  5   5   9]\n",
      "  [  4  12  11]\n",
      "  [ 18   9  20]\n",
      "  [ 25  35  23]\n",
      "  [ 57  57  56]\n",
      "  [ 58  82  57]\n",
      "  [ 98  94 102]\n",
      "  [130 104  98]\n",
      "  [126 108 111]\n",
      "  [ 93 136 120]\n",
      "  [114  97 112]\n",
      "  [106  72  94]\n",
      "  [ 53  66  70]\n",
      "  [ 50  49  50]\n",
      "  [ 28  33  35]\n",
      "  [ 13  15  13]\n",
      "  [ 12   7   6]\n",
      "  [  6   6   2]\n",
      "  [  1   7   4]]\n",
      "\n",
      " [[  4   3   2]\n",
      "  [  7   5   7]\n",
      "  [ 10  10   6]\n",
      "  [ 20  18  18]\n",
      "  [ 38  26  33]\n",
      "  [ 44  37  39]\n",
      "  [ 79  72  80]\n",
      "  [ 86  89  90]\n",
      "  [109 102 131]\n",
      "  [115 119 106]\n",
      "  [113 115 117]\n",
      "  [122 119 110]\n",
      "  [ 79  85  83]\n",
      "  [ 58  76  61]\n",
      "  [ 45  52  48]\n",
      "  [ 26  28  28]\n",
      "  [ 19  19  19]\n",
      "  [ 18  13  11]\n",
      "  [  5   6   4]\n",
      "  [  2   5   6]]\n",
      "\n",
      " [[  3   7   2]\n",
      "  [  2   8   8]\n",
      "  [  6   6   8]\n",
      "  [ 26  16  16]\n",
      "  [ 41  38  28]\n",
      "  [ 43  61  47]\n",
      "  [ 66  65  71]\n",
      "  [ 99  87 105]\n",
      "  [118 108 129]\n",
      "  [107 120 100]\n",
      "  [115 129 114]\n",
      "  [ 97  94  92]\n",
      "  [ 78  85  77]\n",
      "  [ 78  75  93]\n",
      "  [ 55  41  55]\n",
      "  [ 25  27  21]\n",
      "  [ 23  18  17]\n",
      "  [ 12   6   8]\n",
      "  [  2   5   4]\n",
      "  [  3   3   4]]\n",
      "\n",
      " [[  3   3   4]\n",
      "  [  5   2   6]\n",
      "  [  7  10   7]\n",
      "  [ 21  26  28]\n",
      "  [ 31  19  32]\n",
      "  [ 48  48  55]\n",
      "  [ 81  67  65]\n",
      "  [ 76  94  78]\n",
      "  [ 97 109 108]\n",
      "  [110 120 131]\n",
      "  [121 119 112]\n",
      "  [106 108 103]\n",
      "  [ 99  88  81]\n",
      "  [ 71  60  63]\n",
      "  [ 50  52  46]\n",
      "  [ 32  41  41]\n",
      "  [ 19  19  25]\n",
      "  [ 15   7   6]\n",
      "  [  4   2   3]\n",
      "  [  3   5   5]]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "\n",
    "def test_shift_axis():\n",
    "    tensor = tf.zeros([2, 3, 4])\n",
    "    t = shift_axis(tensor, 0, 2)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run(t))\n",
    "\n",
    "\n",
    "def test_get_output_shape_for_hist_1d():\n",
    "    print('\\n' + \"*\"*20 + '\\nget_output_shape_for_hist_1d')\n",
    "    tensor = tf.zeros([2, 3, 4, 5, 6, 7])\n",
    "    axis = -1\n",
    "    num_bins = 10\n",
    "    shape = get_output_shape_for_hist_1d(tensor, axis, num_bins)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run(shape))\n",
    "\n",
    "\n",
    "def test_self_cross_sum_with_factors():\n",
    "    print('\\n' + \"*\"*20 + '\\nself_cross_sum_with_factors')\n",
    "    tensor = [[1, 2, 3], [4, 5, 6]]\n",
    "    cs = self_cross_sum_with_factors(tensor, 0, 10, 1)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run(cs))\n",
    "    \n",
    "    \n",
    "def test_hist_from_nonnegative_ints():\n",
    "    print('\\n' + \"*\"*20 + '\\nhist_from_nonnegative_ints')\n",
    "    tensor = tf.histogram_fixed_width_bins(\n",
    "        tf.random.normal([100000], dtype=tf.float32, mean=0, stddev=1),\n",
    "        [-15., 15.],\n",
    "        nbins=30,\n",
    "    )\n",
    "    tensor = tf.reshape(tensor, [10000, 10])\n",
    "    hist = hist_from_nonnegative_ints(tensor, -2, 30)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(np.max(sess.run(tensor)))\n",
    "        print(sess.run(hist))\n",
    "    \n",
    "    \n",
    "def test_cross_hist_from_tensor():\n",
    "    print('\\n' + \"*\"*20 + '\\ncross_hist_from_tensor')\n",
    "    tensor = [[1. for _ in range(20)] + [2. for _ in range(20)], [3. for _ in range(20)] + [4. for _ in range(20)]]\n",
    "    hist = cross_hist_from_tensor(tensor, 10, [0., 10.])\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run(hist))\n",
    "\n",
    "\n",
    "def test_add_cross_hist_1_slice_independent():\n",
    "    print('\\n' + \"*\"*20 + '\\nadd_cross_hist_1_slice_independent')\n",
    "    idx = tf.constant(3)\n",
    "    histograms = tf.zeros([2, 2, 100], dtype=tf.int32)\n",
    "    activations = tf.constant(\n",
    "        [\n",
    "            [\n",
    "                [1. for _ in range(20)] + [2. for _ in range(20)] + \\\n",
    "                    [1. for _ in range(20)],\n",
    "                [3. for _ in range(20)] + [4. for _ in range(20)] + \\\n",
    "                    [3. for _ in range(10)] + [4. for _ in range(10)]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    num_bins=10\n",
    "    range_ = [0., 10.]\n",
    "    max_sample_size_per_iteration = 10\n",
    "    idx1, histograms1 = add_cross_hist_1_slice_independent(\n",
    "        idx, \n",
    "        histograms, \n",
    "        activations, \n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration\n",
    "    )\n",
    "    idx2, histograms2 = add_cross_hist_1_slice_independent(\n",
    "        idx1, \n",
    "        histograms1, \n",
    "        activations, \n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration\n",
    "    )\n",
    "    idx3, histograms3 = add_cross_hist_1_slice_independent(\n",
    "        idx2, \n",
    "        histograms2, \n",
    "        activations, \n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration\n",
    "    )\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run([idx1, histograms1]))\n",
    "        print(sess.run([idx2, histograms2]))\n",
    "        print(sess.run([idx3, histograms3]))\n",
    "\n",
    "\n",
    "def test_get_init_shape_of_cross_histograms():\n",
    "    print('\\n' + \"*\"*20 + '\\nget_init_shape_of_cross_histograms')\n",
    "    activations = tf.zeros([5, 6, 7, 8])\n",
    "    num_bins = 10\n",
    "    shape = get_init_shape_of_cross_histograms(activations, num_bins)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run(shape))\n",
    "    \n",
    "    \n",
    "def test_sum_self_cross_histograms():\n",
    "    print('\\n' + \"*\"*20 + '\\nsum_self_cross_histograms')\n",
    "    activations = tf.constant(\n",
    "        [\n",
    "            [\n",
    "                [1. for _ in range(20)] + [2. for _ in range(20)] + \\\n",
    "                    [1. for _ in range(20)],\n",
    "                [3. for _ in range(20)] + [4. for _ in range(20)] + \\\n",
    "                    [3. for _ in range(10)] + [4. for _ in range(10)]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "    num_bins = 10\n",
    "    range_ = [0., 10.]\n",
    "    max_sample_size_per_iteration = 10\n",
    "    histograms = sum_self_cross_histograms(\n",
    "        activations,\n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration,\n",
    "    )\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run(histograms))\n",
    "    \n",
    "    \n",
    "def test_get_cross_histograms_permutation():\n",
    "    print('\\n' + \"*\"*20 + '\\nget_cross_histograms_permutation')\n",
    "    perm = get_cross_histograms_permutation(10, 9, 8)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run(perm))\n",
    "    \n",
    "    \n",
    "def test_get_self_cross_histograms():\n",
    "    print('\\n' + \"*\"*20 + '\\nget_self_cross_histograms')\n",
    "    activations = tf.constant(\n",
    "        [\n",
    "            [\n",
    "                [1. for _ in range(20)] + [2. for _ in range(20)] + \\\n",
    "                    [1. for _ in range(20)],\n",
    "                [3. for _ in range(20)] + [4. for _ in range(20)] + \\\n",
    "                    [3. for _ in range(10)] + [4. for _ in range(10)]\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "#     activations = tf.transpose(\n",
    "#         activations,\n",
    "#         perm=[2, 1, 0]\n",
    "#     )\n",
    "#     value_axis = 0\n",
    "#     cross_axis = 1\n",
    "    value_axis = -1\n",
    "    cross_axis = -2\n",
    "    num_bins = 5\n",
    "    range_ = [0., 5.]\n",
    "    max_sample_size_per_iteration = 10\n",
    "    print(activations.get_shape().as_list())\n",
    "    histograms = get_self_cross_histograms(\n",
    "        activations,\n",
    "        value_axis,\n",
    "        cross_axis,\n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration,\n",
    "    )\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        h = sess.run(histograms)[0]\n",
    "        print(h.shape)\n",
    "        print(h)\n",
    "    \n",
    "    \n",
    "def test_get_min_nonzero():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_get_min_nonzero')\n",
    "    tensor = tf.concat([tf.zeros([2, 3, 4]), tf.ones([2, 3, 4]), 2*tf.ones([2, 3, 4]), 3*tf.ones([2, 3, 4])], 0)\n",
    "    nz = get_min_nonzero(tensor)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        print(sess.run([nz]))\n",
    "\n",
    "        \n",
    "def test_mutual_information_and_min_nonzero_count():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_mutual_information_and_min_nonzero_count')\n",
    "    with tf.device('/gpu:0'):\n",
    "#         rand_vec = tf.random_normal([1, 100000000])\n",
    "#         rand_vec_2 = tf.random_normal([1, 100000000])\n",
    "#         max_mutual_info_activations = tf.concat([rand_vec, -rand_vec], 0)\n",
    "#         min_mutual_info_activations = tf.concat([rand_vec, rand_vec_2], 0)\n",
    "        real_activatons = tf.random_normal([10, 16 * 10**6])\n",
    "        activations = real_activatons\n",
    "        value_axis = -1\n",
    "        cross_axis = -2\n",
    "        num_bins = 100\n",
    "        range_ = [-2., 2.]\n",
    "        mutual_info, min_num_events = mutual_information_and_min_nonzero_count(\n",
    "            activations,\n",
    "            value_axis, \n",
    "            cross_axis, \n",
    "            num_bins, \n",
    "            range_,\n",
    "            max_sample_size_per_iteration=2 * 10**4,\n",
    "        )\n",
    "        hists = hist_1d_loop(activations, num_bins, [-2., 2.], -1, 10**6)\n",
    "        entropy = entropy_MM_from_hist(hists, value_axis)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        entropy, mutual_info, min_num_events = sess.run(\n",
    "            [entropy, mutual_info, min_num_events],\n",
    "            options=run_options,\n",
    "        )\n",
    "        print('entropy:\\n', entropy)\n",
    "        print('\\nmutual_info:\\n', mutual_info)\n",
    "        print('\\nmin_num_events:\\n', min_num_events)\n",
    "        \n",
    "        \n",
    "def test_get_slice_specs():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_get_slice_specs')\n",
    "    shape = [3, 4, 5, 6]\n",
    "    idx = 2\n",
    "    axis = -1\n",
    "    sample_size = 10\n",
    "    start, size = get_slice_specs(shape, axis, idx, sample_size)\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run([start, size]))\n",
    "        \n",
    "\n",
    "def test_hist_1d_loop():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_hist_1d_loop')\n",
    "    values = tf.random_normal([10, 1000, 3])\n",
    "    num_bins = 20\n",
    "    range_ = [-3., 3.]\n",
    "    axis = 1\n",
    "    max_sample_size_per_iteration = 10\n",
    "    hist = hist_1d_loop(values, num_bins, range_, axis, max_sample_size_per_iteration)\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(hist))\n",
    "\n",
    "\n",
    "def test_mean_mutual_information_and_min_nonzero_count():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_mean_mutual_information_and_min_nonzero_count')\n",
    "    with tf.device('/gpu:0'):\n",
    "#         rand_vec = tf.random_normal([1, 100000000])\n",
    "#         rand_vec_2 = tf.random_normal([1, 100000000])\n",
    "#         max_mutual_info_activations = tf.concat([rand_vec, -rand_vec], 0)\n",
    "#         min_mutual_info_activations = tf.concat([rand_vec, rand_vec_2], 0)\n",
    "        real_activatons = tf.random_normal([10, 16 * 10**5])\n",
    "        activations = real_activatons\n",
    "        value_axis = -1\n",
    "        cross_axis = -2\n",
    "        num_bins = 100\n",
    "        range_ = [-2., 2.]\n",
    "        mutual_info, mean_mutual_info, min_num_events = mean_mutual_information_and_min_nonzero_count(\n",
    "            activations,\n",
    "            value_axis, \n",
    "            cross_axis, \n",
    "            num_bins, \n",
    "            range_,\n",
    "            max_sample_size_per_iteration=2 * 10**4,\n",
    "        )\n",
    "        hists = hist_1d_loop(activations, num_bins, range_, value_axis, 10**6)\n",
    "        entropy = entropy_MM_from_hist(hists, value_axis)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        entropy, mutual_info, mean_mutual_info, min_num_events = sess.run(\n",
    "            [entropy, mutual_info, mean_mutual_info, min_num_events],\n",
    "            options=run_options,\n",
    "        )\n",
    "        print('entropy:\\n', entropy)\n",
    "        print('\\nmutual_info:\\n', mutual_info)\n",
    "        print('\\nmean_mutual_info:\\n', mean_mutual_info)\n",
    "        print('\\nmin_num_events:\\n', min_num_events)\n",
    "\n",
    "\n",
    "\n",
    "test_shift_axis()\n",
    "test_get_output_shape_for_hist_1d()\n",
    "test_self_cross_sum_with_factors()\n",
    "test_hist_from_nonnegative_ints()\n",
    "test_cross_hist_from_tensor()\n",
    "test_add_cross_hist_1_slice_independent()\n",
    "test_get_init_shape_of_cross_histograms()\n",
    "test_sum_self_cross_histograms()\n",
    "test_get_cross_histograms_permutation()\n",
    "test_get_self_cross_histograms()\n",
    "test_get_min_nonzero()\n",
    "test_mean_mutual_information_and_min_nonzero_count()\n",
    "\n",
    "t = timeit.timeit(\n",
    "    stmt=\"test_mutual_information_and_min_nonzero_count()\",\n",
    "    globals=dict(\n",
    "        test_mutual_information_and_min_nonzero_count= \\\n",
    "            test_mutual_information_and_min_nonzero_count\n",
    "    ),\n",
    "    number=1,\n",
    ")\n",
    "print(t)\n",
    "\n",
    "test_get_slice_specs()\n",
    "test_hist_1d_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 0, 1, 1, 0, 2, 3, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 3, 2, 0, 2, 3, 0, 3, 0, 0, 0, 0, 1, 1, 2, 0, 0, 2, 1, 1, 0, 1, 0, 1, 2, 1, 0, 0, 3, 2, 3, 3, 0, 3, 3, 2, 2, 2, 0, 1, 2, 1, 0, 3, 0, 1, 3, 3, 3, 3, 1, 2, 3, 2, 1, 0, 1, 2, 2, 0, 0, 1, 3, 2, 0, 3, 3, 0, 3, 1, 0, 2, 1, 3, 1, 2, 1, 3]\n",
      "[3.30732052702613, 2.704484321925528, 1.1356599924090203, 4.960280783923953, 2.328815254189307, 3.042010708546553, 1.0874640825724153, 1.2471648896813257, 3.9991356343362647, 1.312624625567014, 2.0167593138575066, 1.0967421309369045, 1.4573367418188918, 3.5688291843674307, 3.5540065848419493, 1.6102653253746189, 3.5703106424130877, 3.560354627845804, 2.1141412582769825, 2.153727636254102, 2.198045370079959, 4.397287464329246, 3.2415730754342227, 2.7918545368810532, 1.861353516488777, 4.704413859583499, 2.2799691618100035, 1.1382637738031607, 1.182612751807552, 3.7394622452320494, 3.671164103430943, 1.4635704817548774, 3.1014481800254514, 2.4097307615425816, 4.599280675306451, 3.781698692097668, 1.049785719583884, 1.0786100463999386, 1.9134694620688677, 1.1153518412784633, 3.9458117066901033, 3.5130217637456664, 2.15305188260547, 3.1668874924253165, 2.019551726819736, 4.083701487041973, 2.3484751371204426, 2.8722709657093035, 2.4584690431797305, 1.2896373816667779, 3.947074702489574, 1.4469767245541973, 2.688843779222066, 1.5054439132484991, 3.3736613722513495, 4.6405775408332195, 2.709727031406505, 4.368051702255702, 3.8634623684891882, 1.323544859021029, 4.3127182494331535, 4.192746289709948, 4.4453669154191084, 2.6531966289466338, 1.1975509526711425, 2.5929871498337373, 1.838823789020501, 1.092816775899299, 2.8660757260579426, 3.7160289903913313, 4.816860890449714, 4.888063982557246, 1.3399695151898805, 3.887209980207013, 1.209655262129448, 2.0527073173480095, 4.9867550583711315, 2.40109826816526, 2.2183959307989793, 2.7194986626754183, 2.2902516009626703, 1.9679186958427555, 3.9130747792638156, 4.702825443400127, 1.8474419269146103, 2.858593682447594, 1.09930059385559, 4.9888864245062825, 2.987351029113643, 1.8574133592401953, 2.8251951305451253, 2.851723896210828, 3.0662129686422217, 4.759464622334973, 3.2772768350131893, 1.6463663560657202, 2.076307377842522, 4.149472063967252, 1.008369920624817, 4.69273032130854]\n"
     ]
    }
   ],
   "source": [
    "def sample_from_distribution(distr):\n",
    "    n = len(distr)\n",
    "    u = np.random.uniform()\n",
    "    start = 0\n",
    "    cumulative = []\n",
    "    for p in distr:\n",
    "        start += p\n",
    "        cumulative.append(start)\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= n:\n",
    "            raise ValueError(\n",
    "                \"random variable `u` and has not larger than 1.0\"\n",
    "                \" and sum of probabilities in distribution has to be equal to 1.0\"\n",
    "            )\n",
    "        if cumulative[i] > u:\n",
    "            return i\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "def sample_from_distribution_continuous(distr, borders):\n",
    "    n = len(distr)\n",
    "    u = np.random.uniform()\n",
    "    start = 0\n",
    "    cumulative = []\n",
    "    for p in distr:\n",
    "        start += p\n",
    "        cumulative.append(start)\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= n:\n",
    "            raise ValueError(\n",
    "                \"random variable `u` and has not larger than 1.0\"\n",
    "                \" and sum of probabilities in distribution has to be equal to 1.0\"\n",
    "            )\n",
    "        if cumulative[i] > u:\n",
    "            return np.random.uniform(borders[i][0], borders[i][1])\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def test_sample_from_distribution():\n",
    "    distr = [.25, .25, .25, .25, .0]\n",
    "    l = [sample_from_distribution(distr) for _ in range(100)]\n",
    "    print(l)\n",
    "    \n",
    "    \n",
    "def test_sample_from_distribution_continuous():\n",
    "    distr = [.0, .25, .25, .25, .25]\n",
    "    borders = [[float(i), float(i+1)] for i in range(5)]\n",
    "    l = [sample_from_distribution_continuous(distr, borders) for _ in range(100)]\n",
    "    print(l)\n",
    "    \n",
    "    \n",
    "test_sample_from_distribution()\n",
    "test_sample_from_distribution_continuous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************\n",
      "test_mean_mutual_information_and_min_nonzero_count\n",
      "\n",
      "####################\n",
      "number of points: 50\n",
      "entropy:\n",
      " [1.8101091 1.8832393 1.8098161 1.8285853]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.8163064  0.2481358  0.17387557 0.24109554]\n",
      "  [0.24813557 1.8981521  0.30713058 0.40756893]\n",
      "  [0.17387557 0.30713034 1.8105798  0.23249245]\n",
      "  [0.24109554 0.40756893 0.23249221 1.8424051 ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.26838312\n",
      "\n",
      "min_num_events:\n",
      " 1\n",
      "\n",
      "####################\n",
      "number of points: 100\n",
      "entropy:\n",
      " [1.8981922 1.8834307 1.7335024 1.770347 ]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.9014682  0.27717113 0.17181087 0.25773835]\n",
      "  [0.27717113 1.8877968  0.2035265  0.23029709]\n",
      "  [0.17181087 0.20352674 1.7220167  0.21127868]\n",
      "  [0.25773835 0.23029709 0.21127868 1.755602  ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.22530381\n",
      "\n",
      "min_num_events:\n",
      " 1\n",
      "\n",
      "####################\n",
      "number of points: 200\n",
      "entropy:\n",
      " [1.7037476 1.8134648 1.8772413 1.7626739]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.6968374  0.1178689  0.1412096  0.09154773]\n",
      "  [0.1178689  1.8162493  0.1356051  0.11317515]\n",
      "  [0.14120913 0.13560486 1.8794247  0.17885089]\n",
      "  [0.09154773 0.11317539 0.17885089 1.763342  ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.12970956\n",
      "\n",
      "min_num_events:\n",
      " 1\n",
      "\n",
      "####################\n",
      "number of points: 400\n",
      "entropy:\n",
      " [1.8260734 1.8151524 1.7725252 1.8224124]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.826712   0.18576837 0.15417457 0.18729472]\n",
      "  [0.18576837 1.8160967  0.12703347 0.12429142]\n",
      "  [0.15417504 0.12703323 1.7736675  0.11993194]\n",
      "  [0.18729472 0.12429142 0.11993194 1.8235883 ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.14974912\n",
      "\n",
      "min_num_events:\n",
      " 3\n",
      "\n",
      "####################\n",
      "number of points: 1000\n",
      "entropy:\n",
      " [1.8057078 1.823881  1.8213742 1.8013572]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.8061278  0.1586709  0.17176938 0.16511488]\n",
      "  [0.1586709  1.8242178  0.16899228 0.15512466]\n",
      "  [0.17176938 0.16899252 1.8217678  0.1521833 ]\n",
      "  [0.16511488 0.15512466 0.15218377 1.8017151 ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.16197598\n",
      "\n",
      "min_num_events:\n",
      " 13\n",
      "\n",
      "####################\n",
      "number of points: 2000\n",
      "entropy:\n",
      " [1.8080862 1.8108172 1.8015612 1.8097473]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.8082881  0.16211462 0.15157223 0.15694475]\n",
      "  [0.16211438 1.8110338  0.16407037 0.1591909 ]\n",
      "  [0.15157223 0.16407037 1.8017145  0.16717887]\n",
      "  [0.15694499 0.1591909  0.16717887 1.809952  ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.16017859\n",
      "\n",
      "min_num_events:\n",
      " 25\n",
      "\n",
      "####################\n",
      "number of points: 5000\n",
      "entropy:\n",
      " [1.8157122 1.8141875 1.8137021 1.8075076]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.8154811  0.16936398 0.16703343 0.15857196]\n",
      "  [0.16936374 1.814272   0.16531062 0.15544796]\n",
      "  [0.16703343 0.16531086 1.8137914  0.16118479]\n",
      "  [0.15857172 0.15544772 0.16118455 1.807587  ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.16281871\n",
      "\n",
      "min_num_events:\n",
      " 85\n",
      "\n",
      "####################\n",
      "number of points: 10000\n",
      "entropy:\n",
      " [1.8062695 1.805793  1.7968256 1.8032223]\n",
      "\n",
      "mutual_info:\n",
      " [[[1.8063107  0.16572475 0.15697122 0.16900182]\n",
      "  [0.16572523 1.8058314  0.15613937 0.165591  ]\n",
      "  [0.15697098 0.15613961 1.7966974  0.1601758 ]\n",
      "  [0.16900158 0.16559124 0.1601758  1.8030989 ]]]\n",
      "\n",
      "mean_mutual_info:\n",
      " 0.16226733\n",
      "\n",
      "min_num_events:\n",
      " 174\n"
     ]
    }
   ],
   "source": [
    "def test_mean_mutual_information_and_min_nonzero_count_2():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_mean_mutual_information_and_min_nonzero_count')\n",
    "    distr = [.0, .25, .25, .25, .25]\n",
    "    borders = [[float(i), float(i+1)] for i in range(5)]\n",
    "    with tf.device('/gpu:0'):\n",
    "#         rand_vec = tf.random_normal([1, 100000000])\n",
    "#         rand_vec_2 = tf.random_normal([1, 100000000])\n",
    "#         max_mutual_info_activations = tf.concat([rand_vec, -rand_vec], 0)\n",
    "#         min_mutual_info_activations = tf.concat([rand_vec, rand_vec_2], 0)\n",
    "        activations = tf.placeholder(tf.float32)\n",
    "        value_axis = -2\n",
    "        cross_axis = -1\n",
    "        num_bins = 5\n",
    "        range_ = [-0., 5.]\n",
    "        mutual_info, mean_mutual_info, min_num_events = mean_mutual_information_and_min_nonzero_count(\n",
    "            activations,\n",
    "            value_axis, \n",
    "            cross_axis, \n",
    "            num_bins, \n",
    "            range_,\n",
    "            max_sample_size_per_iteration=2 * 10**4,\n",
    "        )\n",
    "        hists = hist_1d_loop(activations, num_bins, range_, value_axis, 10**6)\n",
    "        entropy = entropy_MM_from_hist(hists, value_axis)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        for i in [50, 100, 200, 400, 1000, 2000, 5000, 10000]:\n",
    "            real_activations = np.array(\n",
    "                [\n",
    "                    [sample_from_distribution_continuous(distr, borders) for _ in range(i)] \n",
    "                    for _ in range(4)\n",
    "                ]\n",
    "            ).transpose()\n",
    "            entropy_r, mutual_info_r, mean_mutual_info_r, min_num_events_r = sess.run(\n",
    "                [entropy, mutual_info, mean_mutual_info, min_num_events],\n",
    "                options=run_options,\n",
    "                feed_dict={activations: real_activations}\n",
    "            )\n",
    "            print('\\n' + '#'*20)\n",
    "            print(\"number of points:\", i)\n",
    "            print('entropy:\\n', entropy_r)\n",
    "            print('\\nmutual_info:\\n', mutual_info_r)\n",
    "            print('\\nmean_mutual_info:\\n', mean_mutual_info_r)\n",
    "            print('\\nmin_num_events:\\n', min_num_events_r)\n",
    "\n",
    "\n",
    "def test_mean_mutual_information_and_min_nonzero_count_3():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_mean_mutual_information_and_min_nonzero_count')\n",
    "    distr = [.0, .25, .25, .25, .25]\n",
    "    borders = [[float(i), float(i+1)] for i in range(5)]\n",
    "    with tf.device('/gpu:0'):\n",
    "#         rand_vec = tf.random_normal([1, 100000000])\n",
    "#         rand_vec_2 = tf.random_normal([1, 100000000])\n",
    "#         max_mutual_info_activations = tf.concat([rand_vec, -rand_vec], 0)\n",
    "#         min_mutual_info_activations = tf.concat([rand_vec, rand_vec_2], 0)\n",
    "        activations = tf.placeholder(tf.float32)\n",
    "        value_axis = -2\n",
    "        cross_axis = -1\n",
    "        num_bins = 5\n",
    "        range_ = [-0., 5.]\n",
    "        mutual_info, mean_mutual_info, min_num_events = mean_mutual_information_and_min_nonzero_count(\n",
    "            activations,\n",
    "            value_axis, \n",
    "            cross_axis, \n",
    "            num_bins, \n",
    "            range_,\n",
    "            max_sample_size_per_iteration=2 * 10**4,\n",
    "        )\n",
    "        hists = hist_1d_loop(activations, num_bins, range_, value_axis, 10**6)\n",
    "        entropy = entropy_MM_from_hist(hists, value_axis)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        for i in [50, 100, 200, 400, 1000, 2000, 5000, 10000]:\n",
    "            real_activations = np.array(\n",
    "                [\n",
    "                    [sample_from_distribution_continuous(distr, borders) for _ in range(i)] \n",
    "                    for _ in range(2)\n",
    "                ] + [[sample_from_distribution_continuous(distr, borders) for _ in range(i)]]*2\n",
    "            ).transpose()\n",
    "            entropy_r, mutual_info_r, mean_mutual_info_r, min_num_events_r = sess.run(\n",
    "                [entropy, mutual_info, mean_mutual_info, min_num_events],\n",
    "                options=run_options,\n",
    "                feed_dict={activations: real_activations}\n",
    "            )\n",
    "            print('\\n' + '#'*20)\n",
    "            print(\"number of points:\", i)\n",
    "            print('entropy:\\n', entropy_r)\n",
    "            print('\\nmutual_info:\\n', mutual_info_r)\n",
    "            print('\\nmean_mutual_info:\\n', mean_mutual_info_r)\n",
    "            print('\\nmin_num_events:\\n', min_num_events_r)\n",
    "            \n",
    "            \n",
    "def test_mean_mutual_information_and_min_nonzero_count_4():\n",
    "    print('\\n' + \"*\"*20 + '\\ntest_mean_mutual_information_and_min_nonzero_count')\n",
    "    distr = [.0, .25, .25, .25, .25]\n",
    "    borders = [[float(i), float(i+1)] for i in range(5)]\n",
    "    with tf.device('/gpu:0'):\n",
    "#         rand_vec = tf.random_normal([1, 100000000])\n",
    "#         rand_vec_2 = tf.random_normal([1, 100000000])\n",
    "#         max_mutual_info_activations = tf.concat([rand_vec, -rand_vec], 0)\n",
    "#         min_mutual_info_activations = tf.concat([rand_vec, rand_vec_2], 0)\n",
    "        activations = tf.placeholder(tf.float32)\n",
    "        value_axis = -2\n",
    "        cross_axis = -1\n",
    "        num_bins = 5\n",
    "        range_ = [-0., 5.]\n",
    "        mutual_info, mean_mutual_info, min_num_events = mean_mutual_information_and_min_nonzero_count(\n",
    "            activations,\n",
    "            value_axis, \n",
    "            cross_axis, \n",
    "            num_bins, \n",
    "            range_,\n",
    "            max_sample_size_per_iteration=2 * 10**4,\n",
    "        )\n",
    "        hists = hist_1d_loop(activations, num_bins, range_, value_axis, 10**6)\n",
    "        entropy = entropy_MM_from_hist(hists, value_axis)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        for i in [50, 100, 200, 400, 1000, 2000, 5000, 10000]:\n",
    "            real_activations = 0.5 * np.array(\n",
    "                [\n",
    "                    [sample_from_distribution_continuous(distr, borders) for _ in range(i)] \n",
    "                    for _ in range(4)\n",
    "                ] + np.array([[sample_from_distribution_continuous(distr, borders) for _ in range(i)]]*4)\n",
    "            ).transpose()\n",
    "            entropy_r, mutual_info_r, mean_mutual_info_r, min_num_events_r = sess.run(\n",
    "                [entropy, mutual_info, mean_mutual_info, min_num_events],\n",
    "                options=run_options,\n",
    "                feed_dict={activations: real_activations}\n",
    "            )\n",
    "            print('\\n' + '#'*20)\n",
    "            print(\"number of points:\", i)\n",
    "            print('entropy:\\n', entropy_r)\n",
    "            print('\\nmutual_info:\\n', mutual_info_r)\n",
    "            print('\\nmean_mutual_info:\\n', mean_mutual_info_r)\n",
    "            print('\\nmin_num_events:\\n', min_num_events_r)\n",
    "\n",
    "\n",
    "test_mean_mutual_information_and_min_nonzero_count_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************\n",
      "PermuteTwoAxes\n",
      "[array([[[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "       [[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]]], dtype=float32), array([[[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "       [[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]]], dtype=float32), array([[[[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [5.]],\n",
      "\n",
      "        [[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [5.]],\n",
      "\n",
      "        [[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [5.]]],\n",
      "\n",
      "\n",
      "       [[[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [5.]],\n",
      "\n",
      "        [[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [5.]],\n",
      "\n",
      "        [[5.],\n",
      "         [5.],\n",
      "         [5.],\n",
      "         [5.]]]], dtype=float32)]\n",
      "\n",
      "********************\n",
      "TensorToMatrix\n",
      "[array([[ 0,  1,  2,  3],\n",
      "       [ 4,  5,  6,  7],\n",
      "       [ 8,  9, 10, 11]], dtype=int32), array([[ 0,  1,  2,  3],\n",
      "       [ 4,  5,  6,  7],\n",
      "       [ 8,  9, 10, 11]], dtype=int32), array([[ 6],\n",
      "       [22],\n",
      "       [38]], dtype=int32)]\n",
      "\n",
      "********************\n",
      "hist_1d\n",
      "[array([[[  0,   0],\n",
      "        [  0,   0],\n",
      "        [  0,   0],\n",
      "        [ 25,  15],\n",
      "        [136, 129],\n",
      "        [265, 289],\n",
      "        [314, 358],\n",
      "        [196, 163],\n",
      "        [ 64,  46],\n",
      "        [  0,   0]],\n",
      "\n",
      "       [[  0,   0],\n",
      "        [  0,   0],\n",
      "        [  0,   0],\n",
      "        [ 14,  12],\n",
      "        [134, 126],\n",
      "        [275, 308],\n",
      "        [310, 306],\n",
      "        [213, 199],\n",
      "        [ 54,  49],\n",
      "        [  0,   0]],\n",
      "\n",
      "       [[  0,   0],\n",
      "        [  0,   0],\n",
      "        [  0,   0],\n",
      "        [ 16,  14],\n",
      "        [132, 126],\n",
      "        [282, 271],\n",
      "        [323, 317],\n",
      "        [194, 212],\n",
      "        [ 53,  60],\n",
      "        [  0,   0]],\n",
      "\n",
      "       [[  0,   0],\n",
      "        [  0,   0],\n",
      "        [  0,   0],\n",
      "        [ 15,  19],\n",
      "        [130, 128],\n",
      "        [284, 298],\n",
      "        [312, 309],\n",
      "        [195, 194],\n",
      "        [ 64,  52],\n",
      "        [  0,   0]],\n",
      "\n",
      "       [[  0,   0],\n",
      "        [  0,   0],\n",
      "        [  0,   0],\n",
      "        [ 13,  22],\n",
      "        [142, 139],\n",
      "        [274, 280],\n",
      "        [306, 305],\n",
      "        [199, 193],\n",
      "        [ 66,  61],\n",
      "        [  0,   0]]], dtype=int32)]\n",
      "\n",
      "********************\n",
      "compute_probabilities\n",
      "[array([[[0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.01      , 0.018     ],\n",
      "        [0.12      , 0.135     ],\n",
      "        [0.305     , 0.26900002],\n",
      "        [0.316     , 0.31800002],\n",
      "        [0.17600001, 0.2       ],\n",
      "        [0.07300001, 0.06      ],\n",
      "        [0.        , 0.        ]],\n",
      "\n",
      "       [[0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.016     , 0.016     ],\n",
      "        [0.132     , 0.12100001],\n",
      "        [0.261     , 0.294     ],\n",
      "        [0.30200002, 0.337     ],\n",
      "        [0.21100001, 0.18800001],\n",
      "        [0.078     , 0.044     ],\n",
      "        [0.        , 0.        ]],\n",
      "\n",
      "       [[0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.015     , 0.019     ],\n",
      "        [0.11000001, 0.12400001],\n",
      "        [0.256     , 0.259     ],\n",
      "        [0.33600003, 0.324     ],\n",
      "        [0.208     , 0.21700001],\n",
      "        [0.075     , 0.057     ],\n",
      "        [0.        , 0.        ]],\n",
      "\n",
      "       [[0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.015     , 0.02      ],\n",
      "        [0.13800001, 0.12      ],\n",
      "        [0.26900002, 0.259     ],\n",
      "        [0.31500003, 0.303     ],\n",
      "        [0.20400001, 0.22800002],\n",
      "        [0.059     , 0.07      ],\n",
      "        [0.        , 0.        ]],\n",
      "\n",
      "       [[0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.        , 0.        ],\n",
      "        [0.012     , 0.011     ],\n",
      "        [0.11800001, 0.119     ],\n",
      "        [0.27600002, 0.26500002],\n",
      "        [0.3       , 0.305     ],\n",
      "        [0.23900001, 0.23500001],\n",
      "        [0.055     , 0.06500001],\n",
      "        [0.        , 0.        ]]], dtype=float32)]\n",
      "\n",
      "********************\n",
      "entropy_MLE_from_prob\n",
      "[[ 1.5632691 ]\n",
      " [-0.        ]\n",
      " [ 0.92192805]]\n",
      "\n",
      "********************\n",
      "entropy_MM_from_prob\n",
      "[array([[1.5732691 ],\n",
      "       [1.005     ],\n",
      "       [0.93192804]], dtype=float32)]\n",
      "\n",
      "********************\n",
      "entropy_MLE_from_hist\n",
      "[[ 1.5849626 ]\n",
      " [ 1.5849626 ]\n",
      " [ 1.4591479 ]\n",
      " [ 0.02277425]\n",
      " [-0.        ]]\n",
      "\n",
      "********************\n",
      "entropy_MM_from_hist\n",
      "[[1.918296  ]\n",
      " [1.7516292 ]\n",
      " [1.6258146 ]\n",
      " [0.02287406]\n",
      " [0.        ]]\n",
      "\n",
      "********************\n",
      "mean_neuron_entropy\n",
      "5.854674\n",
      "\n",
      "********************\n",
      "entropy_MM_from_hist\n",
      "[5.823768  5.7940307 5.774404  5.723738  5.7974825 5.6507945 5.804626\n",
      " 5.6415105 5.7013464 5.7726483]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def test_PermuteTwoAxes():\n",
    "    print('\\n' + \"*\"*20 + '\\nPermuteTwoAxes')\n",
    "#     a = tf.reshape(tf.range(12), [3, 4])\n",
    "    a = tf.ones([2, 3, 4, 5])\n",
    "\n",
    "    with PermuteTwoAxes(a, -2, axis_2=1) as ctx:\n",
    "        t = ctx.tensor\n",
    "        ctx.tensor = tf.reduce_sum(t, axis=-1, keepdims=True)\n",
    "\n",
    "    t2 = ctx.tensor\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # print(sess.run(ctx.print))\n",
    "        print(sess.run([a, t, t2]))\n",
    "        \n",
    "\n",
    "def test_TensorToMatrix():\n",
    "    print('\\n' + \"*\"*20 + '\\nTensorToMatrix')\n",
    "    a = tf.reshape(tf.range(12), [3, 4])\n",
    "    with TensorToMatrix(a) as ctx:\n",
    "        t = ctx.tensor\n",
    "        ctx.tensor = tf.reduce_sum(t, axis=-1, keepdims=True)\n",
    "\n",
    "    t2 = ctx.tensor\n",
    "    with tf.Session() as sess:\n",
    "        # print(sess.run(ctx.print))\n",
    "        print(sess.run([a, t, t2]))\n",
    "        \n",
    "        \n",
    "def test_hist_1d():\n",
    "    print('\\n' + \"*\"*20 + '\\nhist_1d')\n",
    "    a = tf.truncated_normal([5, 1000, 2], mean=1, stddev=1)\n",
    "    num_bins = 10\n",
    "    range_ = [-4., 4.]\n",
    "    axis = -2\n",
    "    histograms = hist_1d(a, num_bins, range_, axis)\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run([histograms]))\n",
    "        \n",
    "        \n",
    "def test_compute_probabilities():\n",
    "    print('\\n' + \"*\"*20 + '\\ncompute_probabilities')\n",
    "    a = tf.truncated_normal([5, 1000, 2], mean=1, stddev=1)\n",
    "    num_bins = 10\n",
    "    range_ = [-4., 4.]\n",
    "    axis = -2\n",
    "    probabilities = compute_probabilities(a, num_bins, range_, axis)\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run([probabilities]))\n",
    "        \n",
    "        \n",
    "def test_entropy_MM_from_prob():\n",
    "    print('\\n' + \"*\"*20 + '\\nentropy_MM_from_prob')\n",
    "    axis = -2\n",
    "    probabilities = tf.constant(\n",
    "        [[[0.3], [0.3], [0.3]],\n",
    "         [[.5], [.5], [0.]],\n",
    "         [[.1], [.1], [.8]]]\n",
    "    )\n",
    "    n = 100\n",
    "    shape = tf.shape(probabilities)\n",
    "    m = [[[3]], [[2]], [[3]]]\n",
    "    entropy = entropy_MM_from_prob(probabilities, n, m, axis)\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run([entropy]))\n",
    "        \n",
    "        \n",
    "def test_entropy_MLE_from_prob():\n",
    "    print('\\n' + \"*\"*20 + '\\nentropy_MLE_from_prob')\n",
    "    axis = -2\n",
    "    probabilities = tf.constant(\n",
    "        [[[0.3], [0.3], [0.3]],\n",
    "         [[1.], [0.], [0.]],\n",
    "         [[.1], [.1], [.8]]]\n",
    "    )\n",
    "    entropy = entropy_MLE_from_prob(probabilities, axis)\n",
    "    with tf.Session() as sess:\n",
    "        res = sess.run(entropy)\n",
    "        print(res)\n",
    "        \n",
    "        \n",
    "def test_entropy_MLE_from_hist():\n",
    "    print('\\n' + \"*\"*20 + '\\nentropy_MLE_from_hist')\n",
    "    axis = 1\n",
    "    hist = tf.constant(\n",
    "        [[[1], [1], [1]],\n",
    "         [[2], [2], [2]],\n",
    "         [[1], [2], [3]],\n",
    "         [[10], [10000], [10]],\n",
    "         [[0], [0], [1]]]\n",
    "    )\n",
    "    entropy = entropy_MLE_from_hist(hist, axis)\n",
    "    with tf.Session() as sess:\n",
    "        res = sess.run(entropy)\n",
    "        print(res)\n",
    "        \n",
    "        \n",
    "def test_entropy_MM_from_hist():\n",
    "    print('\\n' + \"*\"*20 + '\\nentropy_MM_from_hist')\n",
    "    axis = -2\n",
    "    hist = tf.constant(\n",
    "        [[[1], [1], [1]],\n",
    "         [[2], [2], [2]],\n",
    "         [[1], [2], [3]],\n",
    "         [[10], [10000], [10]],\n",
    "         [[0], [0], [1]]]\n",
    "    )\n",
    "    entropy = entropy_MM_from_hist(hist, axis)\n",
    "    with tf.Session() as sess:\n",
    "        res = sess.run(entropy)\n",
    "        print(res)\n",
    "        \n",
    "        \n",
    "def test_mean_neuron_entropy():\n",
    "    print('\\n' + \"*\"*20 + '\\nmean_neuron_entropy')\n",
    "    a = tf.truncated_normal([10, 1000])\n",
    "    axis = 1\n",
    "    mean_entropy = mean_neuron_entropy(a, axis, 100, [-3., 3.])\n",
    "    with tf.Session() as sess:\n",
    "        res = sess.run(mean_entropy)\n",
    "        print(res)\n",
    "\n",
    "\n",
    "def test2_entropy_MM_from_hist():\n",
    "    print('\\n' + \"*\"*20 + '\\nentropy_MM_from_hist')\n",
    "    axis = -1\n",
    "    a = tf.truncated_normal([10, 1000])\n",
    "    hist = hist_1d(a, 100, [-1., 1.], axis)\n",
    "    entropy = entropy_MM_from_hist(hist, axis)\n",
    "    with tf.Session() as sess:\n",
    "        res = sess.run(entropy)\n",
    "        print(res)\n",
    "    \n",
    "\n",
    "test_PermuteTwoAxes()\n",
    "test_TensorToMatrix()\n",
    "test_hist_1d()\n",
    "test_compute_probabilities()\n",
    "test_entropy_MLE_from_prob()\n",
    "test_entropy_MM_from_prob()\n",
    "test_entropy_MLE_from_hist()\n",
    "test_entropy_MM_from_hist()\n",
    "test_mean_neuron_entropy()\n",
    "test2_entropy_MM_from_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def hist_1d_loop_numpy(tensor, num_bins, range_, axis, sample_size):\n",
    "    ndim = tensor.ndim\n",
    "    axis %= ndim\n",
    "    shape = tensor.shape\n",
    "    idx = 0\n",
    "    hist = 0\n",
    "    while idx < shape[axis]:\n",
    "        sl = [slice(None)]*axis + \\\n",
    "            [slice(idx, idx+sample_size)] + \\\n",
    "            [slice(None)]*(ndim-2-axis)\n",
    "        sl = tuple(sl)\n",
    "        t = tensor[sl]\n",
    "        hist += hist_1d_numpy(t, num_bins, range_, axis)\n",
    "        idx += sample_size\n",
    "    return hist\n",
    "\n",
    "\n",
    "def adjust_histogram_range_for_numpy(range_, num_bins):\n",
    "    range_ = list(range_)\n",
    "    h = (range_[1] - range_[0]) / num_bins\n",
    "    range_[0] += h\n",
    "    range_[1] -= h\n",
    "    return range_\n",
    "\n",
    "\n",
    "def hist_1d_numpy(tensor, num_bins, range_, axis):\n",
    "    range_ = adjust_histogram_range_for_numpy(range_, num_bins)\n",
    "    bins = np.histogram_bin_edges(tensor, num_bins-2, range_)\n",
    "    tensor = np.digitize(tensor, bins)\n",
    "    tensor = hist_from_nonnegative_ints_numpy(\n",
    "        tensor,\n",
    "        axis,\n",
    "        num_bins\n",
    "    )\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def shift_axis_numpy(\n",
    "        tensor,\n",
    "        axis,\n",
    "        pos,\n",
    "):\n",
    "    shape = tensor.shape\n",
    "    ndim = tensor.ndim\n",
    "    axis %= ndim\n",
    "    pos %= ndim\n",
    "    dims = list(range(ndim))\n",
    "    if axis == pos:\n",
    "        return tensor\n",
    "    if pos > axis:\n",
    "        perm = dims[:axis] + dims[axis+1:pos+1] + [axis] + dims[pos+1:]\n",
    "    else:\n",
    "        perm = dims[:pos] + [axis] + dims[pos:axis] + dims[axis+1:]\n",
    "    return tensor.transpose(*perm)\n",
    "\n",
    "\n",
    "def hist_from_nonnegative_ints_numpy(\n",
    "        tensor,\n",
    "        axis,\n",
    "        num_bins\n",
    "):\n",
    "    tensor = shift_axis_numpy(tensor, axis, -1)\n",
    "    shape = tensor.shape\n",
    "    tensor = tensor.reshape([-1, shape[-1]])\n",
    "    n = tensor.shape[0]\n",
    "    shifts = (np.arange(n) * num_bins).reshape([-1, 1])\n",
    "    tensor += shifts\n",
    "    tensor = tensor.reshape([-1])\n",
    "    tensor = np.bincount(tensor, minlength=n*num_bins)\n",
    "    tensor = tensor.reshape(list(shape[:-1]) + [-1])\n",
    "    return shift_axis_numpy(tensor, -1, axis)\n",
    "\n",
    "\n",
    "def self_cross_sum_numpy(\n",
    "        tensor,\n",
    "        axis,\n",
    "):\n",
    "    axis %= tensor.ndim\n",
    "    tensor_2 = np.expand_dims(tensor, axis=axis+1)\n",
    "    tensor = np.expand_dims(tensor, axis=axis)\n",
    "    return tensor + tensor_2\n",
    "\n",
    "\n",
    "def self_cross_sum_numpy_with_factors(\n",
    "        tensor,\n",
    "        axis,\n",
    "        f1,\n",
    "        f2,\n",
    "):\n",
    "    axis %= tensor.ndim\n",
    "    tensor_2 = np.expand_dims(tensor, axis=axis+1)\n",
    "    tensor = np.expand_dims(tensor, axis=axis)\n",
    "    mul1 = f1 * tensor\n",
    "    mul2 = f2 * tensor_2\n",
    "    s = mul1 + mul2\n",
    "    return s\n",
    "\n",
    "\n",
    "def self_cross_hist(\n",
    "        tensor,\n",
    "        value_axis,\n",
    "        cross_axis,\n",
    "        num_bins,\n",
    "        range_,\n",
    "):\n",
    "    ndim = tensor.ndim\n",
    "    value_axis %= ndim\n",
    "    cross_axis %= ndim\n",
    "    range_ = adjust_histogram_range_for_numpy(range_, num_bins)\n",
    "    bins = np.histogram_bin_edges(tensor, num_bins-2, range_)\n",
    "    tensor = np.digitize(tensor, bins)\n",
    "    tensor = self_cross_sum_numpy_with_factors(tensor, cross_axis, 1, num_bins)\n",
    "    value_axis += int(value_axis > cross_axis)\n",
    "    hist = hist_from_nonnegative_ints_numpy(tensor, value_axis, num_bins**2)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def get_self_cross_histograms_numpy(\n",
    "        activations,\n",
    "        value_axis,\n",
    "        cross_axis,\n",
    "        num_bins,\n",
    "        range_,\n",
    "        max_sample_size_per_iteration=10**3,\n",
    "):\n",
    "    ndim = activations.ndim\n",
    "    value_axis %= ndim\n",
    "    cross_axis %= ndim\n",
    "    shape = activations.shape\n",
    "    idx = 0\n",
    "    hist = 0\n",
    "    while idx < shape[value_axis]:\n",
    "        sl = [slice(None)]*value_axis + \\\n",
    "            [slice(idx, idx+max_sample_size_per_iteration)] + \\\n",
    "            [slice(None)]*(ndim-2-value_axis)\n",
    "        sl = tuple(sl)\n",
    "        tensor = activations[sl]\n",
    "        hist += self_cross_hist(\n",
    "            tensor,\n",
    "            value_axis,\n",
    "            cross_axis,\n",
    "            num_bins,\n",
    "            range_,\n",
    "        )\n",
    "        idx += max_sample_size_per_iteration\n",
    "    return hist\n",
    "\n",
    "\n",
    "def entropy_MLE_from_hist_numpy(hist, axis, keepdims=False):\n",
    "    n = np.sum(hist, axis=axis, keepdims=True)\n",
    "    hist = hist / n\n",
    "    log_prob = np.log2(hist)\n",
    "    hist *= log_prob\n",
    "    hist = np.nan_to_num(hist)\n",
    "    return -np.sum(hist, axis=axis, keepdims=keepdims)\n",
    "\n",
    "\n",
    "def entropy_MM_from_hist_numpy(hist, axis, keepdims=False):\n",
    "    entropy = entropy_MLE_from_hist_numpy(hist, axis, keepdims=True)\n",
    "    m = np.count_nonzero(hist, axis=axis)\n",
    "    m = np.expand_dims(m, axis=axis)\n",
    "    n = np.sum(hist, axis=axis, keepdims=True)\n",
    "    entropy = entropy + (m - 1) / (2*n)\n",
    "    if keepdims:\n",
    "        return entropy\n",
    "    return np.squeeze(entropy + (m - 1) / (2*n), axis=axis)\n",
    "\n",
    "\n",
    "def mutual_information_and_min_nonzero_count_numpy(\n",
    "        activations,\n",
    "        value_axis, \n",
    "        cross_axis, \n",
    "        num_bins, \n",
    "        range_, \n",
    "        keepdims=False,\n",
    "        sample_size_1d=5*10**5,\n",
    "        sample_size_2d=2*10**5\n",
    "):\n",
    "    hist = hist_1d_loop_numpy(activations, num_bins, range_, value_axis, sample_size_1d)\n",
    "    entropy = entropy_MM_from_hist_numpy(hist, value_axis, keepdims=True)\n",
    "    entropy_sum = self_cross_sum_numpy(entropy, cross_axis)\n",
    "    cross_hist = get_self_cross_histograms_numpy(\n",
    "        activations,\n",
    "        value_axis, \n",
    "        cross_axis, \n",
    "        num_bins, \n",
    "        range_, \n",
    "        sample_size_2d\n",
    "    )\n",
    "    value_axis += int(value_axis > cross_axis)\n",
    "    joint_entropy = entropy_MM_from_hist_numpy(cross_hist, value_axis, keepdims=True)\n",
    "    entropy = entropy_sum - joint_entropy\n",
    "    m = np.count_nonzero(cross_hist, axis=value_axis)\n",
    "    min_nonzero = np.min(cross_hist)\n",
    "    if keepdims:\n",
    "        return entropy, min_nonzero\n",
    "    return np.squeeze(entropy, axis=value_axis), min_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "[-1.96 -1.92 -1.88 -1.84 -1.8  -1.76 -1.72 -1.68 -1.64 -1.6  -1.56 -1.52\n",
      " -1.48 -1.44 -1.4  -1.36 -1.32 -1.28 -1.24 -1.2  -1.16 -1.12 -1.08 -1.04\n",
      " -1.   -0.96 -0.92 -0.88 -0.84 -0.8  -0.76 -0.72 -0.68 -0.64 -0.6  -0.56\n",
      " -0.52 -0.48 -0.44 -0.4  -0.36 -0.32 -0.28 -0.24 -0.2  -0.16 -0.12 -0.08\n",
      " -0.04  0.    0.04  0.08  0.12  0.16  0.2   0.24  0.28  0.32  0.36  0.4\n",
      "  0.44  0.48  0.52  0.56  0.6   0.64  0.68  0.72  0.76  0.8   0.84  0.88\n",
      "  0.92  0.96  1.    1.04  1.08  1.12  1.16  1.2   1.24  1.28  1.32  1.36\n",
      "  1.4   1.44  1.48  1.52  1.56  1.6   1.64  1.68  1.72  1.76  1.8   1.84\n",
      "  1.88  1.92  1.96]\n",
      "0\n",
      "[[6.45728508e+00 1.32888555e-03 1.32452149e-03 1.37501060e-03\n",
      "  1.38745637e-03 1.37702866e-03 1.44183932e-03 1.41081275e-03\n",
      "  1.38396210e-03 1.33528168e-03]\n",
      " [1.32888555e-03 6.45811881e+00 1.40501405e-03 1.38022226e-03\n",
      "  1.30722517e-03 1.39299922e-03 1.34666039e-03 1.49983963e-03\n",
      "  1.33854215e-03 1.32081803e-03]\n",
      " [1.32452149e-03 1.40501405e-03 6.45679741e+00 1.28815987e-03\n",
      "  1.30594634e-03 1.32036007e-03 1.42244833e-03 1.26088302e-03\n",
      "  1.30613922e-03 1.36103284e-03]\n",
      " [1.37501060e-03 1.38022226e-03 1.28815987e-03 6.45709004e+00\n",
      "  1.28704244e-03 1.37754522e-03 1.49285582e-03 1.34980165e-03\n",
      "  1.41782326e-03 1.44347462e-03]\n",
      " [1.38745637e-03 1.30722517e-03 1.30594634e-03 1.28704244e-03\n",
      "  6.45712685e+00 1.33103909e-03 1.34026179e-03 1.40997405e-03\n",
      "  1.46485749e-03 1.43916164e-03]\n",
      " [1.37702866e-03 1.39299922e-03 1.32036007e-03 1.37754522e-03\n",
      "  1.33103909e-03 6.45686770e+00 1.33383807e-03 1.30500528e-03\n",
      "  1.34289558e-03 1.34168433e-03]\n",
      " [1.44183932e-03 1.34666039e-03 1.42244833e-03 1.49285582e-03\n",
      "  1.34026179e-03 1.33383807e-03 6.45704935e+00 1.37679806e-03\n",
      "  1.38118165e-03 1.31379647e-03]\n",
      " [1.41081275e-03 1.49983963e-03 1.26088302e-03 1.34980165e-03\n",
      "  1.40997405e-03 1.30500528e-03 1.37679806e-03 6.45772995e+00\n",
      "  1.38608624e-03 1.38205520e-03]\n",
      " [1.38396210e-03 1.33854215e-03 1.30613922e-03 1.41782326e-03\n",
      "  1.46485749e-03 1.34289558e-03 1.38118165e-03 1.38608624e-03\n",
      "  6.45840888e+00 1.34478929e-03]\n",
      " [1.33528168e-03 1.32081803e-03 1.36103284e-03 1.44347462e-03\n",
      "  1.43916164e-03 1.34168433e-03 1.31379647e-03 1.38205520e-03\n",
      "  1.34478929e-03 6.45728958e+00]]\n",
      "2.68614584999159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:157: RuntimeWarning: divide by zero encountered in log2\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:158: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def test_shift_axis_numpy():\n",
    "    a = np.zeros((3, 10, 2))\n",
    "    a = shift_axis_numpy(a, 1, 2)\n",
    "    print(a)\n",
    "\n",
    "\n",
    "def test_hist_from_nonnegative_ints_numpy():\n",
    "    a = np.random.randint(0, 10, size=(3, 10, 2))\n",
    "    hist = hist_from_nonnegative_ints_numpy(a, 1, 10)\n",
    "    print(hist)\n",
    "    \n",
    "\n",
    "def test_hist_1d_numpy():\n",
    "    a = np.random.normal(size=[3, 10000, 2])\n",
    "    hist = hist_1d_numpy(a, 30, [-3., 3.], 1)\n",
    "    print(hist)\n",
    "    \n",
    "    \n",
    "def test_self_cross_sum_numpy():\n",
    "    a = np.tile(np.arange(4).reshape([1, -1]), (3, 1))\n",
    "    a = self_cross_sum_numpy(a, 0)\n",
    "    print(a)\n",
    "\n",
    "\n",
    "def test_self_cross_sum_numpy_with_factors():\n",
    "    a = np.arange(4)\n",
    "    a = self_cross_sum_numpy_with_factors(a, 0, 10, 1)\n",
    "    print(a)\n",
    "\n",
    "\n",
    "def test_self_cross_hist():\n",
    "    a = np.random.normal(size=[10**4, 4])\n",
    "    hist = self_cross_hist(a, 0, 1, 10, [-3., 3.])\n",
    "    print(hist)\n",
    "\n",
    "\n",
    "def test_get_self_cross_histograms_numpy():\n",
    "    a = np.random.normal(size=[4, 10**4])\n",
    "    params = (a, 1, 0, 10, [-3., 3.])\n",
    "    hist = get_self_cross_histograms_numpy(*params, 100)\n",
    "    hist_simple = self_cross_hist(*params)\n",
    "    print(np.all(hist == hist_simple))\n",
    "    print(hist)\n",
    "\n",
    "\n",
    "def test_entropy_MLE_from_hist_numpy():\n",
    "    hist = np.random.randint(0, 100, size=[10000, 4])\n",
    "    entropy = entropy_MLE_from_hist_numpy(hist, 0, keepdims=True)\n",
    "    print(entropy)\n",
    "\n",
    "\n",
    "def test_entropy_MM_from_hist_numpy():\n",
    "    hist = np.random.randint(0, 100, size=[10000, 4])\n",
    "    entropy = entropy_MM_from_hist_numpy(hist, 0, keepdims=True)\n",
    "    print(entropy)\n",
    "\n",
    "\n",
    "def test_mutual_information_and_min_nonzero_count_numpy():\n",
    "    activations = np.random.normal(size=[10, 16 * 10**5])\n",
    "    mi, mnz = mutual_information_and_min_nonzero_count_numpy(\n",
    "        activations,\n",
    "        -1, 0,\n",
    "        100,\n",
    "        [-2., 2.],\n",
    "    )\n",
    "    print(mnz)\n",
    "    print(mi)\n",
    "\n",
    "\n",
    "def test_hist_1d_loop_numpy():\n",
    "    a = np.random.normal(size=[3, 10000, 2])\n",
    "    hist = hist_1d_loop_numpy(a, 100, [-2., 2.], 1, 100)\n",
    "    print(hist)\n",
    "\n",
    "\n",
    "# test_shift_axis_numpy()\n",
    "# test_hist_from_nonnegative_ints_numpy()\n",
    "# test_hist_1d_numpy()\n",
    "# test_self_cross_sum_numpy()\n",
    "# test_self_cross_sum_numpy_with_factors()\n",
    "# test_get_self_cross_histograms_numpy()\n",
    "# test_entropy_MLE_from_hist_numpy()\n",
    "# test_entropy_MM_from_hist_numpy()\n",
    "\n",
    "t = timeit.timeit(\n",
    "    stmt=\"test_mutual_information_and_min_nonzero_count_numpy()\",\n",
    "    globals=dict(\n",
    "        test_mutual_information_and_min_nonzero_count_numpy=test_mutual_information_and_min_nonzero_count_numpy\n",
    "    ),\n",
    "    number=1\n",
    ")\n",
    "print(t)\n",
    "\n",
    "# test_hist_1d_loop_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 2 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bins = np.histogram_bin_edges([1], 8, [1., 9.])\n",
    "a = np.array([-1., 0., 1., 1.5, 2.5, 10.4])\n",
    "d = np.digitize(a, bins)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2169441995676607\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "a = np.zeros([10**4, 10**4])\n",
    "b = np.zeros([10**4, 10**4])\n",
    "\n",
    "N = 100\n",
    "\n",
    "t = timeit.timeit(\n",
    "    stmt=\"c = a + b\",\n",
    "    globals=dict(a=a, b=b),\n",
    "    number=N\n",
    ")\n",
    "\n",
    "print(t / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.Variable(0, trainable=False)\n",
    "\n",
    "op = tf.assign_add(a, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run([op, op])\n",
    "    print(a.eval(sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anton/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/anton/h-elmo/helmo/nets/resrnn.py:579: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(_add_rnn_graph)training: True\n",
      "(_add_rnn_graph)'hidden_state' in self._accumulator_postprocessing: False\n",
      "WARNING:tensorflow:From /home/anton/learning-to-learn/learning_to_learn/useful_functions.py:1379: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "(_add_rnn_graph)training: False\n",
      "(_add_rnn_graph)'hidden_state' in self._accumulator_postprocessing: False\n",
      "!!! {'method': 'hist_1d', 'hook': 'update_level0_0_hidden_state_hist', 'args': ['reshape_to_matrix', 50, [-1.0, 1.0], 0], 'accumulator': <tf.Variable 'Variable:0' shape=<unknown> dtype=int32_ref>}\n",
      "Tensor(\"inference/gpu0/rnns/level0/dropout/mul:0\", shape=(?, ?, 100), dtype=float32, device=/device:GPU:0)\n",
      "{'method': 'hist_1d', 'hook': 'update_level0_0_hidden_state_hist', 'args': ['reshape_to_matrix', 50, [-1.0, 1.0], 0], 'accumulator': <tf.Variable 'Variable:0' shape=<unknown> dtype=int32_ref>, 'update_op': <tf.Tensor 'inference/gpu0/rnns/level0/_add_hidden_state_accumulation_ops/AssignAdd:0' shape=(50, 100) dtype=int32_ref>}\n"
     ]
    }
   ],
   "source": [
    "import helmo.nets.resrnn as resrnn\n",
    "\n",
    "rnn_map = {\n",
    "    \"module_name\": \"level0\",\n",
    "    \"num_nodes\": [100, 100],\n",
    "    \"input_idx\": None,\n",
    "    \"output_idx\": None\n",
    "}\n",
    "\n",
    "accumulator_postprocessing=dict(\n",
    "    rnn_map=dict(\n",
    "        level0={\n",
    "            \"0\": dict(\n",
    "                hidden_state=dict(\n",
    "                    entropy=dict(\n",
    "                        method='entropy_MM_from_hist',\n",
    "                        hook='entropy_level0_0_hidden_state',\n",
    "                        accumulators=['hist'],\n",
    "                        args=[0],\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "accumulator_specs=dict(\n",
    "    rnn_map=dict(\n",
    "        level0={\n",
    "            \"0\": dict(\n",
    "                hidden_state=dict(\n",
    "                    hist=dict(\n",
    "                        method='hist_1d',\n",
    "                        hook='update_level0_0_hidden_state_hist',\n",
    "                        args=['reshape_to_matrix', 50, [-1., 1.], 0],\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "net = resrnn.Rnn(\n",
    "    voc_size=100,\n",
    "    rnn_map=rnn_map,\n",
    "    accumulator_specs=accumulator_specs,\n",
    "    accumulator_postprocessing=accumulator_postprocessing,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = net.get_default_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': <tf.Tensor 'inps_and_lbls/inps:0' shape=(?, ?) dtype=int32>, 'labels': <tf.Tensor 'inps_and_lbls/lbls:0' shape=(?, ?) dtype=int32>, 'train_op': <tf.Operation 'gpu0_gradients/Adam' type=NoOp>, 'learning_rate': <tf.Tensor 'learning_rate:0' shape=<unknown> dtype=float32>, 'loss': <tf.Tensor 'loss_and_metrics/averaging_metrics/add:0' shape=() dtype=float32>, 'predictions': <tf.Tensor 'concat:0' shape=(?, ?, 100) dtype=float32>, 'validation_inputs': <tf.Tensor 'inps_and_lbls/inps:0' shape=(?, ?) dtype=int32>, 'validation_labels': <tf.Tensor 'inps_and_lbls/lbls:0' shape=(?, ?) dtype=int32>, 'validation_predictions': <tf.Tensor 'concat_1:0' shape=(?, ?, 100) dtype=float32>, 'reset_validation_state': <tf.Operation 'inference/group_deps' type=NoOp>, 'randomize_sample_state': <tf.Operation 'inference/group_deps_1' type=NoOp>, 'reset_train_state': <tf.Operation 'train/group_deps' type=NoOp>, 'randomize_train_state': <tf.Operation 'train/group_deps_1' type=NoOp>, 'dropout': <tf.Tensor 'dropout_rate:0' shape=<unknown> dtype=float32>, 'saver': <tensorflow.python.training.saver.Saver object at 0x7f971f6c0668>, 'entropy_level0_0_hidden_state': <tf.Tensor 'entropy_MM_from_hist/Squeeze:0' shape=<unknown> dtype=float32>, 'level0_0_hidden_state': <tf.Tensor 'inference/gpu0/rnns/level0/dropout/mul:0' shape=(?, ?, 100) dtype=float32>, 'level0_1_hidden_state': <tf.Tensor 'inference/gpu0/rnns/level0/mul_1:0' shape=(?, ?, 100) dtype=float32>, 'level0_0_axis_quarters': <tf.Tensor 'inference/gpu0/rnns/level0/get_axis_quarters/Cast_2:0' shape=(?, ?) dtype=int32>, 'level0_1_axis_quarters': <tf.Tensor 'inference/gpu0/rnns/level0/get_axis_quarters_1/Cast_2:0' shape=(?, ?) dtype=int32>, 'validation_loss': <tf.Tensor 'loss_and_metrics_1/averaging_metrics/add:0' shape=() dtype=float32>, 'subgraph_savers': {'level0': <tensorflow.python.training.saver.Saver object at 0x7f971ee8aef0>}}\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inputs', 'labels', 'train_op', 'learning_rate', 'momentum', 'loss', 'predictions', 'validation_inputs', 'validation_labels', 'validation_predictions', 'reset_validation_state', 'randomize_sample_state', 'reset_train_state', 'randomize_train_state', 'dropout', 'saver', 'correlation', 'correlation_values', 'correlation2', 'correlation12', 'correlation_values_1-2', 'update_level0_0_hidden_state_hist', 'entropy_level0_0_hidden_state', 'level0_0_hidden_state', 'level0_1_hidden_state', 'level0_0_axis_quarters', 'level0_1_axis_quarters', 'validation_loss', 'subgraph_savers']\n"
     ]
    }
   ],
   "source": [
    "print(list(net._hooks.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"inference/gpu0/rnns/level0/_add_hidden_state_accumulation_ops/AssignAdd:0\", shape=(100, 100), dtype=int32_ref)\n"
     ]
    }
   ],
   "source": [
    "print(h['update_level0_0_hidden_state_hist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.group()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "\n",
    "k, n, p = symbols('k n p')\n",
    "\n",
    "p = Product(k**(k * binomial(n, k) * p**k * (1-p)**(n-k)), (k, 0, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = p.doit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product(k**(k*p**k*(-p + 1)**(-k + n)*binomial(n, k)), (k, 0, n))\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_line(file_name):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(file_name) as f:\n",
    "        for line in f.readlines():\n",
    "            xx, yy = line.split()\n",
    "            x.append(float(xx))\n",
    "            y.append(float(yy))\n",
    "    return [x, y]\n",
    "\n",
    "\n",
    "def load_lines(file_names):\n",
    "    lines = []\n",
    "    for fn in file_names:\n",
    "        lines.append(load_line(fn))\n",
    "    return lines\n",
    "\n",
    "\n",
    "def load_groups_of_lines(groups):\n",
    "    lines = {}\n",
    "    for label, file_names in groups.items():\n",
    "        lines[label] = load_lines(file_names)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def plot_similar_lines(lines, color, lw):\n",
    "    for line in lines:\n",
    "        plt.plot(line[0], line[1], lw=lw, color=color)\n",
    "        \n",
    "        \n",
    "def add_legend(artists, labels, position):\n",
    "    if position == 'outside':\n",
    "        pos_dict = dict(\n",
    "            bbox_to_anchor=(1.05, 1),\n",
    "            loc=2,\n",
    "        )\n",
    "    elif position == 'upper_right':\n",
    "        pos_dict = dict(\n",
    "            bbox_to_anchor=(.95, .95),\n",
    "            loc=1,\n",
    "        )\n",
    "    elif position == 'upper_left':\n",
    "        pos_dict = dict(\n",
    "            bbox_to_anchor=(.05, .95),\n",
    "            loc=2,\n",
    "        )\n",
    "    elif position == 'best':\n",
    "        pos_dict = {'loc': 'best'}\n",
    "    ax = plt.gca()\n",
    "    lgd = ax.legend(\n",
    "        artists,\n",
    "        labels,\n",
    "        **pos_dict,\n",
    "    )\n",
    "    return lgd\n",
    "\n",
    "\n",
    "def form_symlog_kwargs(groups):\n",
    "    x_nonzero_values = []\n",
    "    y_nonzero_values = []\n",
    "    for group_of_lines in groups.values():\n",
    "        for line in group_of_lines:\n",
    "            x_nonzero_values += [x for x in line[0] if x != 0]\n",
    "            y_nonzero_values += [y for y in line[1] if y != 0]\n",
    "    xkwargs = dict(\n",
    "        linthreshx=np.min(np.abs(x_nonzero_values))\n",
    "    )\n",
    "    ykwargs = dict(\n",
    "        linthreshy=np.min(np.abs(y_nonzero_values))\n",
    "    )\n",
    "    return xkwargs, ykwargs\n",
    "\n",
    "\n",
    "def plot_groups_of_lines(\n",
    "        groups,\n",
    "        colors,\n",
    "        lw,\n",
    "        xlabel,\n",
    "        ylabel,\n",
    "        xscale,\n",
    "        yscale,\n",
    "        legend_position,\n",
    "        dpi,\n",
    "        save_path,\n",
    "        show,\n",
    "):\n",
    "    custom_lines = []\n",
    "    labels = []\n",
    "    for (label, group_of_lines), color in zip(groups.items(), colors):\n",
    "        print(label)\n",
    "        labels.append(label)\n",
    "        custom_lines.append(Line2D([0], [0], color=color, lw=4))\n",
    "        plot_similar_lines(group_of_lines, color, lw)\n",
    "    plt.grid(which='both')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    xkwargs, ykwargs = form_symlog_kwargs(groups)\n",
    "    if xscale != 'symlog':\n",
    "        xkwargs = {}    \n",
    "    if yscale != 'symlog':\n",
    "        ykwargs = {}\n",
    "    plt.xscale(xscale, **xkwargs)\n",
    "    plt.yscale(yscale, **ykwargs)\n",
    "    bbox_extra_artists = [add_legend(custom_lines, labels, legend_position)]\n",
    "    if save_path is not None:\n",
    "        os.makedirs(os.path.split(save_path)[0], exists_ok=True)\n",
    "        plt.savefig(\n",
    "            save_path,\n",
    "            bbox_extra_artists=bbox_extra_artists,\n",
    "            bbox_inches='tight',\n",
    "            dpi=dpi,\n",
    "        )\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def main(\n",
    "        groups_of_file_names,\n",
    "        colors,\n",
    "        lw,\n",
    "        xlabel,\n",
    "        ylabel,\n",
    "        xscale,\n",
    "        yscale,\n",
    "        legend_position,\n",
    "        dpi,\n",
    "        save_path,\n",
    "        show,\n",
    "):\n",
    "    groups = load_groups_of_lines(groups_of_file_names)\n",
    "    plot_groups_of_lines(\n",
    "        groups,\n",
    "        colors,\n",
    "        lw,\n",
    "        xlabel,\n",
    "        ylabel,\n",
    "        xscale,\n",
    "        yscale,\n",
    "        legend_position,\n",
    "        dpi,\n",
    "        save_path,\n",
    "        show,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ch100_w200', 'ch100_w100', 'ch100_w50']\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "prefix = 'expres/resrnn/word/restore_tt'\n",
    "postfix = 'results_joined/loss_valid.txt'\n",
    "\n",
    "nets = ['ch100_w200', 'ch100_w100', 'ch100_w50']\n",
    "numbers = list(range(10))\n",
    "\n",
    "groups_of_file_names = OrderedDict()\n",
    "for net in nets:\n",
    "    groups_of_file_names[net] = []\n",
    "    for i in numbers:\n",
    "        file_name = os.path.join(prefix, net, str(i), postfix)\n",
    "        groups_of_file_names[net].append(file_name)\n",
    "        \n",
    "print(list(groups_of_file_names.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch100_w100\n",
      "ch100_w200\n",
      "ch100_w50\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(\n",
    "    groups_of_file_names,\n",
    "    ['red', 'green', 'blue'],\n",
    "    1,\n",
    "    'step',\n",
    "    'loss',\n",
    "    'linear',\n",
    "    'log',\n",
    "    'best',\n",
    "    900,\n",
    "    None,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
